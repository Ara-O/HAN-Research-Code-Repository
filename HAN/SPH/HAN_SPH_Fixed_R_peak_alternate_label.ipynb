{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbKFm3-45fxQ",
        "outputId": "7c4893dc-a5ce-4c72-b80b-5719f5b40a1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m139.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 kB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q torchinfo mlflow optuna thop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua-UVjXsOWsu",
        "outputId": "540dfba6-fb9e-4e73-b603-f6838bbb6d74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Optional\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pywt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "from scipy.signal import butter, filtfilt, find_peaks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "import optuna\n",
        "from optuna.exceptions import TrialPruned\n",
        "from dotenv import load_dotenv\n",
        "import time\n",
        "from thop import profile, clever_format\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il9nOz1tLNU9",
        "outputId": "30b18af2-f497-4d8a-9933-1557a9e43e07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/2727678298130740', creation_time=1767908664414, experiment_id='2727678298130740', last_update_time=1767916356467, lifecycle_stage='active', name='/Users/oladipoeyiara@gmail.com/han_sph_ablation_alternate_code_mappings', tags={'mlflow.experiment.sourceName': '/Users/oladipoeyiara@gmail.com/han_sph_ablation_alternate_code_mappings',\n",
              " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
              " 'mlflow.ownerEmail': 'oladipoeyiara@gmail.com',\n",
              " 'mlflow.ownerId': '1108839756692281'}>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/oladipoeyiara@gmail.com/han_sph_ablation_alternate_code_mappings\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adAQ0YZbMAkt"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AunfTkWOIiHX",
        "outputId": "c2fe6049-04d6-44d6-fc61-4d407bbede22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Successfully extracted /content/drive/MyDrive/records.zip to /content\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Define the path to the zip file in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/records.zip'\n",
        "\n",
        "# Define the extraction path\n",
        "extract_path = '/content'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Check if the zip file exists\n",
        "if os.path.exists(zip_file_path):\n",
        "    # Extract the zip file\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"Successfully extracted {zip_file_path} to {extract_path}\")\n",
        "else:\n",
        "    print(f\"Error: {zip_file_path} not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdLWrjEoInkc"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Config\n",
        "# -------------------------\n",
        "PATH = \"records\"\n",
        "SAMPLING_RATE = 300\n",
        "PRE_PEAK_SAMPLES = 99\n",
        "POST_PEAK_SAMPLES = 201\n",
        "SEGMENT_LENGTH = PRE_PEAK_SAMPLES + POST_PEAK_SAMPLES  # 300\n",
        "BATCH_SIZE = 16\n",
        "DROP_LAST = True\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJSNbPRaJIS4"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# utilities: filtering and peak detection\n",
        "# -------------------------\n",
        "def denoise(data):\n",
        "    # wavelet transform\n",
        "    coeffs = pywt.wavedec(data=data, wavelet='db5', level=9)\n",
        "    cA9, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1 = coeffs\n",
        "\n",
        "    # Threshold denoising\n",
        "    threshold = (np.median(np.abs(cD1)) / 0.6745) * (np.sqrt(2 * np.log(len(cD1))))\n",
        "    cD1.fill(0)\n",
        "    cD2.fill(0)\n",
        "    for i in range(1, len(coeffs) - 2):\n",
        "        coeffs[i] = pywt.threshold(coeffs[i], threshold)\n",
        "\n",
        "    # Inverse wavelet transform to obtain the denoised signal\n",
        "    rdata = pywt.waverec(coeffs=coeffs, wavelet='db5')\n",
        "    return rdata\n",
        "\n",
        "\n",
        "def pan_tompkins_detector(ecg_signal, fs):\n",
        "    lowcut, highcut = 5.0, 15.0\n",
        "    nyquist = 0.5 * fs\n",
        "    low, high = lowcut / nyquist, highcut / nyquist\n",
        "    b, a = butter(1, [low, high], btype='band')\n",
        "    filtered_ecg = filtfilt(b, a, ecg_signal)\n",
        "    diff_ecg = np.diff(filtered_ecg)\n",
        "    squared_ecg = diff_ecg ** 2\n",
        "    window_size = int(0.150 * fs)\n",
        "    mwa_ecg = np.convolve(squared_ecg, np.ones(window_size) / window_size, mode='same')\n",
        "    peaks, _ = find_peaks(mwa_ecg, distance=int(0.6 * fs))\n",
        "    return peaks\n",
        "\n",
        "\n",
        "def multi_lead_fusion(detected_peaks, fs, fusion_window=0.1, min_leads=None):\n",
        "    n_leads = len(detected_peaks)\n",
        "    if min_leads is None:\n",
        "        min_leads = int(np.ceil(n_leads / 2))\n",
        "\n",
        "    # Collect all peaks with their lead information\n",
        "    all_peaks = [(p, lead) for lead, peaks in enumerate(detected_peaks) for p in peaks]\n",
        "    all_peaks.sort(key=lambda x: x[0])\n",
        "\n",
        "    fused_peaks = []\n",
        "    i = 0\n",
        "\n",
        "    while i < len(all_peaks):\n",
        "        # Start a new cluster\n",
        "        cluster = [all_peaks[i]]\n",
        "        i += 1\n",
        "\n",
        "        # Add nearby peaks to the cluster\n",
        "        while i < len(all_peaks) and all_peaks[i][0] - cluster[-1][0] <= fusion_window * fs:\n",
        "            cluster.append(all_peaks[i])\n",
        "            i += 1\n",
        "\n",
        "        # Check if cluster has peaks from enough leads\n",
        "        unique_leads = {lead for _, lead in cluster}\n",
        "        if len(unique_leads) >= min_leads:\n",
        "            # Use median position as the fused peak\n",
        "            fused_peak = int(np.median([p for (p, _) in cluster]))\n",
        "            fused_peaks.append(fused_peak)\n",
        "\n",
        "    return np.array(sorted(fused_peaks))\n",
        "\n",
        "\n",
        "def detect_r_peaks(ecg_signals, fs):\n",
        "    detected_peaks = []\n",
        "    for lead in ecg_signals:\n",
        "        peaks = pan_tompkins_detector(lead, fs)\n",
        "        detected_peaks.append(peaks)\n",
        "\n",
        "    fused_r_peaks = multi_lead_fusion(detected_peaks, fs, fusion_window=0.1, min_leads=6)\n",
        "    return fused_r_peaks\n",
        "\n",
        "\n",
        "def extract_segments_around_peaks(signal, r_peaks, pre_samples, post_samples):\n",
        "    segments = []\n",
        "\n",
        "    for peak in r_peaks:\n",
        "        start = max(0, peak - pre_samples)\n",
        "        end = min(len(signal), peak + post_samples)\n",
        "\n",
        "        if end - start == pre_samples + post_samples:\n",
        "            segment = signal[start:end]\n",
        "            segments.append(segment)\n",
        "\n",
        "    return segments\n",
        "\n",
        "def extract_beats_multi_lead(ecg_signals, fs, pre_samples, post_samples, denoise_fn=None):\n",
        "    # Convert to numpy array for consistent indexing\n",
        "    ecg_signals = np.array(ecg_signals)\n",
        "\n",
        "    # Apply denoising if provided\n",
        "    if denoise_fn is not None:\n",
        "        ecg_signals = np.array([denoise_fn(lead) for lead in ecg_signals])\n",
        "\n",
        "    # Detect fused R-peaks across all leads\n",
        "    r_peaks = detect_r_peaks(ecg_signals, fs)\n",
        "    # print(f\"Detected {len(r_peaks)} R-peaks after fusion\")\n",
        "\n",
        "    if len(r_peaks) == 0:\n",
        "        return None\n",
        "\n",
        "    # Extract segments from all leads\n",
        "    all_lead_segments = []\n",
        "    for lead_idx, lead_signal in enumerate(ecg_signals):\n",
        "        segments = extract_segments_around_peaks(lead_signal, r_peaks, pre_samples, post_samples)\n",
        "        all_lead_segments.append(segments)\n",
        "\n",
        "    # Find the minimum number of valid segments across all leads\n",
        "    min_segments = min(len(segments) for segments in all_lead_segments)\n",
        "    # print(f\"Extracted {min_segments} valid segments across all leads\")\n",
        "\n",
        "    if min_segments == 0:\n",
        "        return None\n",
        "\n",
        "    # Stack segments: (n_beats, segment_length, n_leads)\n",
        "    beats_arr = np.stack([\n",
        "        np.stack(segments[:min_segments], axis=0)\n",
        "        for segments in all_lead_segments\n",
        "    ], axis=-1)\n",
        "\n",
        "    return beats_arr.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTpLOqc4JgEI",
        "outputId": "19a39fdb-5a2f-4fb5-a7e6-b9ef4b2dee81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_classes: 11 labels: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'M']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n",
            "[Parallel(n_jobs=11)]: Done   3 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=11)]: Done  10 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=11)]: Done  19 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=11)]: Done  28 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=11)]: Done  39 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=11)]: Done  50 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=11)]: Done  63 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=11)]: Done  76 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=11)]: Batch computation too fast (0.19508193200166563s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=11)]: Done  91 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=11)]: Done 106 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=11)]: Done 136 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=11)]: Done 170 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=11)]: Done 208 tasks      | elapsed:    3.4s\n",
            "[Parallel(n_jobs=11)]: Done 246 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=11)]: Done 288 tasks      | elapsed:    3.8s\n",
            "[Parallel(n_jobs=11)]: Done 330 tasks      | elapsed:    4.0s\n",
            "[Parallel(n_jobs=11)]: Done 376 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=11)]: Done 422 tasks      | elapsed:    4.6s\n",
            "[Parallel(n_jobs=11)]: Done 472 tasks      | elapsed:    4.9s\n",
            "[Parallel(n_jobs=11)]: Done 522 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=11)]: Done 576 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=11)]: Done 630 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=11)]: Done 688 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=11)]: Done 746 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=11)]: Done 808 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=11)]: Done 870 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=11)]: Done 936 tasks      | elapsed:    7.4s\n",
            "[Parallel(n_jobs=11)]: Done 1002 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=11)]: Done 1072 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=11)]: Done 1142 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=11)]: Done 1216 tasks      | elapsed:    8.9s\n",
            "[Parallel(n_jobs=11)]: Done 1290 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=11)]: Done 1368 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=11)]: Done 1446 tasks      | elapsed:   10.1s\n",
            "[Parallel(n_jobs=11)]: Done 1528 tasks      | elapsed:   10.6s\n",
            "[Parallel(n_jobs=11)]: Done 1610 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=11)]: Done 1696 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=11)]: Done 1782 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=11)]: Batch computation too fast (0.1995087587449313s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=11)]: Done 1874 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=11)]: Done 2054 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=11)]: Done 2242 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=11)]: Done 2430 tasks      | elapsed:   14.5s\n",
            "[Parallel(n_jobs=11)]: Done 2626 tasks      | elapsed:   15.2s\n",
            "[Parallel(n_jobs=11)]: Done 2822 tasks      | elapsed:   16.1s\n",
            "[Parallel(n_jobs=11)]: Done 3026 tasks      | elapsed:   16.9s\n",
            "[Parallel(n_jobs=11)]: Done 3230 tasks      | elapsed:   17.7s\n",
            "[Parallel(n_jobs=11)]: Done 3442 tasks      | elapsed:   18.5s\n",
            "[Parallel(n_jobs=11)]: Done 3654 tasks      | elapsed:   19.4s\n",
            "[Parallel(n_jobs=11)]: Done 3874 tasks      | elapsed:   20.2s\n",
            "[Parallel(n_jobs=11)]: Done 4094 tasks      | elapsed:   21.1s\n",
            "[Parallel(n_jobs=11)]: Done 4322 tasks      | elapsed:   22.0s\n",
            "[Parallel(n_jobs=11)]: Done 4550 tasks      | elapsed:   22.8s\n",
            "[Parallel(n_jobs=11)]: Done 4786 tasks      | elapsed:   23.7s\n",
            "[Parallel(n_jobs=11)]: Done 5022 tasks      | elapsed:   24.6s\n",
            "[Parallel(n_jobs=11)]: Done 5266 tasks      | elapsed:   25.5s\n",
            "[Parallel(n_jobs=11)]: Done 5510 tasks      | elapsed:   26.4s\n",
            "[Parallel(n_jobs=11)]: Done 5762 tasks      | elapsed:   27.4s\n",
            "[Parallel(n_jobs=11)]: Done 6014 tasks      | elapsed:   28.3s\n",
            "[Parallel(n_jobs=11)]: Done 6274 tasks      | elapsed:   29.3s\n",
            "[Parallel(n_jobs=11)]: Done 6534 tasks      | elapsed:   30.4s\n",
            "[Parallel(n_jobs=11)]: Done 6802 tasks      | elapsed:   31.4s\n",
            "[Parallel(n_jobs=11)]: Done 7070 tasks      | elapsed:   32.5s\n",
            "[Parallel(n_jobs=11)]: Done 7346 tasks      | elapsed:   33.6s\n",
            "[Parallel(n_jobs=11)]: Done 7622 tasks      | elapsed:   34.6s\n",
            "[Parallel(n_jobs=11)]: Done 7906 tasks      | elapsed:   35.7s\n",
            "[Parallel(n_jobs=11)]: Done 8190 tasks      | elapsed:   36.8s\n",
            "[Parallel(n_jobs=11)]: Done 8482 tasks      | elapsed:   37.9s\n",
            "[Parallel(n_jobs=11)]: Done 8774 tasks      | elapsed:   39.0s\n",
            "[Parallel(n_jobs=11)]: Done 9074 tasks      | elapsed:   40.0s\n",
            "[Parallel(n_jobs=11)]: Done 9374 tasks      | elapsed:   41.2s\n",
            "[Parallel(n_jobs=11)]: Done 9682 tasks      | elapsed:   42.3s\n",
            "[Parallel(n_jobs=11)]: Done 9990 tasks      | elapsed:   43.5s\n",
            "[Parallel(n_jobs=11)]: Done 10306 tasks      | elapsed:   44.7s\n",
            "[Parallel(n_jobs=11)]: Done 10622 tasks      | elapsed:   46.0s\n",
            "[Parallel(n_jobs=11)]: Done 10946 tasks      | elapsed:   47.3s\n",
            "[Parallel(n_jobs=11)]: Done 11270 tasks      | elapsed:   48.6s\n",
            "[Parallel(n_jobs=11)]: Done 11602 tasks      | elapsed:   49.9s\n",
            "[Parallel(n_jobs=11)]: Done 11934 tasks      | elapsed:   51.1s\n",
            "[Parallel(n_jobs=11)]: Done 12274 tasks      | elapsed:   52.4s\n",
            "[Parallel(n_jobs=11)]: Done 12614 tasks      | elapsed:   53.7s\n",
            "[Parallel(n_jobs=11)]: Done 12962 tasks      | elapsed:   55.0s\n",
            "[Parallel(n_jobs=11)]: Done 13310 tasks      | elapsed:   56.3s\n",
            "[Parallel(n_jobs=11)]: Done 13666 tasks      | elapsed:   57.7s\n",
            "[Parallel(n_jobs=11)]: Done 14022 tasks      | elapsed:   59.1s\n",
            "[Parallel(n_jobs=11)]: Done 14386 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=11)]: Done 14750 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=11)]: Done 15122 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=11)]: Done 15494 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=11)]: Done 15874 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=11)]: Done 16254 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=11)]: Done 16642 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=11)]: Done 17030 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=11)]: Done 17426 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=11)]: Done 17822 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=11)]: Done 18226 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=11)]: Done 18630 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=11)]: Done 19042 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=11)]: Done 19454 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=11)]: Done 19874 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=11)]: Done 20294 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=11)]: Done 20722 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=11)]: Done 21150 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=11)]: Done 21586 tasks      | elapsed:  1.5min\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared records: 20844\n",
            "Beat counts distribution: Counter({22: 3111, 23: 2772, 21: 2516, 20: 1922, 24: 1659, 19: 1319, 14: 1039, 18: 889, 15: 857, 25: 702, 16: 670, 17: 660, 26: 468, 27: 424, 13: 349, 28: 345, 29: 243, 30: 168, 32: 94, 31: 92, 33: 78, 34: 69, 36: 60, 35: 55, 37: 47, 38: 31, 39: 17, 40: 17, 42: 16, 43: 15, 41: 13, 44: 11, 48: 11, 45: 10, 47: 9, 50: 9, 46: 9, 57: 6, 64: 5, 58: 5, 52: 5, 53: 4, 51: 4, 54: 4, 49: 4, 69: 3, 56: 2, 70: 2, 67: 2, 60: 2, 98: 2, 55: 2, 66: 1, 143: 1, 102: 1, 87: 1, 95: 1, 65: 1, 73: 1, 84: 1, 71: 1, 78: 1, 75: 1, 72: 1, 61: 1, 80: 1, 74: 1, 63: 1})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=11)]: Done 22010 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=11)]: Done 22046 out of 22046 | elapsed:  1.5min finished\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing as mp\n",
        "\n",
        "# -------------------------\n",
        "metadata = pd.read_csv(\"metadata.csv\")\n",
        "codes = pd.read_csv(\"code_new.csv\")\n",
        "\n",
        "code_mappings = dict(zip(codes['Code'].astype(str), codes['Category']))\n",
        "\n",
        "metadata = metadata[~metadata['AHA_Code'].str.contains(\";\")]\n",
        "metadata['AHA_Code'] = metadata['AHA_Code'].str.split(\"+\").str[0]\n",
        "metadata['AHA_Code_Mapped'] = metadata['AHA_Code'].map(code_mappings)\n",
        "\n",
        "unique_labels = sorted(metadata['AHA_Code_Mapped'].dropna().unique())\n",
        "label2idx = {lbl: i for i, lbl in enumerate(unique_labels)}\n",
        "num_classes = len(unique_labels)\n",
        "\n",
        "print(\"num_classes:\", num_classes, \"labels:\", unique_labels)\n",
        "\n",
        "def process_row(row):\n",
        "    ecg_data_path = os.path.join(PATH, row.ECG_ID + \".h5\")\n",
        "    if not os.path.exists(ecg_data_path):\n",
        "        return None\n",
        "\n",
        "    label = row.AHA_Code_Mapped\n",
        "    if pd.isna(label) or label not in label2idx:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with h5py.File(ecg_data_path, 'r') as f:\n",
        "            ecg = np.array(f['ecg'])\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "    beats = extract_beats_multi_lead(\n",
        "        ecg,\n",
        "        fs=SAMPLING_RATE,\n",
        "        pre_samples=PRE_PEAK_SAMPLES,\n",
        "        post_samples=POST_PEAK_SAMPLES,\n",
        "        denoise_fn=denoise\n",
        "    )\n",
        "\n",
        "    if beats is None:\n",
        "        return None\n",
        "\n",
        "    return (beats.astype(np.float32), label2idx[label])\n",
        "\n",
        "n_jobs = max(1, mp.cpu_count() - 1)\n",
        "\n",
        "results = Parallel(\n",
        "    n_jobs=n_jobs,\n",
        "    backend=\"loky\",\n",
        "    verbose=10\n",
        ")(\n",
        "    delayed(process_row)(row)\n",
        "    for row in metadata.itertuples(index=False)\n",
        ")\n",
        "\n",
        "data_list = [r for r in results if r is not None]\n",
        "\n",
        "print(\"Prepared records:\", len(data_list))\n",
        "print(\"Beat counts distribution:\", Counter([x[0].shape[0] for x in data_list]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F9RkvzLLBb4",
        "outputId": "9664dd20-8149-4ab5-c4a4-f17919d61e36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20, 300, 12)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None,\n",
              " {'A': 0,\n",
              "  'B': 1,\n",
              "  'C': 2,\n",
              "  'D': 3,\n",
              "  'E': 4,\n",
              "  'F': 5,\n",
              "  'G': 6,\n",
              "  'H': 7,\n",
              "  'J': 8,\n",
              "  'K': 9,\n",
              "  'M': 10})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(data_list[2][0].shape), label2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k-vBZcIlTui",
        "outputId": "02030777-6620-48bf-fe21-14886d2f4669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({0: 13903, 1: 2612, 9: 1523, 5: 1334, 3: 527, 2: 490, 6: 185, 7: 165, 10: 56, 4: 26, 8: 23})\n"
          ]
        }
      ],
      "source": [
        "\n",
        "label_counts = Counter([x[1] for x in data_list])\n",
        "print(label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs7wTSUUL2wR"
      },
      "outputs": [],
      "source": [
        "# ---------- Length-bucketing Batch Sampler ----------\n",
        "class LengthBucketBatchSampler(Sampler):\n",
        "    def __init__(self,\n",
        "                 lengths: List[int],\n",
        "                 batch_size: int,\n",
        "                 bin_size: Optional[int] = None,\n",
        "                 shuffle: bool = True,\n",
        "                 drop_last: bool = False):\n",
        "        self.lengths = list(lengths)\n",
        "        self.batch_size = int(batch_size)\n",
        "        self.bin_size = bin_size\n",
        "        self.shuffle = shuffle\n",
        "        self.drop_last = drop_last\n",
        "\n",
        "        # Build mapping length_key -> list of indices\n",
        "        self._buckets = defaultdict(list)\n",
        "        for idx, L in enumerate(self.lengths):\n",
        "            key = self._length_key(L)\n",
        "            self._buckets[key].append(idx)\n",
        "\n",
        "        # Convert to normal dict for iteration; keep keys list stable\n",
        "        self.bucket_keys = list(self._buckets.keys())\n",
        "\n",
        "    def _length_key(self, length: int) -> int:\n",
        "        if self.bin_size is None or self.bin_size <= 0:\n",
        "            return int(length)   # exact-length bucket\n",
        "        else:\n",
        "            return (length // self.bin_size) * self.bin_size\n",
        "\n",
        "    def __iter__(self):\n",
        "      # For each epoch, build batches from buckets.\n",
        "      batches = []\n",
        "      for key in self.bucket_keys:\n",
        "          idxs = list(self._buckets[key])\n",
        "          if len(idxs) < self.batch_size:\n",
        "              # skip this bucket entirely\n",
        "              continue\n",
        "          if self.shuffle:\n",
        "              random.shuffle(idxs)\n",
        "          # chunk into batches\n",
        "          for i in range(0, len(idxs), self.batch_size):\n",
        "              batch = idxs[i:i + self.batch_size]\n",
        "              if len(batch) < self.batch_size and self.drop_last:\n",
        "                  continue\n",
        "              batches.append(batch)\n",
        "\n",
        "      if self.shuffle:\n",
        "          random.shuffle(batches)\n",
        "\n",
        "      for batch in batches:\n",
        "          yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "      total = 0\n",
        "      for key in self.bucket_keys:\n",
        "          n = len(self._buckets[key])\n",
        "          if n < self.batch_size:\n",
        "              continue  # Skip small buckets like in __iter__\n",
        "          if self.drop_last:\n",
        "              total += n // self.batch_size\n",
        "          else:\n",
        "              total += math.ceil(n / self.batch_size)\n",
        "      return total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dam8A7JIK2DU"
      },
      "outputs": [],
      "source": [
        "class ECGSegmentDataset(Dataset):\n",
        "    def __init__(self, data_list):\n",
        "        # data_list: list of (beats_array (S, T, C), label_idx)\n",
        "        self.data = data_list\n",
        "        self.num_beats = [int(x[0].shape[0]) for x in data_list]\n",
        "        # optionally check that T==SEGMENT_LENGTH for all entries\n",
        "        for sig, _ in data_list:\n",
        "            assert sig.shape[1] == SEGMENT_LENGTH, \"SEGMENT_LENGTH mismatch\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sig, label = self.data[idx]\n",
        "        sig_t = torch.as_tensor(sig, dtype=torch.float32)  # (S, T, C)\n",
        "        return {\"signal\": sig_t, \"label\": int(label), \"num_beats\": int(sig_t.shape[0])}\n",
        "\n",
        "\n",
        "def collate_by_num_beats(batch):\n",
        "    s_vals = [item[\"num_beats\"] for item in batch]\n",
        "    if not all(s == s_vals[0] for s in s_vals):\n",
        "        raise ValueError(\"collate_by_num_beats received mixed num_beats in a batch\")\n",
        "    signals = torch.stack([item[\"signal\"] for item in batch], dim=0)  # (B, S, T, C)\n",
        "    labels = torch.tensor([item[\"label\"] for item in batch], dtype=torch.long)\n",
        "    return {\"signal\": signals, \"label\": labels, \"num_beats\": torch.tensor(s_vals, dtype=torch.long)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "pV4wYaTDUOkz",
        "outputId": "157e1a00-28bb-4e4e-879e-24466b129a3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x79158de77aa0>]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Not denoised\n",
        "plt.plot(np.array(data_list[2][0][:,:,0]).reshape(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6tvcFTaK4d6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "# # instantiate dataset and sampler\n",
        "ds = ECGSegmentDataset(data_list)\n",
        "\n",
        "# -------------------------\n",
        "# Split indices\n",
        "# -------------------------\n",
        "all_indices = list(range(len(ds)))\n",
        "all_labels = [data_list[i][1] for i in all_indices]  # label_idx for each sample\n",
        "\n",
        "# First split: train+val vs test (stratified)\n",
        "trainval_indices, test_indices = train_test_split(\n",
        "    all_indices,\n",
        "    test_size=0.1,\n",
        "    random_state=10,\n",
        "    stratify=all_labels  \n",
        ")\n",
        "\n",
        "# Extract labels for the trainval subset\n",
        "trainval_labels = [all_labels[i] for i in trainval_indices]\n",
        "\n",
        "# Second split: train vs val (stratified)\n",
        "train_indices, val_indices = train_test_split(\n",
        "    trainval_indices,\n",
        "    test_size=0.1,\n",
        "    random_state=10,\n",
        "    stratify=trainval_labels  \n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Create Subsets\n",
        "# -------------------------\n",
        "train_ds = Subset(ds, train_indices)\n",
        "val_ds   = Subset(ds, val_indices)\n",
        "test_ds  = Subset(ds, test_indices)\n",
        "\n",
        "# -------------------------\n",
        "# Make loader helper\n",
        "# -------------------------\n",
        "def make_loader(subset_ds, batch_size=16, drop_last=True, shuffle=True):\n",
        "    subset_indices = subset_ds.indices\n",
        "    lengths = [ds.num_beats[i] for i in subset_indices]\n",
        "\n",
        "    sampler = LengthBucketBatchSampler(\n",
        "        lengths=lengths,\n",
        "        batch_size=batch_size,\n",
        "        bin_size=None,       # exact-length buckets\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(\n",
        "        subset_ds,\n",
        "        batch_sampler=sampler,\n",
        "        collate_fn=collate_by_num_beats,\n",
        "        num_workers=6,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4uGlP9vh0IL",
        "outputId": "a27af178-0b5e-49b9-8735-313908a21c5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train distribution: Counter({0: 11261, 1: 2116, 9: 1234, 5: 1081, 3: 426, 2: 397, 6: 149, 7: 134, 10: 45, 4: 21, 8: 19})\n",
            "Val distribution: Counter({0: 1251, 1: 235, 9: 137, 5: 120, 3: 48, 2: 44, 6: 17, 7: 15, 10: 5, 8: 2, 4: 2})\n",
            "Test distribution: Counter({0: 1391, 1: 261, 9: 152, 5: 133, 3: 53, 2: 49, 6: 19, 7: 16, 10: 6, 4: 3, 8: 2})\n"
          ]
        }
      ],
      "source": [
        "# Verifying stratifying\n",
        "train_loader = make_loader(train_ds, batch_size=BATCH_SIZE)\n",
        "val_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader  = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "def get_label_distribution(indices):\n",
        "    labels = [data_list[i][1] for i in indices]\n",
        "    return Counter(labels)\n",
        "\n",
        "print(\"Train distribution:\", get_label_distribution(train_indices))\n",
        "print(\"Val distribution:\", get_label_distribution(val_indices))\n",
        "print(\"Test distribution:\", get_label_distribution(test_indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTH5m7jHMjD9"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Attention / helper layers\n",
        "# -------------------------\n",
        "class ChannelAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Expects x shape = (batch, channels, seq_len)\n",
        "    \"\"\"\n",
        "    def __init__(self, channels, ratio=8):\n",
        "        super().__init__()\n",
        "        mid = max(1, channels // ratio)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(channels, mid, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(mid, channels, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, L)\n",
        "        avg_pool = torch.mean(x, dim=2)           # (B, C)\n",
        "        max_pool, _ = torch.max(x, dim=2)         # (B, C)\n",
        "        avg_out = self.mlp(avg_pool)              # (B, C)\n",
        "        max_out = self.mlp(max_pool)              # (B, C)\n",
        "        att = torch.sigmoid(avg_out + max_out)    # (B, C)\n",
        "        att = att.unsqueeze(2)                    # (B, C, 1)\n",
        "        return x * att                             # broadcast multiply -> (B, C, L)\n",
        "\n",
        "\n",
        "class SegmentAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Input: (batch, time_steps, input_dim)\n",
        "    Produces: (batch, input_dim), (batch, time_steps)  (output vector, alphas)\n",
        "    `units` is the hidden size of the attention MLP (same as original design).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, units):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_dim, units, bias=True) \n",
        "        # u vector for scoring\n",
        "        self.u = nn.Parameter(torch.randn(units))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # inputs: (B, T, D)\n",
        "        v = torch.tanh(self.linear(inputs))           # (B, T, units)\n",
        "        # score each time step\n",
        "        vu = torch.matmul(v, self.u)                  # (B, T)\n",
        "        alphas = F.softmax(vu, dim=1)                 # softmax over time dimension\n",
        "        output = torch.sum(inputs * alphas.unsqueeze(-1), dim=1)  # (B, D)\n",
        "        return output, alphas\n",
        "\n",
        "\n",
        "class TimeDistributedSegmentAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    inputs: (B, segments, seg_len, feature_dim)\n",
        "    returns: (B, segments, feature_dim), (B, segments, seg_len)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, units):\n",
        "        super().__init__()\n",
        "        self.segment_attention = SegmentAttention(input_dim, units)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # inputs: (B, S, T, D)\n",
        "        B, S, T, D = inputs.shape\n",
        "        flat = inputs.view(B * S, T, D)                       # (B*S, T, D)\n",
        "        outputs, alphas = self.segment_attention(flat)        # (B*S, D), (B*S, T)\n",
        "        outputs = outputs.view(B, S, D)                       # (B, S, D)\n",
        "        alphas = alphas.view(B, S, T)                         # (B, S, T)\n",
        "        return outputs, alphas\n",
        "\n",
        "\n",
        "class HANWithAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes,\n",
        "        conv_channels=128,\n",
        "        segment_hidden=256,\n",
        "        sequence_hidden=512,\n",
        "        fc_hidden=2048,\n",
        "        dropout=0.4,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1D conv over 12 leads\n",
        "        self.conv1d = nn.Conv1d(12, conv_channels, kernel_size=25, padding=12)\n",
        "        self.channel_attention = ChannelAttention(conv_channels, ratio=8)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Beat-level LSTM\n",
        "        self.lstm_segment = nn.LSTM(\n",
        "            input_size=conv_channels,\n",
        "            hidden_size=segment_hidden,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.time_distributed_attention = TimeDistributedSegmentAttention(\n",
        "            segment_hidden,\n",
        "            segment_hidden\n",
        "        )\n",
        "\n",
        "        # Sequence-level LSTM\n",
        "        self.lstm_sequence = nn.LSTM(\n",
        "            input_size=segment_hidden,\n",
        "            hidden_size=sequence_hidden,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.final_attention = SegmentAttention(sequence_hidden, sequence_hidden)\n",
        "\n",
        "        self.fc = nn.Linear(sequence_hidden, fc_hidden)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(fc_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits, _, _ = self.forward_with_attention(x)\n",
        "        return logits\n",
        "\n",
        "    def forward_with_attention(self, x):\n",
        "        # x: (B, S, T, C) = (batch, beats, time, leads)\n",
        "        B, S, T, C = x.shape\n",
        "\n",
        "        # process beats individually: (B*S, C, T)\n",
        "        x = x.view(B * S, T, C).permute(0, 2, 1)\n",
        "\n",
        "        conv = self.conv1d(x)\n",
        "        att  = self.channel_attention(conv)\n",
        "        pooled = self.pool(att).permute(0, 2, 1)     # (B*S, T2, conv_channels)\n",
        "\n",
        "        seg_out, _ = self.lstm_segment(pooled)       # (B*S, T2, segment_hidden)\n",
        "\n",
        "        # regroup beats: (B, S, T2, segment_hidden)\n",
        "        seg_out = seg_out.view(B, S, seg_out.shape[1], seg_out.shape[2])\n",
        "\n",
        "        # TimeDistributed attention over each beat\n",
        "        seg_feats, seg_alphas = self.time_distributed_attention(seg_out)  # (B,S,segment_hidden)\n",
        "\n",
        "        # Sequence-level LSTM over beats\n",
        "        seq_out, _ = self.lstm_sequence(seg_feats)                        # (B,S,sequence_hidden)\n",
        "        final_vec, final_alphas = self.final_attention(seq_out)           # (B,sequence_hidden), (B,S)\n",
        "\n",
        "        x = F.relu(self.fc(final_vec))\n",
        "        x = self.dropout(x)\n",
        "        logits = self.classifier(x)                                       # (B,C)\n",
        "        return logits, final_alphas, seg_alphas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEp5ILUE8CqG",
        "outputId": "d1c661de-81a0-4011-a6e2-df5611652d0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================================================================================================\n",
              "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Trainable\n",
              "=================================================================================================================================================\n",
              "HANWithAttention                              [2, 10, 300, 12]          [2, 11]                   --                        True\n",
              "├─Conv1d: 1-1                                 [20, 12, 300]             [20, 128, 300]            38,528                    True\n",
              "├─ChannelAttention: 1-2                       [20, 128, 300]            [20, 128, 300]            --                        True\n",
              "│    └─Sequential: 2-1                        [20, 128]                 [20, 128]                 --                        True\n",
              "│    │    └─Linear: 3-1                       [20, 128]                 [20, 16]                  2,064                     True\n",
              "│    │    └─ReLU: 3-2                         [20, 16]                  [20, 16]                  --                        --\n",
              "│    │    └─Linear: 3-3                       [20, 16]                  [20, 128]                 2,176                     True\n",
              "│    └─Sequential: 2-2                        [20, 128]                 [20, 128]                 (recursive)               True\n",
              "│    │    └─Linear: 3-4                       [20, 128]                 [20, 16]                  (recursive)               True\n",
              "│    │    └─ReLU: 3-5                         [20, 16]                  [20, 16]                  --                        --\n",
              "│    │    └─Linear: 3-6                       [20, 16]                  [20, 128]                 (recursive)               True\n",
              "├─MaxPool1d: 1-3                              [20, 128, 300]            [20, 128, 150]            --                        --\n",
              "├─LSTM: 1-4                                   [20, 150, 128]            [20, 150, 128]            132,096                   True\n",
              "├─TimeDistributedSegmentAttention: 1-5        [2, 10, 150, 128]         [2, 10, 128]              --                        True\n",
              "│    └─SegmentAttention: 2-3                  [20, 150, 128]            [20, 128]                 128                       True\n",
              "│    │    └─Linear: 3-7                       [20, 150, 128]            [20, 150, 128]            16,512                    True\n",
              "├─LSTM: 1-6                                   [2, 10, 128]              [2, 10, 512]              1,314,816                 True\n",
              "├─SegmentAttention: 1-7                       [2, 10, 512]              [2, 512]                  512                       True\n",
              "│    └─Linear: 2-4                            [2, 10, 512]              [2, 10, 512]              262,656                   True\n",
              "├─Linear: 1-8                                 [2, 512]                  [2, 512]                  262,656                   True\n",
              "├─Dropout: 1-9                                [2, 512]                  [2, 512]                  --                        --\n",
              "├─Linear: 1-10                                [2, 512]                  [2, 11]                   5,643                     True\n",
              "=================================================================================================================================================\n",
              "Total params: 2,037,787\n",
              "Trainable params: 2,037,787\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 655.31\n",
              "=================================================================================================================================================\n",
              "Input size (MB): 0.29\n",
              "Forward/backward pass size (MB): 12.51\n",
              "Params size (MB): 8.15\n",
              "Estimated Total Size (MB): 20.94\n",
              "================================================================================================================================================="
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = HANWithAttention(num_classes=11,\n",
        "                          conv_channels=128,\n",
        "                          segment_hidden=128,\n",
        "                          sequence_hidden=512,\n",
        "                          fc_hidden=512,\n",
        "                          dropout=0.3).to(device)\n",
        "\n",
        "summary(model,\n",
        "        input_size=(2, 10, 300, 12),    # (batch, segments, timesteps, channels)\n",
        "        col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n",
        "        depth=4,\n",
        "        device=device.type)            # \"cpu\" or \"cuda\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZstNbOkxMugd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_metrics(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_labels, all_preds, all_probs = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            inputs = batch[\"signal\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "            labels = labels.cpu().numpy()\n",
        "\n",
        "            all_labels.extend(labels)\n",
        "            all_preds.extend(preds)\n",
        "            all_probs.extend(probs)\n",
        "\n",
        "    avg_loss = running_loss / len(all_labels)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "\n",
        "    try:\n",
        "      y_true = np.eye(num_classes)[all_labels]\n",
        "      y_score = np.array(all_probs)\n",
        "\n",
        "      auc_list = []\n",
        "      for i in range(num_classes):\n",
        "          if np.any(y_true[:, i]):  # class i exists\n",
        "              auc_list.append(roc_auc_score(y_true[:, i], y_score[:, i]))\n",
        "      if auc_list:\n",
        "          auc = np.mean(auc_list)\n",
        "      else:\n",
        "          auc = float(\"nan\")\n",
        "    except ValueError:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return avg_loss, acc, precision, recall, auc, f1\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer, criterion, device,\n",
        "          epochs, scheduler=None):\n",
        "    model.to(device)\n",
        "    history = {\n",
        "        \"train_loss\": [], \"train_acc\": [], \"train_f1\": [], \"train_precision\": [], \"train_recall\": [], \"train_auc\": [],\n",
        "        \"val_loss\": [],   \"val_acc\": [],   \"val_f1\": [],   \"val_precision\": [],   \"val_recall\": [], \"val_auc\": []\n",
        "    }\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        all_preds = []\n",
        "        all_probs = []\n",
        "        all_labels = []\n",
        "        steps = 0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False)\n",
        "        for batch in loop:\n",
        "            inputs = batch[\"signal\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_size = labels.size(0)\n",
        "            running_loss += loss.item() * batch_size\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            probs = torch.softmax(outputs, dim=1).detach().cpu().numpy()\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += batch_size\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy().tolist())\n",
        "            all_probs.extend(probs.tolist())\n",
        "            all_labels.extend(labels.cpu().numpy().tolist())\n",
        "\n",
        "            steps += 1\n",
        "            loop.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{(correct/total):.4f}\")\n",
        "\n",
        "        if scheduler is not None:\n",
        "            try:\n",
        "                scheduler.step()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # if statement is kinda useless\n",
        "        if total == 0:\n",
        "            epoch_loss = float(\"nan\")\n",
        "            epoch_acc = float(\"nan\")\n",
        "            epoch_precision = epoch_recall = epoch_f1 = float(\"nan\")\n",
        "        else:\n",
        "            epoch_loss = running_loss / total\n",
        "            epoch_acc = correct / total\n",
        "            epoch_precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "            epoch_recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "            epoch_f1 = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "            try:\n",
        "              y_true = np.eye(num_classes)[all_labels]\n",
        "              y_score = np.array(all_probs)\n",
        "\n",
        "              auc_list = []\n",
        "              for i in range(num_classes):\n",
        "                  if np.any(y_true[:, i]):\n",
        "                      auc_list.append(roc_auc_score(y_true[:, i], y_score[:, i]))\n",
        "              if auc_list:\n",
        "                  auc = np.mean(auc_list)\n",
        "              else:\n",
        "                  auc = float(\"nan\")\n",
        "            except ValueError:\n",
        "                auc = float(\"nan\")\n",
        "\n",
        "        # append train history\n",
        "        history[\"train_loss\"].append(epoch_loss)\n",
        "        history[\"train_auc\"].append(auc)\n",
        "        history[\"train_acc\"].append(epoch_acc)\n",
        "        history[\"train_precision\"].append(epoch_precision)\n",
        "        history[\"train_recall\"].append(epoch_recall)\n",
        "        history[\"train_f1\"].append(epoch_f1)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{epochs}  train_loss: {epoch_loss:.4f}  train_acc: {epoch_acc:.4f}  train_f1: {epoch_f1:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        if val_loader is not None:\n",
        "            vloss, vacc, vprecision, vrecall, vauc, vf1 = evaluate_metrics(model, val_loader, criterion, device)\n",
        "            history[\"val_loss\"].append(vloss)\n",
        "            history[\"val_acc\"].append(vacc)\n",
        "            history[\"val_auc\"].append(vauc)\n",
        "            history[\"val_f1\"].append(vf1)\n",
        "            history[\"val_precision\"].append(vprecision)\n",
        "            history[\"val_recall\"].append(vrecall)\n",
        "\n",
        "\n",
        "            # log per-epoch metrics to mlflow if available\n",
        "            if 'mlflow' in globals():\n",
        "                try:\n",
        "                    mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
        "                    mlflow.log_metric(\"train_f1\", epoch_f1, step=epoch)\n",
        "                    mlflow.log_metric(\"train_precision\", epoch_precision, step=epoch)\n",
        "                    mlflow.log_metric(\"train_recall\", epoch_recall, step=epoch)\n",
        "                    mlflow.log_metric(\"train_acc\", epoch_acc, step=epoch)\n",
        "                    mlflow.log_metric(\"train_auc\", auc, step=epoch)\n",
        "\n",
        "                    mlflow.log_metric(\"val_loss\", vloss, step=epoch)\n",
        "                    mlflow.log_metric(\"val_f1\", vf1, step=epoch)\n",
        "                    mlflow.log_metric(\"val_precision\", vprecision, step=epoch)\n",
        "                    mlflow.log_metric(\"val_recall\", vrecall, step=epoch)\n",
        "                    mlflow.log_metric(\"val_acc\", vacc, step=epoch)\n",
        "                    mlflow.log_metric(\"val_auc\", vauc, step=epoch)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            tqdm.write(\n",
        "                f\"Epoch {epoch}  train_loss {epoch_loss:.4f} | val_loss {vloss:.4f} | \"\n",
        "                f\"val_f1 {vf1:.4f} | val_precision {vprecision:.4f} | val_recall {vrecall:.4f} | val_auc {vauc:.4f}\"\n",
        "            )\n",
        "        else:\n",
        "            # keep consistent history lengths\n",
        "            history[\"val_loss\"].append(None)\n",
        "            history[\"val_auc\"].append(None)\n",
        "            history[\"val_acc\"].append(None)\n",
        "            history[\"val_f1\"].append(None)\n",
        "            history[\"val_precision\"].append(None)\n",
        "            history[\"val_recall\"].append(None)\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKHGeA-VQrON"
      },
      "source": [
        "# -------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y69phNTc0vxd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "def run_experiments(model_fn,\n",
        "                    optimizer_fn, criterion, device, epochs, num_classes,\n",
        "                    seeds=10):\n",
        "\n",
        "  results = {\"acc\": [], \"precision\": [], \"recall\": [], \"auc\": [], \"loss\": [], \"f1\": []}\n",
        "  print(\"run exp\")\n",
        "  for seed in range(seeds):\n",
        "      print(f\"\\n=== Seed {seed} ===\")\n",
        "      set_seed(seed)\n",
        "\n",
        "      all_indices = list(range(len(ds)))\n",
        "      all_labels = [data_list[i][1] for i in all_indices]  # label_idx for each sample\n",
        "\n",
        "      trainval_indices, test_indices = train_test_split(\n",
        "          all_indices,\n",
        "          test_size=0.1,\n",
        "          random_state=seed,\n",
        "          stratify=all_labels  # ← stratify by class labels\n",
        "      )\n",
        "\n",
        "      # Extract labels for the trainval subset\n",
        "      trainval_labels = [all_labels[i] for i in trainval_indices]\n",
        "\n",
        "      # Second split: train vs val (stratified)\n",
        "      train_indices, val_indices = train_test_split(\n",
        "          trainval_indices,\n",
        "          test_size=0.1,\n",
        "          random_state=seed,\n",
        "          stratify=trainval_labels  # ← stratify by class labels\n",
        "      )\n",
        "\n",
        "      # -------------------------\n",
        "      # Create Subsets\n",
        "      # -------------------------\n",
        "      train_ds = Subset(ds, train_indices)\n",
        "      val_ds   = Subset(ds, val_indices)\n",
        "      test_ds  = Subset(ds, test_indices)\n",
        "\n",
        "      train_loader = make_loader(train_ds, batch_size=BATCH_SIZE)\n",
        "      val_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "      test_loader  = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "      print(\"Train distribution:\", get_label_distribution(train_indices))\n",
        "      print(\"Val distribution:\", get_label_distribution(val_indices))\n",
        "      print(\"Test distribution:\", get_label_distribution(test_indices))\n",
        "\n",
        "      model = model_fn().to(device)\n",
        "      optimizer = optimizer_fn(model)\n",
        "      scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "      # Train\n",
        "      with mlflow.start_run(nested=True, run_name=f\"HAN-SPH-ABL-SEED-{seed}\"):\n",
        "        _ = train(model, train_loader, val_loader, optimizer, criterion, device, epochs, scheduler)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        loss, acc, precision, recall, auc, f1 = evaluate_metrics(model, test_loader, criterion, device)\n",
        "\n",
        "        print(f\"Test (seed {seed}) — loss: {loss:.4f}, acc: {acc:.4f}, \"\n",
        "            f\"precision: {precision:.4f}, recall: {recall:.4f}, auc: {auc:.4f}, f1: {f1:.4f}\")\n",
        "\n",
        "      results[\"loss\"].append(loss)\n",
        "      results[\"acc\"].append(acc)\n",
        "      results[\"precision\"].append(precision)\n",
        "      results[\"recall\"].append(recall)\n",
        "      results[\"auc\"].append(auc)\n",
        "      results[\"f1\"].append(f1)\n",
        "\n",
        "  # Aggregate results\n",
        "  print(\"\\n=== Final Results (across seeds) ===\")\n",
        "  for k, v in results.items():\n",
        "      arr = np.array(v, dtype=np.float32)\n",
        "      print(f\"{k}: mean={arr.mean():.4f}, std={arr.std():.4f}\")\n",
        "\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76xZ_p8601Es"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  return HANWithAttention(num_classes=num_classes,\n",
        "                            conv_channels=128,\n",
        "                            segment_hidden=128,\n",
        "                            sequence_hidden=512,\n",
        "                            fc_hidden=512,\n",
        "                            dropout=0.3)\n",
        "\n",
        "def optimizer_fn(model):\n",
        "  return torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=9e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxs3CDseTbSz",
        "outputId": "a2f13055-5aa0-4b2a-8141-b15d4f3fab12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run exp\n",
            "\n",
            "=== Seed 0 ===\n",
            "Train distribution: Counter({0: 11261, 1: 2116, 9: 1234, 5: 1081, 3: 426, 2: 397, 6: 149, 7: 134, 10: 45, 4: 21, 8: 19})\n",
            "Val distribution: Counter({0: 1251, 1: 235, 9: 137, 5: 120, 3: 48, 2: 44, 6: 17, 7: 15, 10: 5, 8: 2, 4: 2})\n",
            "Test distribution: Counter({0: 1391, 1: 261, 9: 152, 5: 133, 3: 53, 2: 49, 6: 19, 7: 16, 10: 6, 4: 3, 8: 2})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25  train_loss: 1.2101  train_acc: 0.6697  train_f1: 0.5388\n",
            "Epoch 1  train_loss 1.2101 | val_loss 1.1414 | val_f1 0.5548 | val_precision 0.4670 | val_recall 0.6834 | val_auc 0.5851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/25  train_loss: 1.0983  train_acc: 0.6742  train_f1: 0.5710\n",
            "Epoch 2  train_loss 1.0983 | val_loss 0.9845 | val_f1 0.6012 | val_precision 0.6440 | val_recall 0.7075 | val_auc 0.6895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/25  train_loss: 0.9890  train_acc: 0.7055  train_f1: 0.6338\n",
            "Epoch 3  train_loss 0.9890 | val_loss 0.9125 | val_f1 0.6721 | val_precision 0.6433 | val_recall 0.7229 | val_auc 0.7486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/25  train_loss: 0.8913  train_acc: 0.7370  train_f1: 0.6890\n",
            "Epoch 4  train_loss 0.8913 | val_loss 0.7699 | val_f1 0.7335 | val_precision 0.7415 | val_recall 0.7718 | val_auc 0.7972\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/25  train_loss: 0.7846  train_acc: 0.7619  train_f1: 0.7258\n",
            "Epoch 5  train_loss 0.7846 | val_loss 0.6906 | val_f1 0.7458 | val_precision 0.7747 | val_recall 0.7866 | val_auc 0.8511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/25  train_loss: 0.6710  train_acc: 0.7917  train_f1: 0.7636\n",
            "Epoch 6  train_loss 0.6710 | val_loss 0.6552 | val_f1 0.7602 | val_precision 0.7678 | val_recall 0.7907 | val_auc 0.8263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/25  train_loss: 0.6411  train_acc: 0.7975  train_f1: 0.7724\n",
            "Epoch 7  train_loss 0.6411 | val_loss 0.6780 | val_f1 0.7691 | val_precision 0.7710 | val_recall 0.7883 | val_auc 0.8424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/25  train_loss: 0.6058  train_acc: 0.8026  train_f1: 0.7795\n",
            "Epoch 8  train_loss 0.6058 | val_loss 0.6256 | val_f1 0.7649 | val_precision 0.7755 | val_recall 0.7948 | val_auc 0.8459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/25  train_loss: 0.5818  train_acc: 0.8078  train_f1: 0.7872\n",
            "Epoch 9  train_loss 0.5818 | val_loss 0.5944 | val_f1 0.7784 | val_precision 0.7788 | val_recall 0.7995 | val_auc 0.8607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/25  train_loss: 0.5557  train_acc: 0.8135  train_f1: 0.7949\n",
            "Epoch 10  train_loss 0.5557 | val_loss 0.5845 | val_f1 0.7663 | val_precision 0.7918 | val_recall 0.7989 | val_auc 0.8796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/25  train_loss: 0.4995  train_acc: 0.8316  train_f1: 0.8160\n",
            "Epoch 11  train_loss 0.4995 | val_loss 0.5428 | val_f1 0.7941 | val_precision 0.7938 | val_recall 0.8149 | val_auc 0.8908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/25  train_loss: 0.4775  train_acc: 0.8355  train_f1: 0.8219\n",
            "Epoch 12  train_loss 0.4775 | val_loss 0.5388 | val_f1 0.8026 | val_precision 0.8033 | val_recall 0.8154 | val_auc 0.8957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/25  train_loss: 0.4551  train_acc: 0.8423  train_f1: 0.8312\n",
            "Epoch 13  train_loss 0.4551 | val_loss 0.5410 | val_f1 0.8045 | val_precision 0.8063 | val_recall 0.8184 | val_auc 0.9007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/25  train_loss: 0.4474  train_acc: 0.8490  train_f1: 0.8387\n",
            "Epoch 14  train_loss 0.4474 | val_loss 0.5180 | val_f1 0.8145 | val_precision 0.8118 | val_recall 0.8272 | val_auc 0.9011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/25  train_loss: 0.4280  train_acc: 0.8516  train_f1: 0.8429\n",
            "Epoch 15  train_loss 0.4280 | val_loss 0.5067 | val_f1 0.8092 | val_precision 0.8099 | val_recall 0.8225 | val_auc 0.9101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/25  train_loss: 0.3837  train_acc: 0.8684  train_f1: 0.8612\n",
            "Epoch 16  train_loss 0.3837 | val_loss 0.5277 | val_f1 0.8235 | val_precision 0.8245 | val_recall 0.8337 | val_auc 0.9192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/25  train_loss: 0.3661  train_acc: 0.8724  train_f1: 0.8656\n",
            "Epoch 17  train_loss 0.3661 | val_loss 0.5292 | val_f1 0.8225 | val_precision 0.8207 | val_recall 0.8314 | val_auc 0.9144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/25  train_loss: 0.3568  train_acc: 0.8756  train_f1: 0.8701\n",
            "Epoch 18  train_loss 0.3568 | val_loss 0.5266 | val_f1 0.8280 | val_precision 0.8276 | val_recall 0.8355 | val_auc 0.9141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/25  train_loss: 0.3432  train_acc: 0.8805  train_f1: 0.8754\n",
            "Epoch 19  train_loss 0.3432 | val_loss 0.5260 | val_f1 0.8216 | val_precision 0.8187 | val_recall 0.8296 | val_auc 0.9174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/25  train_loss: 0.3301  train_acc: 0.8860  train_f1: 0.8808\n",
            "Epoch 20  train_loss 0.3301 | val_loss 0.5380 | val_f1 0.8279 | val_precision 0.8310 | val_recall 0.8355 | val_auc 0.9230\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/25  train_loss: 0.2941  train_acc: 0.9004  train_f1: 0.8968\n",
            "Epoch 21  train_loss 0.2941 | val_loss 0.5613 | val_f1 0.8214 | val_precision 0.8217 | val_recall 0.8272 | val_auc 0.9224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/25  train_loss: 0.2821  train_acc: 0.9036  train_f1: 0.9002\n",
            "Epoch 22  train_loss 0.2821 | val_loss 0.5552 | val_f1 0.8245 | val_precision 0.8226 | val_recall 0.8302 | val_auc 0.9248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/25  train_loss: 0.2717  train_acc: 0.9080  train_f1: 0.9049\n",
            "Epoch 23  train_loss 0.2717 | val_loss 0.5793 | val_f1 0.8192 | val_precision 0.8174 | val_recall 0.8243 | val_auc 0.9297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/25  train_loss: 0.2606  train_acc: 0.9118  train_f1: 0.9089\n",
            "Epoch 24  train_loss 0.2606 | val_loss 0.5770 | val_f1 0.8195 | val_precision 0.8200 | val_recall 0.8231 | val_auc 0.9227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/25  train_loss: 0.2499  train_acc: 0.9168  train_f1: 0.9141\n",
            "Epoch 25  train_loss 0.2499 | val_loss 0.5969 | val_f1 0.8160 | val_precision 0.8147 | val_recall 0.8213 | val_auc 0.9227\n",
            "Test (seed 0) — loss: 0.5425, acc: 0.8464, precision: 0.8380, recall: 0.8464, auc: 0.8864, f1: 0.8405\n",
            "🏃 View run HAN-SPH-ABL-SEED-0 at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740/runs/b69fd84bbc234bcbb9b97892f55dc2b7\n",
            "🧪 View experiment at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740\n",
            "\n",
            "=== Seed 1 ===\n",
            "Train distribution: Counter({0: 11261, 1: 2116, 9: 1234, 5: 1081, 3: 426, 2: 397, 6: 149, 7: 134, 10: 45, 4: 21, 8: 19})\n",
            "Val distribution: Counter({0: 1251, 1: 235, 9: 137, 5: 120, 3: 48, 2: 44, 6: 17, 7: 15, 10: 5, 4: 2, 8: 2})\n",
            "Test distribution: Counter({0: 1391, 1: 261, 9: 152, 5: 133, 3: 53, 2: 49, 6: 19, 7: 16, 10: 6, 4: 3, 8: 2})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25  train_loss: 1.1999  train_acc: 0.6707  train_f1: 0.5448\n",
            "Epoch 1  train_loss 1.1999 | val_loss 1.1019 | val_f1 0.5362 | val_precision 0.4474 | val_recall 0.6689 | val_auc 0.7141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/25  train_loss: 1.0641  train_acc: 0.6872  train_f1: 0.6041\n",
            "Epoch 2  train_loss 1.0641 | val_loss 0.9631 | val_f1 0.6689 | val_precision 0.6802 | val_recall 0.7194 | val_auc 0.7525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/25  train_loss: 0.8936  train_acc: 0.7249  train_f1: 0.6741\n",
            "Epoch 3  train_loss 0.8936 | val_loss 0.8112 | val_f1 0.7026 | val_precision 0.6962 | val_recall 0.7416 | val_auc 0.8156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/25  train_loss: 0.8087  train_acc: 0.7496  train_f1: 0.7053\n",
            "Epoch 4  train_loss 0.8087 | val_loss 0.7653 | val_f1 0.7086 | val_precision 0.7203 | val_recall 0.7632 | val_auc 0.8498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/25  train_loss: 0.7753  train_acc: 0.7625  train_f1: 0.7212\n",
            "Epoch 5  train_loss 0.7753 | val_loss 0.7635 | val_f1 0.7208 | val_precision 0.7421 | val_recall 0.7584 | val_auc 0.8694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/25  train_loss: 0.6911  train_acc: 0.7806  train_f1: 0.7469\n",
            "Epoch 6  train_loss 0.6911 | val_loss 0.6585 | val_f1 0.7680 | val_precision 0.7609 | val_recall 0.7885 | val_auc 0.8985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/25  train_loss: 0.6503  train_acc: 0.7944  train_f1: 0.7654\n",
            "Epoch 7  train_loss 0.6503 | val_loss 0.5953 | val_f1 0.7781 | val_precision 0.7730 | val_recall 0.7999 | val_auc 0.8920\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/25  train_loss: 0.6146  train_acc: 0.7988  train_f1: 0.7731\n",
            "Epoch 8  train_loss 0.6146 | val_loss 0.6111 | val_f1 0.7719 | val_precision 0.7756 | val_recall 0.7987 | val_auc 0.9142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/25  train_loss: 0.5976  train_acc: 0.8057  train_f1: 0.7831\n",
            "Epoch 9  train_loss 0.5976 | val_loss 0.5786 | val_f1 0.7790 | val_precision 0.7987 | val_recall 0.8089 | val_auc 0.9058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/25  train_loss: 0.5687  train_acc: 0.8138  train_f1: 0.7932\n",
            "Epoch 10  train_loss 0.5687 | val_loss 0.5507 | val_f1 0.7954 | val_precision 0.8032 | val_recall 0.8173 | val_auc 0.9259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/25  train_loss: 0.5166  train_acc: 0.8254  train_f1: 0.8086\n",
            "Epoch 11  train_loss 0.5166 | val_loss 0.5393 | val_f1 0.8000 | val_precision 0.8075 | val_recall 0.8173 | val_auc 0.9205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/25  train_loss: 0.4966  train_acc: 0.8323  train_f1: 0.8179\n",
            "Epoch 12  train_loss 0.4966 | val_loss 0.5425 | val_f1 0.7787 | val_precision 0.7835 | val_recall 0.7999 | val_auc 0.9237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/25  train_loss: 0.4821  train_acc: 0.8352  train_f1: 0.8220\n",
            "Epoch 13  train_loss 0.4821 | val_loss 0.5149 | val_f1 0.8072 | val_precision 0.8153 | val_recall 0.8227 | val_auc 0.9210\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/25  train_loss: 0.4650  train_acc: 0.8427  train_f1: 0.8306\n",
            "Epoch 14  train_loss 0.4650 | val_loss 0.5134 | val_f1 0.8059 | val_precision 0.8165 | val_recall 0.8251 | val_auc 0.9234\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/25  train_loss: 0.4481  train_acc: 0.8442  train_f1: 0.8332\n",
            "Epoch 15  train_loss 0.4481 | val_loss 0.5051 | val_f1 0.8234 | val_precision 0.8222 | val_recall 0.8353 | val_auc 0.9270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/25  train_loss: 0.4080  train_acc: 0.8591  train_f1: 0.8503\n",
            "Epoch 16  train_loss 0.4080 | val_loss 0.5030 | val_f1 0.8166 | val_precision 0.8194 | val_recall 0.8305 | val_auc 0.9177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/25  train_loss: 0.3868  train_acc: 0.8677  train_f1: 0.8603\n",
            "Epoch 17  train_loss 0.3868 | val_loss 0.5009 | val_f1 0.8212 | val_precision 0.8195 | val_recall 0.8323 | val_auc 0.9323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/25  train_loss: 0.3759  train_acc: 0.8708  train_f1: 0.8636\n",
            "Epoch 18  train_loss 0.3759 | val_loss 0.5140 | val_f1 0.8167 | val_precision 0.8176 | val_recall 0.8287 | val_auc 0.9303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/25  train_loss: 0.3631  train_acc: 0.8777  train_f1: 0.8716\n",
            "Epoch 19  train_loss 0.3631 | val_loss 0.4986 | val_f1 0.8255 | val_precision 0.8222 | val_recall 0.8335 | val_auc 0.9294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/25  train_loss: 0.3522  train_acc: 0.8798  train_f1: 0.8741\n",
            "Epoch 20  train_loss 0.3522 | val_loss 0.5050 | val_f1 0.8192 | val_precision 0.8211 | val_recall 0.8311 | val_auc 0.9324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/25  train_loss: 0.3166  train_acc: 0.8925  train_f1: 0.8872\n",
            "Epoch 21  train_loss 0.3166 | val_loss 0.5236 | val_f1 0.8191 | val_precision 0.8207 | val_recall 0.8281 | val_auc 0.9365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/25  train_loss: 0.3058  train_acc: 0.8960  train_f1: 0.8917\n",
            "Epoch 22  train_loss 0.3058 | val_loss 0.5180 | val_f1 0.8231 | val_precision 0.8219 | val_recall 0.8329 | val_auc 0.9396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/25  train_loss: 0.2932  train_acc: 0.9016  train_f1: 0.8976\n",
            "Epoch 23  train_loss 0.2932 | val_loss 0.5245 | val_f1 0.8195 | val_precision 0.8194 | val_recall 0.8305 | val_auc 0.9443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/25  train_loss: 0.2823  train_acc: 0.9048  train_f1: 0.9012\n",
            "Epoch 24  train_loss 0.2823 | val_loss 0.5417 | val_f1 0.8108 | val_precision 0.8081 | val_recall 0.8179 | val_auc 0.9233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/25  train_loss: 0.2704  train_acc: 0.9089  train_f1: 0.9058\n",
            "Epoch 25  train_loss 0.2704 | val_loss 0.5413 | val_f1 0.8205 | val_precision 0.8185 | val_recall 0.8269 | val_auc 0.9392\n",
            "Test (seed 1) — loss: 0.6467, acc: 0.8098, precision: 0.7984, recall: 0.8098, auc: 0.8627, f1: 0.8019\n",
            "🏃 View run HAN-SPH-ABL-SEED-1 at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740/runs/93e40425d88147a7a8ec39576aac6e74\n",
            "🧪 View experiment at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740\n",
            "\n",
            "=== Seed 2 ===\n",
            "Train distribution: Counter({0: 11261, 1: 2116, 9: 1234, 5: 1081, 3: 426, 2: 397, 6: 149, 7: 134, 10: 45, 4: 21, 8: 19})\n",
            "Val distribution: Counter({0: 1251, 1: 235, 9: 137, 5: 120, 3: 48, 2: 44, 6: 17, 7: 15, 10: 5, 8: 2, 4: 2})\n",
            "Test distribution: Counter({0: 1391, 1: 261, 9: 152, 5: 133, 3: 53, 2: 49, 6: 19, 7: 16, 10: 6, 4: 3, 8: 2})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25  train_loss: 1.1774  train_acc: 0.6750  train_f1: 0.5573\n",
            "Epoch 1  train_loss 1.1774 | val_loss 1.0676 | val_f1 0.5593 | val_precision 0.5044 | val_recall 0.6792 | val_auc 0.6438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/25  train_loss: 0.9889  train_acc: 0.7040  train_f1: 0.6174\n",
            "Epoch 2  train_loss 0.9889 | val_loss 0.8780 | val_f1 0.6547 | val_precision 0.6487 | val_recall 0.7170 | val_auc 0.7647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/25  train_loss: 0.8641  train_acc: 0.7338  train_f1: 0.6755\n",
            "Epoch 3  train_loss 0.8641 | val_loss 0.7853 | val_f1 0.7098 | val_precision 0.7058 | val_recall 0.7500 | val_auc 0.8279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/25  train_loss: 0.7975  train_acc: 0.7517  train_f1: 0.7083\n",
            "Epoch 4  train_loss 0.7975 | val_loss 0.7694 | val_f1 0.7296 | val_precision 0.7430 | val_recall 0.7476 | val_auc 0.8293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/25  train_loss: 0.7419  train_acc: 0.7657  train_f1: 0.7293\n",
            "Epoch 5  train_loss 0.7419 | val_loss 0.6814 | val_f1 0.7263 | val_precision 0.7716 | val_recall 0.7754 | val_auc 0.8506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/25  train_loss: 0.6513  train_acc: 0.7882  train_f1: 0.7577\n",
            "Epoch 6  train_loss 0.6513 | val_loss 0.6316 | val_f1 0.7646 | val_precision 0.7819 | val_recall 0.7907 | val_auc 0.8779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/25  train_loss: 0.6239  train_acc: 0.7986  train_f1: 0.7711\n",
            "Epoch 7  train_loss 0.6239 | val_loss 0.6137 | val_f1 0.7672 | val_precision 0.7891 | val_recall 0.7966 | val_auc 0.8713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/25  train_loss: 0.6011  train_acc: 0.8026  train_f1: 0.7784\n",
            "Epoch 8  train_loss 0.6011 | val_loss 0.6255 | val_f1 0.7657 | val_precision 0.7858 | val_recall 0.7930 | val_auc 0.8823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/25  train_loss: 0.5818  train_acc: 0.8071  train_f1: 0.7840\n",
            "Epoch 9  train_loss 0.5818 | val_loss 0.6100 | val_f1 0.7840 | val_precision 0.7906 | val_recall 0.8084 | val_auc 0.8741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/25  train_loss: 0.5622  train_acc: 0.8127  train_f1: 0.7930\n",
            "Epoch 10  train_loss 0.5622 | val_loss 0.6395 | val_f1 0.7716 | val_precision 0.7918 | val_recall 0.7995 | val_auc 0.8802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/25  train_loss: 0.5082  train_acc: 0.8266  train_f1: 0.8109\n",
            "Epoch 11  train_loss 0.5082 | val_loss 0.5718 | val_f1 0.7949 | val_precision 0.7954 | val_recall 0.8119 | val_auc 0.8760\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/25  train_loss: 0.4826  train_acc: 0.8334  train_f1: 0.8206\n",
            "Epoch 12  train_loss 0.4826 | val_loss 0.5838 | val_f1 0.7882 | val_precision 0.7850 | val_recall 0.8078 | val_auc 0.8850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/25  train_loss: 0.4636  train_acc: 0.8409  train_f1: 0.8290\n",
            "Epoch 13  train_loss 0.4636 | val_loss 0.5438 | val_f1 0.8028 | val_precision 0.8008 | val_recall 0.8178 | val_auc 0.9107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/25  train_loss: 0.4477  train_acc: 0.8462  train_f1: 0.8360\n",
            "Epoch 14  train_loss 0.4477 | val_loss 0.5514 | val_f1 0.7989 | val_precision 0.7929 | val_recall 0.8090 | val_auc 0.8888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/25  train_loss: 0.4303  train_acc: 0.8519  train_f1: 0.8432\n",
            "Epoch 15  train_loss 0.4303 | val_loss 0.5409 | val_f1 0.7957 | val_precision 0.7949 | val_recall 0.8113 | val_auc 0.9004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/25  train_loss: 0.3805  train_acc: 0.8680  train_f1: 0.8614\n",
            "Epoch 16  train_loss 0.3805 | val_loss 0.5487 | val_f1 0.8106 | val_precision 0.8071 | val_recall 0.8213 | val_auc 0.8938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/25  train_loss: 0.3615  train_acc: 0.8744  train_f1: 0.8689\n",
            "Epoch 17  train_loss 0.3615 | val_loss 0.5617 | val_f1 0.8032 | val_precision 0.8026 | val_recall 0.8137 | val_auc 0.9067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/25  train_loss: 0.3427  train_acc: 0.8838  train_f1: 0.8794\n",
            "Epoch 18  train_loss 0.3427 | val_loss 0.5740 | val_f1 0.8101 | val_precision 0.8086 | val_recall 0.8190 | val_auc 0.9008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/25  train_loss: 0.3296  train_acc: 0.8847  train_f1: 0.8805\n",
            "Epoch 19  train_loss 0.3296 | val_loss 0.5767 | val_f1 0.8082 | val_precision 0.8072 | val_recall 0.8208 | val_auc 0.8997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/25  train_loss: 0.3134  train_acc: 0.8916  train_f1: 0.8881\n",
            "Epoch 20  train_loss 0.3134 | val_loss 0.5731 | val_f1 0.8159 | val_precision 0.8141 | val_recall 0.8208 | val_auc 0.8969\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/25  train_loss: 0.2726  train_acc: 0.9079  train_f1: 0.9053\n",
            "Epoch 21  train_loss 0.2726 | val_loss 0.6065 | val_f1 0.8100 | val_precision 0.8079 | val_recall 0.8166 | val_auc 0.9184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/25  train_loss: 0.2533  train_acc: 0.9181  train_f1: 0.9163\n",
            "Epoch 22  train_loss 0.2533 | val_loss 0.6270 | val_f1 0.8081 | val_precision 0.8070 | val_recall 0.8160 | val_auc 0.9177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/25  train_loss: 0.2402  train_acc: 0.9207  train_f1: 0.9190\n",
            "Epoch 23  train_loss 0.2402 | val_loss 0.6404 | val_f1 0.8050 | val_precision 0.8029 | val_recall 0.8143 | val_auc 0.9210\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/25  train_loss: 0.2287  train_acc: 0.9221  train_f1: 0.9206\n",
            "Epoch 24  train_loss 0.2287 | val_loss 0.6674 | val_f1 0.8059 | val_precision 0.8042 | val_recall 0.8143 | val_auc 0.9164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/25  train_loss: 0.2125  train_acc: 0.9282  train_f1: 0.9268\n",
            "Epoch 25  train_loss 0.2125 | val_loss 0.7051 | val_f1 0.8109 | val_precision 0.8072 | val_recall 0.8166 | val_auc 0.9137\n",
            "Test (seed 2) — loss: 0.6838, acc: 0.8199, precision: 0.8128, recall: 0.8199, auc: 0.8849, f1: 0.8137\n",
            "🏃 View run HAN-SPH-ABL-SEED-2 at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740/runs/38152776850c4cd09cd9f3f7885fa80c\n",
            "🧪 View experiment at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740\n",
            "\n",
            "=== Seed 3 ===\n",
            "Train distribution: Counter({0: 11261, 1: 2116, 9: 1234, 5: 1081, 3: 426, 2: 397, 6: 149, 7: 134, 10: 45, 4: 21, 8: 19})\n",
            "Val distribution: Counter({0: 1251, 1: 235, 9: 137, 5: 120, 3: 48, 2: 44, 6: 17, 7: 15, 10: 5, 4: 2, 8: 2})\n",
            "Test distribution: Counter({0: 1391, 1: 261, 9: 152, 5: 133, 3: 53, 2: 49, 6: 19, 7: 16, 10: 6, 4: 3, 8: 2})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25  train_loss: 1.2605  train_acc: 0.6685  train_f1: 0.5392\n",
            "Epoch 1  train_loss 1.2605 | val_loss 1.1843 | val_f1 0.5381 | val_precision 0.4494 | val_recall 0.6704 | val_auc 0.5410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/25  train_loss: 1.1882  train_acc: 0.6711  train_f1: 0.5391\n",
            "Epoch 2  train_loss 1.1882 | val_loss 1.1519 | val_f1 0.5381 | val_precision 0.4494 | val_recall 0.6704 | val_auc 0.6031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/25  train_loss: 1.1660  train_acc: 0.6718  train_f1: 0.5399\n",
            "Epoch 3  train_loss 1.1660 | val_loss 1.1357 | val_f1 0.5381 | val_precision 0.4494 | val_recall 0.6704 | val_auc 0.6490\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/25  train_loss: 1.1579  train_acc: 0.6715  train_f1: 0.5395\n",
            "Epoch 4  train_loss 1.1579 | val_loss 1.1383 | val_f1 0.5381 | val_precision 0.4494 | val_recall 0.6704 | val_auc 0.6273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/25  train_loss: 1.1430  train_acc: 0.6717  train_f1: 0.5401\n",
            "Epoch 5  train_loss 1.1430 | val_loss 1.1238 | val_f1 0.5381 | val_precision 0.4494 | val_recall 0.6704 | val_auc 0.6662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/25  train_loss: 1.1089  train_acc: 0.6710  train_f1: 0.5409\n",
            "Epoch 6  train_loss 1.1089 | val_loss 1.0892 | val_f1 0.5381 | val_precision 0.4494 | val_recall 0.6704 | val_auc 0.6862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/25  train_loss: 1.0924  train_acc: 0.6724  train_f1: 0.5491\n",
            "Epoch 7  train_loss 1.0924 | val_loss 1.0793 | val_f1 0.5699 | val_precision 0.5673 | val_recall 0.6722 | val_auc 0.6859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/25  train_loss: 1.0714  train_acc: 0.6757  train_f1: 0.5683\n",
            "Epoch 8  train_loss 1.0714 | val_loss 1.0320 | val_f1 0.5881 | val_precision 0.6533 | val_recall 0.6869 | val_auc 0.6956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/25  train_loss: 1.0132  train_acc: 0.6902  train_f1: 0.6114\n",
            "Epoch 9  train_loss 1.0132 | val_loss 0.9587 | val_f1 0.6382 | val_precision 0.6584 | val_recall 0.7075 | val_auc 0.7194\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/25  train_loss: 0.9495  train_acc: 0.7104  train_f1: 0.6475\n",
            "Epoch 10  train_loss 0.9495 | val_loss 0.8957 | val_f1 0.6742 | val_precision 0.7009 | val_recall 0.7341 | val_auc 0.7473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/25  train_loss: 0.7994  train_acc: 0.7552  train_f1: 0.7168\n",
            "Epoch 11  train_loss 0.7994 | val_loss 0.7805 | val_f1 0.7342 | val_precision 0.7409 | val_recall 0.7671 | val_auc 0.7797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/25  train_loss: 0.7397  train_acc: 0.7719  train_f1: 0.7424\n",
            "Epoch 12  train_loss 0.7397 | val_loss 0.7430 | val_f1 0.7382 | val_precision 0.7547 | val_recall 0.7742 | val_auc 0.8199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/25  train_loss: 0.7019  train_acc: 0.7815  train_f1: 0.7542\n",
            "Epoch 13  train_loss 0.7019 | val_loss 0.7176 | val_f1 0.7452 | val_precision 0.7510 | val_recall 0.7771 | val_auc 0.8062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/25  train_loss: 0.6621  train_acc: 0.7913  train_f1: 0.7675\n",
            "Epoch 14  train_loss 0.6621 | val_loss 0.6805 | val_f1 0.7582 | val_precision 0.7597 | val_recall 0.7854 | val_auc 0.8171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/25  train_loss: 0.6372  train_acc: 0.7929  train_f1: 0.7699\n",
            "Epoch 15  train_loss 0.6372 | val_loss 0.6867 | val_f1 0.7523 | val_precision 0.7504 | val_recall 0.7718 | val_auc 0.8289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/25  train_loss: 0.5744  train_acc: 0.8121  train_f1: 0.7945\n",
            "Epoch 16  train_loss 0.5744 | val_loss 0.6602 | val_f1 0.7621 | val_precision 0.7628 | val_recall 0.7824 | val_auc 0.8525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/25  train_loss: 0.5514  train_acc: 0.8149  train_f1: 0.7984\n",
            "Epoch 17  train_loss 0.5514 | val_loss 0.6486 | val_f1 0.7750 | val_precision 0.7791 | val_recall 0.7913 | val_auc 0.8542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/25  train_loss: 0.5281  train_acc: 0.8214  train_f1: 0.8074\n",
            "Epoch 18  train_loss 0.5281 | val_loss 0.6250 | val_f1 0.7693 | val_precision 0.7843 | val_recall 0.7930 | val_auc 0.9026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/25  train_loss: 0.5064  train_acc: 0.8286  train_f1: 0.8164\n",
            "Epoch 19  train_loss 0.5064 | val_loss 0.6264 | val_f1 0.7842 | val_precision 0.7934 | val_recall 0.8007 | val_auc 0.8794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/25  train_loss: 0.4916  train_acc: 0.8335  train_f1: 0.8217\n",
            "Epoch 20  train_loss 0.4916 | val_loss 0.6148 | val_f1 0.7901 | val_precision 0.7998 | val_recall 0.8096 | val_auc 0.8924\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/25  train_loss: 0.4426  train_acc: 0.8441  train_f1: 0.8350\n",
            "Epoch 21  train_loss 0.4426 | val_loss 0.6008 | val_f1 0.7944 | val_precision 0.7964 | val_recall 0.8096 | val_auc 0.9154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/25  train_loss: 0.4252  train_acc: 0.8517  train_f1: 0.8437\n",
            "Epoch 22  train_loss 0.4252 | val_loss 0.5987 | val_f1 0.7965 | val_precision 0.7961 | val_recall 0.8072 | val_auc 0.9097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/25  train_loss: 0.4136  train_acc: 0.8548  train_f1: 0.8471\n",
            "Epoch 23  train_loss 0.4136 | val_loss 0.6078 | val_f1 0.7913 | val_precision 0.7949 | val_recall 0.8054 | val_auc 0.9154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/25  train_loss: 0.3951  train_acc: 0.8597  train_f1: 0.8527\n",
            "Epoch 24  train_loss 0.3951 | val_loss 0.6040 | val_f1 0.7957 | val_precision 0.7936 | val_recall 0.8072 | val_auc 0.9185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/25  train_loss: 0.3859  train_acc: 0.8618  train_f1: 0.8553\n",
            "Epoch 25  train_loss 0.3859 | val_loss 0.6086 | val_f1 0.7944 | val_precision 0.7916 | val_recall 0.8007 | val_auc 0.9091\n",
            "Test (seed 3) — loss: 0.5424, acc: 0.8280, precision: 0.8189, recall: 0.8280, auc: 0.8939, f1: 0.8219\n",
            "🏃 View run HAN-SPH-ABL-SEED-3 at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740/runs/a0d8ef81651b41c88d49a6101bfcb0a0\n",
            "🧪 View experiment at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740\n",
            "\n",
            "=== Seed 4 ===\n",
            "Train distribution: Counter({0: 11261, 1: 2116, 9: 1234, 5: 1081, 3: 426, 2: 397, 6: 149, 7: 134, 10: 45, 4: 21, 8: 19})\n",
            "Val distribution: Counter({0: 1251, 1: 235, 9: 137, 5: 120, 3: 48, 2: 44, 6: 17, 7: 15, 10: 5, 4: 2, 8: 2})\n",
            "Test distribution: Counter({0: 1391, 1: 261, 9: 152, 5: 133, 3: 53, 2: 49, 6: 19, 7: 16, 10: 6, 4: 3, 8: 2})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25  train_loss: 1.1152  train_acc: 0.6794  train_f1: 0.5789\n",
            "Epoch 1  train_loss 1.1152 | val_loss 0.9968 | val_f1 0.5857 | val_precision 0.5480 | val_recall 0.6987 | val_auc 0.7024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/25  train_loss: 0.8987  train_acc: 0.7231  train_f1: 0.6669\n",
            "Epoch 2  train_loss 0.8987 | val_loss 0.8613 | val_f1 0.6560 | val_precision 0.7280 | val_recall 0.7258 | val_auc 0.8213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/25  train_loss: 0.8248  train_acc: 0.7483  train_f1: 0.7037\n",
            "Epoch 3  train_loss 0.8248 | val_loss 0.7724 | val_f1 0.7209 | val_precision 0.7255 | val_recall 0.7594 | val_auc 0.8484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/25  train_loss: 0.7774  train_acc: 0.7615  train_f1: 0.7201\n",
            "Epoch 4  train_loss 0.7774 | val_loss 0.7765 | val_f1 0.7345 | val_precision 0.7451 | val_recall 0.7636 | val_auc 0.8662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/25  train_loss: 0.7585  train_acc: 0.7678  train_f1: 0.7285\n",
            "Epoch 5  train_loss 0.7585 | val_loss 0.7974 | val_f1 0.7221 | val_precision 0.7349 | val_recall 0.7518 | val_auc 0.8683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/25  train_loss: 0.6874  train_acc: 0.7836  train_f1: 0.7505\n",
            "Epoch 6  train_loss 0.6874 | val_loss 0.6945 | val_f1 0.7457 | val_precision 0.7955 | val_recall 0.7877 | val_auc 0.8786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/25  train_loss: 0.6557  train_acc: 0.7925  train_f1: 0.7633\n",
            "Epoch 7  train_loss 0.6557 | val_loss 0.6618 | val_f1 0.7649 | val_precision 0.7755 | val_recall 0.7960 | val_auc 0.8857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/25  train_loss: 0.6224  train_acc: 0.7983  train_f1: 0.7744\n",
            "Epoch 8  train_loss 0.6224 | val_loss 0.6228 | val_f1 0.7676 | val_precision 0.7776 | val_recall 0.7972 | val_auc 0.9132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/25  train_loss: 0.6018  train_acc: 0.8035  train_f1: 0.7822\n",
            "Epoch 9  train_loss 0.6018 | val_loss 0.6094 | val_f1 0.7690 | val_precision 0.7748 | val_recall 0.7960 | val_auc 0.9190\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/25  train_loss: 0.5773  train_acc: 0.8112  train_f1: 0.7931\n",
            "Epoch 10  train_loss 0.5773 | val_loss 0.6036 | val_f1 0.7742 | val_precision 0.7817 | val_recall 0.8019 | val_auc 0.9159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/25  train_loss: 0.5279  train_acc: 0.8253  train_f1: 0.8096\n",
            "Epoch 11  train_loss 0.5279 | val_loss 0.5512 | val_f1 0.7930 | val_precision 0.8030 | val_recall 0.8149 | val_auc 0.9396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/25  train_loss: 0.5085  train_acc: 0.8283  train_f1: 0.8136\n",
            "Epoch 12  train_loss 0.5085 | val_loss 0.5595 | val_f1 0.7947 | val_precision 0.7994 | val_recall 0.8143 | val_auc 0.9366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/25  train_loss: 0.4910  train_acc: 0.8358  train_f1: 0.8231\n",
            "Epoch 13  train_loss 0.4910 | val_loss 0.5408 | val_f1 0.8042 | val_precision 0.7993 | val_recall 0.8219 | val_auc 0.9173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/25  train_loss: 0.4800  train_acc: 0.8354  train_f1: 0.8234\n",
            "Epoch 14  train_loss 0.4800 | val_loss 0.5433 | val_f1 0.8023 | val_precision 0.8064 | val_recall 0.8243 | val_auc 0.9462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/25  train_loss: 0.4672  train_acc: 0.8410  train_f1: 0.8299\n",
            "Epoch 15  train_loss 0.4672 | val_loss 0.5339 | val_f1 0.7966 | val_precision 0.8044 | val_recall 0.8160 | val_auc 0.9040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/25  train_loss: 0.4307  train_acc: 0.8519  train_f1: 0.8431\n",
            "Epoch 16  train_loss 0.4307 | val_loss 0.5275 | val_f1 0.8160 | val_precision 0.8152 | val_recall 0.8284 | val_auc 0.9201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/25  train_loss: 0.4122  train_acc: 0.8569  train_f1: 0.8486\n",
            "Epoch 17  train_loss 0.4122 | val_loss 0.5376 | val_f1 0.8096 | val_precision 0.8103 | val_recall 0.8208 | val_auc 0.9134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/25  train_loss: 0.4015  train_acc: 0.8603  train_f1: 0.8529\n",
            "Epoch 18  train_loss 0.4015 | val_loss 0.5326 | val_f1 0.8069 | val_precision 0.8044 | val_recall 0.8208 | val_auc 0.9017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/25  train_loss: 0.3852  train_acc: 0.8654  train_f1: 0.8586\n",
            "Epoch 19  train_loss 0.3852 | val_loss 0.5391 | val_f1 0.8066 | val_precision 0.7992 | val_recall 0.8202 | val_auc 0.8979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/25  train_loss: 0.3717  train_acc: 0.8719  train_f1: 0.8658\n",
            "Epoch 20  train_loss 0.3717 | val_loss 0.5279 | val_f1 0.8181 | val_precision 0.8197 | val_recall 0.8302 | val_auc 0.9476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/25  train_loss: 0.3418  train_acc: 0.8806  train_f1: 0.8756\n",
            "Epoch 21  train_loss 0.3418 | val_loss 0.5410 | val_f1 0.8070 | val_precision 0.8064 | val_recall 0.8196 | val_auc 0.9504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/25  train_loss: 0.3261  train_acc: 0.8891  train_f1: 0.8846\n",
            "Epoch 22  train_loss 0.3261 | val_loss 0.5510 | val_f1 0.8082 | val_precision 0.8094 | val_recall 0.8154 | val_auc 0.9017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/25  train_loss: 0.3159  train_acc: 0.8899  train_f1: 0.8857\n",
            "Epoch 23  train_loss 0.3159 | val_loss 0.5589 | val_f1 0.8053 | val_precision 0.8044 | val_recall 0.8149 | val_auc 0.9161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/25  train_loss: 0.3035  train_acc: 0.8965  train_f1: 0.8926\n",
            "Epoch 24  train_loss 0.3035 | val_loss 0.5775 | val_f1 0.8047 | val_precision 0.8044 | val_recall 0.8143 | val_auc 0.8993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/25  train_loss: 0.2942  train_acc: 0.8974  train_f1: 0.8938\n",
            "Epoch 25  train_loss 0.2942 | val_loss 0.5819 | val_f1 0.8001 | val_precision 0.7976 | val_recall 0.8119 | val_auc 0.9402\n",
            "Test (seed 4) — loss: 0.5764, acc: 0.8304, precision: 0.8235, recall: 0.8304, auc: 0.9049, f1: 0.8231\n",
            "🏃 View run HAN-SPH-ABL-SEED-4 at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740/runs/a2f3093b8fe647ae97644fa8663c3ffa\n",
            "🧪 View experiment at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740\n",
            "\n",
            "=== Seed 5 ===\n",
            "Train distribution: Counter({0: 11261, 1: 2116, 9: 1234, 5: 1081, 3: 426, 2: 397, 6: 149, 7: 134, 10: 45, 4: 21, 8: 19})\n",
            "Val distribution: Counter({0: 1251, 1: 235, 9: 137, 5: 120, 3: 48, 2: 44, 6: 17, 7: 15, 10: 5, 8: 2, 4: 2})\n",
            "Test distribution: Counter({0: 1391, 1: 261, 9: 152, 5: 133, 3: 53, 2: 49, 6: 19, 7: 16, 10: 6, 4: 3, 8: 2})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25  train_loss: 1.1801  train_acc: 0.6745  train_f1: 0.5514\n",
            "Epoch 1  train_loss 1.1801 | val_loss 1.0875 | val_f1 0.5863 | val_precision 0.5103 | val_recall 0.6964 | val_auc 0.7240\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/25  train_loss: 1.0306  train_acc: 0.6989  train_f1: 0.6050\n",
            "Epoch 2  train_loss 1.0306 | val_loss 0.8921 | val_f1 0.6620 | val_precision 0.6103 | val_recall 0.7393 | val_auc 0.7732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/25  train_loss: 0.8719  train_acc: 0.7384  train_f1: 0.6654\n",
            "Epoch 3  train_loss 0.8719 | val_loss 0.8790 | val_f1 0.6267 | val_precision 0.6262 | val_recall 0.7208 | val_auc 0.7608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/25  train_loss: 0.7966  train_acc: 0.7571  train_f1: 0.7098\n",
            "Epoch 4  train_loss 0.7966 | val_loss 0.8155 | val_f1 0.7276 | val_precision 0.7250 | val_recall 0.7649 | val_auc 0.7747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/25  train_loss: 0.7494  train_acc: 0.7732  train_f1: 0.7355\n",
            "Epoch 5  train_loss 0.7494 | val_loss 0.7368 | val_f1 0.7379 | val_precision 0.7353 | val_recall 0.7685 | val_auc 0.8130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/25  train_loss: 0.6623  train_acc: 0.7959  train_f1: 0.7670\n",
            "Epoch 6  train_loss 0.6623 | val_loss 0.6607 | val_f1 0.7700 | val_precision 0.7832 | val_recall 0.7994 | val_auc 0.8459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/25  train_loss: 0.6257  train_acc: 0.8032  train_f1: 0.7798\n",
            "Epoch 7  train_loss 0.6257 | val_loss 0.6285 | val_f1 0.7659 | val_precision 0.7666 | val_recall 0.7929 | val_auc 0.8628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/25  train_loss: 0.5948  train_acc: 0.8141  train_f1: 0.7934\n",
            "Epoch 8  train_loss 0.5948 | val_loss 0.6285 | val_f1 0.7762 | val_precision 0.7833 | val_recall 0.7988 | val_auc 0.8743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/25  train_loss: 0.5732  train_acc: 0.8182  train_f1: 0.7994\n",
            "Epoch 9  train_loss 0.5732 | val_loss 0.6152 | val_f1 0.7639 | val_precision 0.7955 | val_recall 0.7976 | val_auc 0.8872\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/25  train_loss: 0.5575  train_acc: 0.8208  train_f1: 0.8027\n",
            "Epoch 10  train_loss 0.5575 | val_loss 0.5995 | val_f1 0.7793 | val_precision 0.7898 | val_recall 0.8012 | val_auc 0.8831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/25  train_loss: 0.5064  train_acc: 0.8336  train_f1: 0.8175\n",
            "Epoch 11  train_loss 0.5064 | val_loss 0.5565 | val_f1 0.7978 | val_precision 0.8003 | val_recall 0.8173 | val_auc 0.8988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/25  train_loss: 0.4845  train_acc: 0.8400  train_f1: 0.8266\n",
            "Epoch 12  train_loss 0.4845 | val_loss 0.5533 | val_f1 0.7961 | val_precision 0.7959 | val_recall 0.8149 | val_auc 0.9004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/25  train_loss: 0.4686  train_acc: 0.8441  train_f1: 0.8328\n",
            "Epoch 13  train_loss 0.4686 | val_loss 0.5414 | val_f1 0.8027 | val_precision 0.8073 | val_recall 0.8244 | val_auc 0.8993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/25  train_loss: 0.4536  train_acc: 0.8482  train_f1: 0.8376\n",
            "Epoch 14  train_loss 0.4536 | val_loss 0.5367 | val_f1 0.8120 | val_precision 0.8233 | val_recall 0.8286 | val_auc 0.8940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/25  train_loss: 0.4408  train_acc: 0.8503  train_f1: 0.8405\n",
            "Epoch 15  train_loss 0.4408 | val_loss 0.5453 | val_f1 0.8066 | val_precision 0.8140 | val_recall 0.8214 | val_auc 0.9241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/25  train_loss: 0.4030  train_acc: 0.8650  train_f1: 0.8572\n",
            "Epoch 16  train_loss 0.4030 | val_loss 0.5190 | val_f1 0.8294 | val_precision 0.8347 | val_recall 0.8417 | val_auc 0.9153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/25  train_loss: 0.3867  train_acc: 0.8708  train_f1: 0.8638\n",
            "Epoch 17  train_loss 0.3867 | val_loss 0.5341 | val_f1 0.8228 | val_precision 0.8229 | val_recall 0.8321 | val_auc 0.9108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/25  train_loss: 0.3714  train_acc: 0.8729  train_f1: 0.8667\n",
            "Epoch 18  train_loss 0.3714 | val_loss 0.5229 | val_f1 0.8235 | val_precision 0.8250 | val_recall 0.8345 | val_auc 0.9071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/25  train_loss: 0.3608  train_acc: 0.8813  train_f1: 0.8756\n",
            "Epoch 19  train_loss 0.3608 | val_loss 0.5393 | val_f1 0.8211 | val_precision 0.8255 | val_recall 0.8339 | val_auc 0.9141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/25  train_loss: 0.3477  train_acc: 0.8844  train_f1: 0.8791\n",
            "Epoch 20  train_loss 0.3477 | val_loss 0.5476 | val_f1 0.8204 | val_precision 0.8216 | val_recall 0.8292 | val_auc 0.9191\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/25  train_loss: 0.3135  train_acc: 0.8962  train_f1: 0.8922\n",
            "Epoch 21  train_loss 0.3135 | val_loss 0.5620 | val_f1 0.8268 | val_precision 0.8284 | val_recall 0.8369 | val_auc 0.9086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/25  train_loss: 0.2997  train_acc: 0.9008  train_f1: 0.8972\n",
            "Epoch 22  train_loss 0.2997 | val_loss 0.5660 | val_f1 0.8228 | val_precision 0.8212 | val_recall 0.8298 | val_auc 0.9102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/25  train_loss: 0.2891  train_acc: 0.9031  train_f1: 0.8996\n",
            "Epoch 23  train_loss 0.2891 | val_loss 0.5900 | val_f1 0.8252 | val_precision 0.8250 | val_recall 0.8327 | val_auc 0.9145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/25  train_loss: 0.2785  train_acc: 0.9066  train_f1: 0.9036\n",
            "Epoch 24  train_loss 0.2785 | val_loss 0.5758 | val_f1 0.8215 | val_precision 0.8216 | val_recall 0.8310 | val_auc 0.9110\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/25  train_loss: 0.2650  train_acc: 0.9132  train_f1: 0.9104\n",
            "Epoch 25  train_loss 0.2650 | val_loss 0.6142 | val_f1 0.8118 | val_precision 0.8109 | val_recall 0.8173 | val_auc 0.9183\n",
            "Test (seed 5) — loss: 0.6213, acc: 0.8162, precision: 0.8101, recall: 0.8162, auc: 0.9455, f1: 0.8113\n",
            "🏃 View run HAN-SPH-ABL-SEED-5 at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740/runs/b35e75d3dd4847d9894bdf293fb267c6\n",
            "🧪 View experiment at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740\n",
            "\n",
            "=== Seed 6 ===\n",
            "Train distribution: Counter({0: 11261, 1: 2116, 9: 1234, 5: 1081, 3: 426, 2: 397, 6: 149, 7: 134, 10: 45, 4: 21, 8: 19})\n",
            "Val distribution: Counter({0: 1251, 1: 235, 9: 137, 5: 120, 3: 48, 2: 44, 6: 17, 7: 15, 10: 5, 8: 2, 4: 2})\n",
            "Test distribution: Counter({0: 1391, 1: 261, 9: 152, 5: 133, 3: 53, 2: 49, 6: 19, 7: 16, 10: 6, 4: 3, 8: 2})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25  train_loss: 1.1611  train_acc: 0.6748  train_f1: 0.5549\n",
            "Epoch 1  train_loss 1.1611 | val_loss 1.0219 | val_f1 0.5955 | val_precision 0.5408 | val_recall 0.7033 | val_auc 0.6380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/25  train_loss: 0.9955  train_acc: 0.7083  train_f1: 0.6224\n",
            "Epoch 2  train_loss 0.9955 | val_loss 0.8534 | val_f1 0.6754 | val_precision 0.6234 | val_recall 0.7471 | val_auc 0.7518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/25  train_loss: 0.8591  train_acc: 0.7409  train_f1: 0.6751\n",
            "Epoch 3  train_loss 0.8591 | val_loss 0.7941 | val_f1 0.6879 | val_precision 0.7534 | val_recall 0.7518 | val_auc 0.7790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/25  train_loss: 0.8222  train_acc: 0.7486  train_f1: 0.7005\n",
            "Epoch 4  train_loss 0.8222 | val_loss 0.7599 | val_f1 0.7146 | val_precision 0.7174 | val_recall 0.7599 | val_auc 0.8134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/25  train_loss: 0.7924  train_acc: 0.7590  train_f1: 0.7140\n",
            "Epoch 5  train_loss 0.7924 | val_loss 0.8276 | val_f1 0.6957 | val_precision 0.7106 | val_recall 0.7471 | val_auc 0.7609\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/25  train_loss: 0.7517  train_acc: 0.7685  train_f1: 0.7260\n",
            "Epoch 6  train_loss 0.7517 | val_loss 0.7017 | val_f1 0.7387 | val_precision 0.7836 | val_recall 0.7891 | val_auc 0.8194\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/25  train_loss: 0.7129  train_acc: 0.7803  train_f1: 0.7429\n",
            "Epoch 7  train_loss 0.7129 | val_loss 0.6789 | val_f1 0.7510 | val_precision 0.7660 | val_recall 0.7868 | val_auc 0.8370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/25  train_loss: 0.7079  train_acc: 0.7781  train_f1: 0.7413\n",
            "Epoch 8  train_loss 0.7079 | val_loss 0.6568 | val_f1 0.7565 | val_precision 0.7638 | val_recall 0.7921 | val_auc 0.8459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/25  train_loss: 0.6625  train_acc: 0.7935  train_f1: 0.7652\n",
            "Epoch 9  train_loss 0.6625 | val_loss 0.6445 | val_f1 0.7645 | val_precision 0.7712 | val_recall 0.7944 | val_auc 0.8634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/25  train_loss: 0.6436  train_acc: 0.7975  train_f1: 0.7714\n",
            "Epoch 10  train_loss 0.6436 | val_loss 0.6171 | val_f1 0.7821 | val_precision 0.7847 | val_recall 0.8043 | val_auc 0.8501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/25  train_loss: 0.5977  train_acc: 0.8102  train_f1: 0.7883\n",
            "Epoch 11  train_loss 0.5977 | val_loss 0.5835 | val_f1 0.7939 | val_precision 0.7893 | val_recall 0.8107 | val_auc 0.8855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/25  train_loss: 0.5727  train_acc: 0.8131  train_f1: 0.7930\n",
            "Epoch 12  train_loss 0.5727 | val_loss 0.5876 | val_f1 0.7912 | val_precision 0.7925 | val_recall 0.8113 | val_auc 0.8870\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/25  train_loss: 0.5554  train_acc: 0.8198  train_f1: 0.8010\n",
            "Epoch 13  train_loss 0.5554 | val_loss 0.5589 | val_f1 0.7941 | val_precision 0.7863 | val_recall 0.8131 | val_auc 0.8971\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/25  train_loss: 0.5369  train_acc: 0.8236  train_f1: 0.8077\n",
            "Epoch 14  train_loss 0.5369 | val_loss 0.5745 | val_f1 0.7863 | val_precision 0.7926 | val_recall 0.8119 | val_auc 0.9055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/25  train_loss: 0.5166  train_acc: 0.8287  train_f1: 0.8136\n",
            "Epoch 15  train_loss 0.5166 | val_loss 0.5788 | val_f1 0.7937 | val_precision 0.8120 | val_recall 0.8084 | val_auc 0.9014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/25  train_loss: 0.4795  train_acc: 0.8411  train_f1: 0.8291\n",
            "Epoch 16  train_loss 0.4795 | val_loss 0.5413 | val_f1 0.8107 | val_precision 0.8046 | val_recall 0.8224 | val_auc 0.9023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/25  train_loss: 0.4591  train_acc: 0.8442  train_f1: 0.8333\n",
            "Epoch 17  train_loss 0.4591 | val_loss 0.5231 | val_f1 0.8199 | val_precision 0.8124 | val_recall 0.8324 | val_auc 0.8973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/25  train_loss: 0.4414  train_acc: 0.8500  train_f1: 0.8409\n",
            "Epoch 18  train_loss 0.4414 | val_loss 0.5374 | val_f1 0.8237 | val_precision 0.8221 | val_recall 0.8318 | val_auc 0.8964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/25  train_loss: 0.4308  train_acc: 0.8535  train_f1: 0.8447\n",
            "Epoch 19  train_loss 0.4308 | val_loss 0.5282 | val_f1 0.8201 | val_precision 0.8228 | val_recall 0.8312 | val_auc 0.9094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/25  train_loss: 0.4094  train_acc: 0.8633  train_f1: 0.8563\n",
            "Epoch 20  train_loss 0.4094 | val_loss 0.5351 | val_f1 0.8195 | val_precision 0.8187 | val_recall 0.8341 | val_auc 0.9049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/25  train_loss: 0.3775  train_acc: 0.8726  train_f1: 0.8663\n",
            "Epoch 21  train_loss 0.3775 | val_loss 0.5250 | val_f1 0.8335 | val_precision 0.8333 | val_recall 0.8394 | val_auc 0.9054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/25  train_loss: 0.3575  train_acc: 0.8790  train_f1: 0.8738\n",
            "Epoch 22  train_loss 0.3575 | val_loss 0.5348 | val_f1 0.8291 | val_precision 0.8264 | val_recall 0.8341 | val_auc 0.9115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/25  train_loss: 0.3497  train_acc: 0.8830  train_f1: 0.8782\n",
            "Epoch 23  train_loss 0.3497 | val_loss 0.5388 | val_f1 0.8335 | val_precision 0.8333 | val_recall 0.8400 | val_auc 0.9115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/25  train_loss: 0.3377  train_acc: 0.8857  train_f1: 0.8813\n",
            "Epoch 24  train_loss 0.3377 | val_loss 0.5422 | val_f1 0.8304 | val_precision 0.8299 | val_recall 0.8335 | val_auc 0.9115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/25  train_loss: 0.3272  train_acc: 0.8886  train_f1: 0.8844\n",
            "Epoch 25  train_loss 0.3272 | val_loss 0.5584 | val_f1 0.8282 | val_precision 0.8258 | val_recall 0.8347 | val_auc 0.9143\n",
            "Test (seed 6) — loss: 0.5940, acc: 0.8280, precision: 0.8180, recall: 0.8280, auc: 0.8990, f1: 0.8191\n",
            "🏃 View run HAN-SPH-ABL-SEED-6 at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740/runs/adee8879333b4807973f91489c86ba4a\n",
            "🧪 View experiment at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740\n",
            "\n",
            "=== Seed 7 ===\n",
            "Train distribution: Counter({0: 11261, 1: 2116, 9: 1234, 5: 1081, 3: 426, 2: 397, 6: 149, 7: 134, 10: 45, 4: 21, 8: 19})\n",
            "Val distribution: Counter({0: 1251, 1: 235, 9: 137, 5: 120, 3: 48, 2: 44, 6: 17, 7: 15, 10: 5, 4: 2, 8: 2})\n",
            "Test distribution: Counter({0: 1391, 1: 261, 9: 152, 5: 133, 3: 53, 2: 49, 6: 19, 7: 16, 10: 6, 4: 3, 8: 2})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25  train_loss: 1.1532  train_acc: 0.6765  train_f1: 0.5615\n",
            "Epoch 1  train_loss 1.1532 | val_loss 1.0869 | val_f1 0.5956 | val_precision 0.5340 | val_recall 0.6936 | val_auc 0.6696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/25  train_loss: 0.9188  train_acc: 0.7236  train_f1: 0.6548\n",
            "Epoch 2  train_loss 0.9188 | val_loss 0.8520 | val_f1 0.6831 | val_precision 0.6844 | val_recall 0.7354 | val_auc 0.7353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/25  train_loss: 0.8228  train_acc: 0.7454  train_f1: 0.6937\n",
            "Epoch 3  train_loss 0.8228 | val_loss 0.7902 | val_f1 0.6867 | val_precision 0.7281 | val_recall 0.7573 | val_auc 0.7783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/25  train_loss: 0.7957  train_acc: 0.7531  train_f1: 0.7046\n",
            "Epoch 4  train_loss 0.7957 | val_loss 0.9022 | val_f1 0.6788 | val_precision 0.6718 | val_recall 0.7093 | val_auc 0.7704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/25  train_loss: 0.7578  train_acc: 0.7674  train_f1: 0.7260\n",
            "Epoch 5  train_loss 0.7578 | val_loss 0.7691 | val_f1 0.7148 | val_precision 0.7230 | val_recall 0.7670 | val_auc 0.7869\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/25  train_loss: 0.6878  train_acc: 0.7848  train_f1: 0.7505\n",
            "Epoch 6  train_loss 0.6878 | val_loss 0.7123 | val_f1 0.7394 | val_precision 0.7448 | val_recall 0.7785 | val_auc 0.8186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/25  train_loss: 0.6584  train_acc: 0.7915  train_f1: 0.7629\n",
            "Epoch 7  train_loss 0.6584 | val_loss 0.6968 | val_f1 0.7577 | val_precision 0.7544 | val_recall 0.7755 | val_auc 0.8177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/25  train_loss: 0.6315  train_acc: 0.7986  train_f1: 0.7744\n",
            "Epoch 8  train_loss 0.6315 | val_loss 0.6646 | val_f1 0.7765 | val_precision 0.7861 | val_recall 0.7998 | val_auc 0.8346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/25  train_loss: 0.6077  train_acc: 0.8063  train_f1: 0.7857\n",
            "Epoch 9  train_loss 0.6077 | val_loss 0.6169 | val_f1 0.7829 | val_precision 0.7837 | val_recall 0.7998 | val_auc 0.8350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/25  train_loss: 0.5823  train_acc: 0.8146  train_f1: 0.7964\n",
            "Epoch 10  train_loss 0.5823 | val_loss 0.6441 | val_f1 0.7760 | val_precision 0.7837 | val_recall 0.8052 | val_auc 0.8376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/25  train_loss: 0.5294  train_acc: 0.8322  train_f1: 0.8172\n",
            "Epoch 11  train_loss 0.5294 | val_loss 0.6008 | val_f1 0.7878 | val_precision 0.7932 | val_recall 0.8034 | val_auc 0.8372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/25  train_loss: 0.5093  train_acc: 0.8338  train_f1: 0.8200\n",
            "Epoch 12  train_loss 0.5093 | val_loss 0.5803 | val_f1 0.8015 | val_precision 0.8022 | val_recall 0.8174 | val_auc 0.8743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/25  train_loss: 0.4904  train_acc: 0.8394  train_f1: 0.8272\n",
            "Epoch 13  train_loss 0.4904 | val_loss 0.5643 | val_f1 0.8143 | val_precision 0.8123 | val_recall 0.8271 | val_auc 0.8643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/25  train_loss: 0.4807  train_acc: 0.8393  train_f1: 0.8283\n",
            "Epoch 14  train_loss 0.4807 | val_loss 0.5590 | val_f1 0.8087 | val_precision 0.8184 | val_recall 0.8252 | val_auc 0.8486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/25  train_loss: 0.4629  train_acc: 0.8469  train_f1: 0.8365\n",
            "Epoch 15  train_loss 0.4629 | val_loss 0.5783 | val_f1 0.8009 | val_precision 0.8070 | val_recall 0.8113 | val_auc 0.8898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/25  train_loss: 0.4240  train_acc: 0.8605  train_f1: 0.8524\n",
            "Epoch 16  train_loss 0.4240 | val_loss 0.5390 | val_f1 0.8131 | val_precision 0.8115 | val_recall 0.8228 | val_auc 0.8910\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/25  train_loss: 0.4080  train_acc: 0.8636  train_f1: 0.8566\n",
            "Epoch 17  train_loss 0.4080 | val_loss 0.5280 | val_f1 0.8172 | val_precision 0.8230 | val_recall 0.8313 | val_auc 0.8909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/25  train_loss: 0.3898  train_acc: 0.8689  train_f1: 0.8624\n",
            "Epoch 18  train_loss 0.3898 | val_loss 0.5354 | val_f1 0.8186 | val_precision 0.8197 | val_recall 0.8313 | val_auc 0.8985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/25  train_loss: 0.3803  train_acc: 0.8730  train_f1: 0.8672\n",
            "Epoch 19  train_loss 0.3803 | val_loss 0.5391 | val_f1 0.8156 | val_precision 0.8151 | val_recall 0.8234 | val_auc 0.8887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/25  train_loss: 0.3693  train_acc: 0.8764  train_f1: 0.8711\n",
            "Epoch 20  train_loss 0.3693 | val_loss 0.5275 | val_f1 0.8204 | val_precision 0.8204 | val_recall 0.8325 | val_auc 0.8986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/25  train_loss: 0.3344  train_acc: 0.8882  train_f1: 0.8834\n",
            "Epoch 21  train_loss 0.3344 | val_loss 0.5491 | val_f1 0.8267 | val_precision 0.8286 | val_recall 0.8374 | val_auc 0.8868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/25  train_loss: 0.3200  train_acc: 0.8944  train_f1: 0.8903\n",
            "Epoch 22  train_loss 0.3200 | val_loss 0.5600 | val_f1 0.8213 | val_precision 0.8246 | val_recall 0.8331 | val_auc 0.8935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/25  train_loss: 0.3085  train_acc: 0.8970  train_f1: 0.8932\n",
            "Epoch 23  train_loss 0.3085 | val_loss 0.5613 | val_f1 0.8161 | val_precision 0.8190 | val_recall 0.8301 | val_auc 0.8941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/25  train_loss: 0.2949  train_acc: 0.9013  train_f1: 0.8977\n",
            "Epoch 24  train_loss 0.2949 | val_loss 0.5710 | val_f1 0.8236 | val_precision 0.8237 | val_recall 0.8325 | val_auc 0.9030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/25  train_loss: 0.2833  train_acc: 0.9055  train_f1: 0.9025\n",
            "Epoch 25  train_loss 0.2833 | val_loss 0.5852 | val_f1 0.8171 | val_precision 0.8159 | val_recall 0.8283 | val_auc 0.9076\n",
            "Test (seed 7) — loss: 0.6226, acc: 0.8215, precision: 0.8081, recall: 0.8215, auc: 0.8857, f1: 0.8118\n",
            "🏃 View run HAN-SPH-ABL-SEED-7 at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740/runs/1293e25c397743cd9d3fd8e16fa12cfc\n",
            "🧪 View experiment at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740\n",
            "\n",
            "=== Seed 8 ===\n",
            "Train distribution: Counter({0: 11261, 1: 2116, 9: 1234, 5: 1081, 3: 426, 2: 397, 6: 149, 7: 134, 10: 45, 4: 21, 8: 19})\n",
            "Val distribution: Counter({0: 1251, 1: 235, 9: 137, 5: 120, 3: 48, 2: 44, 6: 17, 7: 15, 10: 5, 8: 2, 4: 2})\n",
            "Test distribution: Counter({0: 1391, 1: 261, 9: 152, 5: 133, 3: 53, 2: 49, 6: 19, 7: 16, 10: 6, 4: 3, 8: 2})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25  train_loss: 1.2284  train_acc: 0.6684  train_f1: 0.5393\n",
            "Epoch 1  train_loss 1.2284 | val_loss 1.1718 | val_f1 0.5562 | val_precision 0.4685 | val_recall 0.6844 | val_auc 0.4767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/25  train_loss: 1.1456  train_acc: 0.6712  train_f1: 0.5508\n",
            "Epoch 2  train_loss 1.1456 | val_loss 1.1024 | val_f1 0.5791 | val_precision 0.5280 | val_recall 0.6820 | val_auc 0.5373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/25  train_loss: 1.0654  train_acc: 0.6832  train_f1: 0.5877\n",
            "Epoch 3  train_loss 1.0654 | val_loss 1.0526 | val_f1 0.5997 | val_precision 0.6440 | val_recall 0.7022 | val_auc 0.5905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/25  train_loss: 0.9539  train_acc: 0.7147  train_f1: 0.6558\n",
            "Epoch 4  train_loss 0.9539 | val_loss 0.8505 | val_f1 0.6966 | val_precision 0.7086 | val_recall 0.7457 | val_auc 0.7400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/25  train_loss: 0.8244  train_acc: 0.7502  train_f1: 0.7068\n",
            "Epoch 5  train_loss 0.8244 | val_loss 0.7832 | val_f1 0.6762 | val_precision 0.7394 | val_recall 0.7457 | val_auc 0.7871\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/25  train_loss: 0.7293  train_acc: 0.7740  train_f1: 0.7367\n",
            "Epoch 6  train_loss 0.7293 | val_loss 0.7023 | val_f1 0.7236 | val_precision 0.7540 | val_recall 0.7727 | val_auc 0.8046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/25  train_loss: 0.6801  train_acc: 0.7885  train_f1: 0.7555\n",
            "Epoch 7  train_loss 0.6801 | val_loss 0.6675 | val_f1 0.7559 | val_precision 0.7639 | val_recall 0.7843 | val_auc 0.7951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/25  train_loss: 0.6474  train_acc: 0.7959  train_f1: 0.7672\n",
            "Epoch 8  train_loss 0.6474 | val_loss 0.6331 | val_f1 0.7680 | val_precision 0.7828 | val_recall 0.7996 | val_auc 0.8299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/25  train_loss: 0.6157  train_acc: 0.8033  train_f1: 0.7772\n",
            "Epoch 9  train_loss 0.6157 | val_loss 0.6008 | val_f1 0.7782 | val_precision 0.7737 | val_recall 0.7935 | val_auc 0.8323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/25  train_loss: 0.5797  train_acc: 0.8102  train_f1: 0.7878\n",
            "Epoch 10  train_loss 0.5797 | val_loss 0.5868 | val_f1 0.7816 | val_precision 0.7878 | val_recall 0.8058 | val_auc 0.8076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/25  train_loss: 0.5144  train_acc: 0.8271  train_f1: 0.8096\n",
            "Epoch 11  train_loss 0.5144 | val_loss 0.5300 | val_f1 0.8034 | val_precision 0.8111 | val_recall 0.8229 | val_auc 0.8417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/25  train_loss: 0.4820  train_acc: 0.8368  train_f1: 0.8231\n",
            "Epoch 12  train_loss 0.4820 | val_loss 0.5234 | val_f1 0.8007 | val_precision 0.8012 | val_recall 0.8211 | val_auc 0.8481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/25  train_loss: 0.4615  train_acc: 0.8434  train_f1: 0.8320\n",
            "Epoch 13  train_loss 0.4615 | val_loss 0.5180 | val_f1 0.8110 | val_precision 0.8118 | val_recall 0.8284 | val_auc 0.8838\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/25  train_loss: 0.4357  train_acc: 0.8486  train_f1: 0.8389\n",
            "Epoch 14  train_loss 0.4357 | val_loss 0.5150 | val_f1 0.8135 | val_precision 0.8184 | val_recall 0.8297 | val_auc 0.8670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/25  train_loss: 0.4215  train_acc: 0.8579  train_f1: 0.8491\n",
            "Epoch 15  train_loss 0.4215 | val_loss 0.4929 | val_f1 0.8161 | val_precision 0.8140 | val_recall 0.8284 | val_auc 0.8624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/25  train_loss: 0.3754  train_acc: 0.8705  train_f1: 0.8632\n",
            "Epoch 16  train_loss 0.3754 | val_loss 0.4724 | val_f1 0.8266 | val_precision 0.8338 | val_recall 0.8395 | val_auc 0.8411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/25  train_loss: 0.3530  train_acc: 0.8790  train_f1: 0.8730\n",
            "Epoch 17  train_loss 0.3530 | val_loss 0.4810 | val_f1 0.8270 | val_precision 0.8265 | val_recall 0.8370 | val_auc 0.8308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/25  train_loss: 0.3381  train_acc: 0.8832  train_f1: 0.8778\n",
            "Epoch 18  train_loss 0.3381 | val_loss 0.4733 | val_f1 0.8292 | val_precision 0.8273 | val_recall 0.8352 | val_auc 0.8220\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/25  train_loss: 0.3247  train_acc: 0.8877  train_f1: 0.8827\n",
            "Epoch 19  train_loss 0.3247 | val_loss 0.4871 | val_f1 0.8272 | val_precision 0.8270 | val_recall 0.8364 | val_auc 0.8285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/25  train_loss: 0.3088  train_acc: 0.8947  train_f1: 0.8905\n",
            "Epoch 20  train_loss 0.3088 | val_loss 0.5139 | val_f1 0.8233 | val_precision 0.8234 | val_recall 0.8339 | val_auc 0.8364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/25  train_loss: 0.2653  train_acc: 0.9100  train_f1: 0.9069\n",
            "Epoch 21  train_loss 0.2653 | val_loss 0.5097 | val_f1 0.8269 | val_precision 0.8256 | val_recall 0.8346 | val_auc 0.8290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/25  train_loss: 0.2480  train_acc: 0.9157  train_f1: 0.9128\n",
            "Epoch 22  train_loss 0.2480 | val_loss 0.5390 | val_f1 0.8232 | val_precision 0.8206 | val_recall 0.8309 | val_auc 0.8283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/25  train_loss: 0.2356  train_acc: 0.9209  train_f1: 0.9184\n",
            "Epoch 23  train_loss 0.2356 | val_loss 0.5509 | val_f1 0.8159 | val_precision 0.8150 | val_recall 0.8241 | val_auc 0.8247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/25  train_loss: 0.2221  train_acc: 0.9235  train_f1: 0.9214\n",
            "Epoch 24  train_loss 0.2221 | val_loss 0.5580 | val_f1 0.8199 | val_precision 0.8189 | val_recall 0.8254 | val_auc 0.8302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/25  train_loss: 0.2116  train_acc: 0.9293  train_f1: 0.9273\n",
            "Epoch 25  train_loss 0.2116 | val_loss 0.5866 | val_f1 0.8124 | val_precision 0.8104 | val_recall 0.8199 | val_auc 0.8293\n",
            "Test (seed 8) — loss: 0.6378, acc: 0.8255, precision: 0.8156, recall: 0.8255, auc: 0.9372, f1: 0.8173\n",
            "🏃 View run HAN-SPH-ABL-SEED-8 at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740/runs/e6075281ecab4e3a9366b4c543de759c\n",
            "🧪 View experiment at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740\n",
            "\n",
            "=== Seed 9 ===\n",
            "Train distribution: Counter({0: 11261, 1: 2116, 9: 1234, 5: 1081, 3: 426, 2: 397, 6: 149, 7: 134, 10: 45, 4: 21, 8: 19})\n",
            "Val distribution: Counter({0: 1251, 1: 235, 9: 137, 5: 120, 3: 48, 2: 44, 6: 17, 7: 15, 10: 5, 8: 2, 4: 2})\n",
            "Test distribution: Counter({0: 1391, 1: 261, 9: 152, 5: 133, 3: 53, 2: 49, 6: 19, 7: 16, 10: 6, 4: 3, 8: 2})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25  train_loss: 1.2066  train_acc: 0.6709  train_f1: 0.5395\n",
            "Epoch 1  train_loss 1.2066 | val_loss 1.1346 | val_f1 0.5484 | val_precision 0.4602 | val_recall 0.6784 | val_auc 0.6260\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/25  train_loss: 1.1061  train_acc: 0.6784  train_f1: 0.5726\n",
            "Epoch 2  train_loss 1.1061 | val_loss 0.9450 | val_f1 0.6769 | val_precision 0.6840 | val_recall 0.7178 | val_auc 0.7331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/25  train_loss: 0.9025  train_acc: 0.7299  train_f1: 0.6805\n",
            "Epoch 3  train_loss 0.9025 | val_loss 0.8373 | val_f1 0.7179 | val_precision 0.7173 | val_recall 0.7579 | val_auc 0.7656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/25  train_loss: 0.8091  train_acc: 0.7502  train_f1: 0.7080\n",
            "Epoch 4  train_loss 0.8091 | val_loss 0.7400 | val_f1 0.7309 | val_precision 0.7384 | val_recall 0.7712 | val_auc 0.8247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/25  train_loss: 0.7670  train_acc: 0.7615  train_f1: 0.7230\n",
            "Epoch 5  train_loss 0.7670 | val_loss 0.6819 | val_f1 0.7497 | val_precision 0.7569 | val_recall 0.7822 | val_auc 0.8612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/25  train_loss: 0.6775  train_acc: 0.7854  train_f1: 0.7562\n",
            "Epoch 6  train_loss 0.6775 | val_loss 0.6300 | val_f1 0.7774 | val_precision 0.7798 | val_recall 0.7998 | val_auc 0.8141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/25  train_loss: 0.6440  train_acc: 0.7941  train_f1: 0.7684\n",
            "Epoch 7  train_loss 0.6440 | val_loss 0.5976 | val_f1 0.7780 | val_precision 0.8036 | val_recall 0.8113 | val_auc 0.8651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/25  train_loss: 0.6208  train_acc: 0.7984  train_f1: 0.7747\n",
            "Epoch 8  train_loss 0.6208 | val_loss 0.6070 | val_f1 0.7885 | val_precision 0.7915 | val_recall 0.8095 | val_auc 0.8179\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/25  train_loss: 0.5924  train_acc: 0.8069  train_f1: 0.7852\n",
            "Epoch 9  train_loss 0.5924 | val_loss 0.5860 | val_f1 0.7817 | val_precision 0.7970 | val_recall 0.8119 | val_auc 0.8543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/25  train_loss: 0.5749  train_acc: 0.8110  train_f1: 0.7908\n",
            "Epoch 10  train_loss 0.5749 | val_loss 0.5481 | val_f1 0.8151 | val_precision 0.8151 | val_recall 0.8331 | val_auc 0.8916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/25  train_loss: 0.5123  train_acc: 0.8303  train_f1: 0.8136\n",
            "Epoch 11  train_loss 0.5123 | val_loss 0.5200 | val_f1 0.8250 | val_precision 0.8181 | val_recall 0.8368 | val_auc 0.8768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/25  train_loss: 0.4900  train_acc: 0.8377  train_f1: 0.8237\n",
            "Epoch 12  train_loss 0.4900 | val_loss 0.5482 | val_f1 0.8123 | val_precision 0.8168 | val_recall 0.8198 | val_auc 0.9092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/25  train_loss: 0.4711  train_acc: 0.8407  train_f1: 0.8283\n",
            "Epoch 13  train_loss 0.4711 | val_loss 0.5085 | val_f1 0.8185 | val_precision 0.8150 | val_recall 0.8343 | val_auc 0.9279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/25  train_loss: 0.4560  train_acc: 0.8450  train_f1: 0.8333\n",
            "Epoch 14  train_loss 0.4560 | val_loss 0.4969 | val_f1 0.8162 | val_precision 0.8148 | val_recall 0.8350 | val_auc 0.9370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/25  train_loss: 0.4468  train_acc: 0.8484  train_f1: 0.8369\n",
            "Epoch 15  train_loss 0.4468 | val_loss 0.5019 | val_f1 0.8286 | val_precision 0.8399 | val_recall 0.8434 | val_auc 0.9290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/25  train_loss: 0.4030  train_acc: 0.8618  train_f1: 0.8530\n",
            "Epoch 16  train_loss 0.4030 | val_loss 0.4705 | val_f1 0.8333 | val_precision 0.8346 | val_recall 0.8410 | val_auc 0.9434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/25  train_loss: 0.3838  train_acc: 0.8656  train_f1: 0.8575\n",
            "Epoch 17  train_loss 0.3838 | val_loss 0.4802 | val_f1 0.8300 | val_precision 0.8372 | val_recall 0.8416 | val_auc 0.9410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/25  train_loss: 0.3738  train_acc: 0.8715  train_f1: 0.8644\n",
            "Epoch 18  train_loss 0.3738 | val_loss 0.4954 | val_f1 0.8229 | val_precision 0.8277 | val_recall 0.8356 | val_auc 0.9460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/25  train_loss: 0.3597  train_acc: 0.8762  train_f1: 0.8693\n",
            "Epoch 19  train_loss 0.3597 | val_loss 0.4985 | val_f1 0.8279 | val_precision 0.8307 | val_recall 0.8380 | val_auc 0.9461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/25  train_loss: 0.3497  train_acc: 0.8789  train_f1: 0.8725\n",
            "Epoch 20  train_loss 0.3497 | val_loss 0.4958 | val_f1 0.8272 | val_precision 0.8354 | val_recall 0.8362 | val_auc 0.9422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/25  train_loss: 0.3117  train_acc: 0.8920  train_f1: 0.8872\n",
            "Epoch 21  train_loss 0.3117 | val_loss 0.4987 | val_f1 0.8274 | val_precision 0.8304 | val_recall 0.8350 | val_auc 0.9521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/25  train_loss: 0.2981  train_acc: 0.8960  train_f1: 0.8918\n",
            "Epoch 22  train_loss 0.2981 | val_loss 0.4901 | val_f1 0.8413 | val_precision 0.8458 | val_recall 0.8483 | val_auc 0.9528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/25  train_loss: 0.2856  train_acc: 0.9035  train_f1: 0.8996\n",
            "Epoch 23  train_loss 0.2856 | val_loss 0.5256 | val_f1 0.8288 | val_precision 0.8332 | val_recall 0.8343 | val_auc 0.9534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/25  train_loss: 0.2727  train_acc: 0.9072  train_f1: 0.9038\n",
            "Epoch 24  train_loss 0.2727 | val_loss 0.5228 | val_f1 0.8345 | val_precision 0.8413 | val_recall 0.8416 | val_auc 0.9560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/25  train_loss: 0.2653  train_acc: 0.9110  train_f1: 0.9077\n",
            "Epoch 25  train_loss 0.2653 | val_loss 0.5298 | val_f1 0.8330 | val_precision 0.8351 | val_recall 0.8386 | val_auc 0.9532\n",
            "Test (seed 9) — loss: 0.6049, acc: 0.8093, precision: 0.7992, recall: 0.8093, auc: 0.9525, f1: 0.8025\n",
            "🏃 View run HAN-SPH-ABL-SEED-9 at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740/runs/cd415ff4f29e4460b9330a1263676ff6\n",
            "🧪 View experiment at: https://dbc-5cba9d5d-ddf8.cloud.databricks.com/ml/experiments/2727678298130740\n",
            "\n",
            "=== Final Results (across seeds) ===\n",
            "acc: mean=0.8235, std=0.0104\n",
            "precision: mean=0.8143, std=0.0111\n",
            "recall: mean=0.8235, std=0.0104\n",
            "auc: mean=0.9053, std=0.0283\n",
            "loss: mean=0.6073, std=0.0428\n",
            "f1: mean=0.8163, std=0.0106\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'acc': [0.8463983050847458,\n",
              "  0.8098290598290598,\n",
              "  0.8198529411764706,\n",
              "  0.8279914529914529,\n",
              "  0.8303571428571429,\n",
              "  0.8161764705882353,\n",
              "  0.8279914529914529,\n",
              "  0.8215042372881356,\n",
              "  0.8255434782608696,\n",
              "  0.8092948717948718],\n",
              " 'precision': [0.838043746983761,\n",
              "  0.7984390637478526,\n",
              "  0.8127678403720887,\n",
              "  0.8189222726238736,\n",
              "  0.8234605235073799,\n",
              "  0.8100944376116187,\n",
              "  0.8180481935548947,\n",
              "  0.8081017861714833,\n",
              "  0.8155852926206023,\n",
              "  0.7991501931536913],\n",
              " 'recall': [0.8463983050847458,\n",
              "  0.8098290598290598,\n",
              "  0.8198529411764706,\n",
              "  0.8279914529914529,\n",
              "  0.8303571428571429,\n",
              "  0.8161764705882353,\n",
              "  0.8279914529914529,\n",
              "  0.8215042372881356,\n",
              "  0.8255434782608696,\n",
              "  0.8092948717948718],\n",
              " 'auc': [np.float64(0.8863960287867546),\n",
              "  np.float64(0.8627199431643618),\n",
              "  np.float64(0.8848674519349352),\n",
              "  np.float64(0.8939358352644896),\n",
              "  np.float64(0.9048986230598618),\n",
              "  np.float64(0.9454835578845099),\n",
              "  np.float64(0.8990159856580227),\n",
              "  np.float64(0.8856829925568235),\n",
              "  np.float64(0.9372115476550618),\n",
              "  np.float64(0.9524522796728309)],\n",
              " 'loss': [0.5425233934390343,\n",
              "  0.6467354188108037,\n",
              "  0.683836000087131,\n",
              "  0.5423673172600758,\n",
              "  0.5764044881054834,\n",
              "  0.6212656448806534,\n",
              "  0.5940400290374572,\n",
              "  0.6225976079260394,\n",
              "  0.6378346496302149,\n",
              "  0.6049035581736228],\n",
              " 'f1': [0.8404512495040105,\n",
              "  0.8018652940543312,\n",
              "  0.8137429539095902,\n",
              "  0.821906344630879,\n",
              "  0.8230698846353635,\n",
              "  0.8112663949521564,\n",
              "  0.8190650348708293,\n",
              "  0.8118212024376285,\n",
              "  0.8173229578465966,\n",
              "  0.8024813710862378]}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "run_experiments(model_fn, optimizer_fn, criterion, DEVICE, 25, 11, 10)\n",
        "# maybe change num of epochs to 30!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU0OMFca7iI7",
        "outputId": "eae7b366-43f0-4ee1-8d28-7f061f69e604"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================================================================================================\n",
              "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Trainable\n",
              "=================================================================================================================================================\n",
              "HANWithAttention                              [2, 10, 300, 12]          [2, 11]                   4,240                     True\n",
              "├─Conv1d: 1-1                                 [20, 12, 300]             [20, 128, 300]            38,528                    True\n",
              "├─MaxPool1d: 1-2                              [20, 128, 300]            [20, 128, 150]            --                        --\n",
              "├─LSTM: 1-3                                   [20, 150, 128]            [20, 150, 128]            132,096                   True\n",
              "├─TimeDistributedSegmentAttention: 1-4        [2, 10, 150, 128]         [2, 10, 128]              --                        True\n",
              "│    └─SegmentAttention: 2-1                  [20, 150, 128]            [20, 128]                 128                       True\n",
              "│    │    └─Linear: 3-1                       [20, 150, 128]            [20, 150, 128]            16,512                    True\n",
              "├─LSTM: 1-5                                   [2, 10, 128]              [2, 10, 512]              1,314,816                 True\n",
              "├─SegmentAttention: 1-6                       [2, 10, 512]              [2, 512]                  512                       True\n",
              "│    └─Linear: 2-2                            [2, 10, 512]              [2, 10, 512]              262,656                   True\n",
              "├─Linear: 1-7                                 [2, 512]                  [2, 512]                  262,656                   True\n",
              "├─Dropout: 1-8                                [2, 512]                  [2, 512]                  --                        --\n",
              "├─Linear: 1-9                                 [2, 512]                  [2, 11]                   5,643                     True\n",
              "=================================================================================================================================================\n",
              "Total params: 2,037,787\n",
              "Trainable params: 2,037,787\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 655.14\n",
              "=================================================================================================================================================\n",
              "Input size (MB): 0.29\n",
              "Forward/backward pass size (MB): 12.46\n",
              "Params size (MB): 8.13\n",
              "Estimated Total Size (MB): 20.88\n",
              "================================================================================================================================================="
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model,\n",
        "        input_size=(2, 10, 300, 12),    # (batch, segments, timesteps, channels)\n",
        "        col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n",
        "        depth=4,\n",
        "        device=device.type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXVjg2BIKV9U"
      },
      "source": [
        "# Resource use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QOyRiZdxVBo"
      },
      "outputs": [],
      "source": [
        "!pip install calflops -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxpGdzARxbkS"
      },
      "outputs": [],
      "source": [
        "import calflops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZdSl-e2xxjq",
        "outputId": "00e27c0b-5c6a-4937-8837-a1514efd698c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------- Calculate Flops Results -------------------------------------\n",
            "Notations:\n",
            "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
            "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
            "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
            "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
            "\n",
            "Total Training Params:                                                  2.04 M  \n",
            "fwd MACs:                                                               169.945 MMACs\n",
            "fwd FLOPs:                                                              762.061 MFLOPS\n",
            "fwd+bwd MACs:                                                           509.834 MMACs\n",
            "fwd+bwd FLOPs:                                                          2.2862 GFLOPS\n",
            "\n",
            "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
            "Each module caculated is listed after its name in the following order: \n",
            "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
            "\n",
            "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
            " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
            "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
            "\n",
            "HANWithAttention(\n",
            "  2.04 M = 100% Params, 169.94 MMACs = 100% MACs, 762.06 MFLOPS = 100% FLOPs\n",
            "  (conv1d): Conv1d(38.53 K = 1.8907% Params, 115.2 MMACs = 67.7868% MACs, 230.78 MFLOPS = 30.2842% FLOPs, 12, 128, kernel_size=(25,), stride=(1,), padding=(12,))\n",
            "  (channel_attention): ChannelAttention(\n",
            "    4.24 K = 0.2081% Params, 81.92 KMACs = 0.0482% MACs, 164.16 KFLOPS = 0.0215% FLOPs\n",
            "    (mlp): Sequential(\n",
            "      4.24 K = 0.2081% Params, 81.92 KMACs = 0.0482% MACs, 164.16 KFLOPS = 0.0215% FLOPs\n",
            "      (0): Linear(2.06 K = 0.1013% Params, 40.96 KMACs = 0.0241% MACs, 81.92 KFLOPS = 0.0107% FLOPs, in_features=128, out_features=16, bias=True)\n",
            "      (1): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 320 FLOPS = 0% FLOPs)\n",
            "      (2): Linear(2.18 K = 0.1068% Params, 40.96 KMACs = 0.0241% MACs, 81.92 KFLOPS = 0.0107% FLOPs, in_features=16, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (pool): MaxPool1d(0 = 0% Params, 0 MACs = 0% MACs, 384 KFLOPS = 0.0504% FLOPs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (lstm_segment): LSTM(132.1 K = 6.4823% Params, 0 MACs = 0% MACs, 395.14 MFLOPS = 51.851% FLOPs, 128, 128, batch_first=True)\n",
            "  (time_distributed_attention): TimeDistributedSegmentAttention(\n",
            "    16.64 K = 0.8166% Params, 49.15 MMACs = 28.9224% MACs, 98.31 MFLOPS = 12.8999% FLOPs\n",
            "    (segment_attention): SegmentAttention(\n",
            "      16.64 K = 0.8166% Params, 49.15 MMACs = 28.9224% MACs, 98.31 MFLOPS = 12.8999% FLOPs\n",
            "      (linear): Linear(16.51 K = 0.8103% Params, 24.58 MMACs = 14.4612% MACs, 49.15 MFLOPS = 6.4499% FLOPs, in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (lstm_sequence): LSTM(1.31 M = 64.5218% Params, 0 MACs = 0% MACs, 26.27 MFLOPS = 3.4467% FLOPs, 128, 512, batch_first=True)\n",
            "  (final_attention): SegmentAttention(\n",
            "    263.17 K = 12.9144% Params, 5.24 MMACs = 3.0851% MACs, 10.49 MFLOPS = 1.376% FLOPs\n",
            "    (linear): Linear(262.66 K = 12.8893% Params, 2.62 MMACs = 1.5425% MACs, 5.24 MFLOPS = 0.688% FLOPs, in_features=512, out_features=512, bias=True)\n",
            "  )\n",
            "  (fc): Linear(262.66 K = 12.8893% Params, 262.14 KMACs = 0.1543% MACs, 524.29 KFLOPS = 0.0688% FLOPs, in_features=512, out_features=512, bias=True)\n",
            "  (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.3, inplace=False)\n",
            "  (classifier): Linear(5.64 K = 0.2769% Params, 5.63 KMACs = 0.0033% MACs, 11.26 KFLOPS = 0.0015% FLOPs, in_features=512, out_features=11, bias=True)\n",
            ")\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Model FLOPs:762.061 MFLOPS   MACs:169.945 MMACs   Params:2.0378 M \n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = HANWithAttention(num_classes=11,\n",
        "                            conv_channels=128,\n",
        "                            segment_hidden=128,\n",
        "                            sequence_hidden=512,\n",
        "                            fc_hidden=512,\n",
        "                            dropout=0.3)\n",
        "\n",
        "flops, macs, params = calflops.calculate_flops(model=model,\n",
        "                                      input_shape=(1, 10, 300, 12),\n",
        "                                      output_as_string=True,\n",
        "                                      output_precision=4)\n",
        "print(\"Model FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR5CvCk7KijN",
        "outputId": "7512a2af-0b1a-4b36-f90e-a104830b77c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "MODEL COMPLEXITY ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "📊 Parameter Count:\n",
            "   Total Parameters:       2,037,787\n",
            "   Trainable Parameters:   2,037,787\n",
            "   Non-trainable Parameters: 0\n",
            "   Model Size (MB):        7.77\n",
            "\n",
            "🔢 FLOPs (Floating Point Operations):\n",
            "   MACs (Multiply-Accumulate): 355.616M\n",
            "   Parameters (thop):          2.037M\n",
            "\n",
            "📋 Layer-wise Parameter Breakdown:\n",
            "Layer Name                                    Parameters   % of Total\n",
            "----------------------------------------------------------------------\n",
            "conv1d.weight                                     38,400        1.88%\n",
            "conv1d.bias                                          128        0.01%\n",
            "channel_attention.mlp.0.weight                     2,048        0.10%\n",
            "channel_attention.mlp.0.bias                          16        0.00%\n",
            "channel_attention.mlp.2.weight                     2,048        0.10%\n",
            "channel_attention.mlp.2.bias                         128        0.01%\n",
            "lstm_segment.weight_ih_l0                         65,536        3.22%\n",
            "lstm_segment.weight_hh_l0                         65,536        3.22%\n",
            "lstm_segment.bias_ih_l0                              512        0.03%\n",
            "lstm_segment.bias_hh_l0                              512        0.03%\n",
            "time_distributed_attention.segment_attention.u             128        0.01%\n",
            "time_distributed_attention.segment_attention.linear.weight          16,384        0.80%\n",
            "time_distributed_attention.segment_attention.linear.bias             128        0.01%\n",
            "lstm_sequence.weight_ih_l0                       262,144       12.86%\n",
            "lstm_sequence.weight_hh_l0                     1,048,576       51.46%\n",
            "lstm_sequence.bias_ih_l0                           2,048        0.10%\n",
            "lstm_sequence.bias_hh_l0                           2,048        0.10%\n",
            "final_attention.u                                    512        0.03%\n",
            "final_attention.linear.weight                    262,144       12.86%\n",
            "final_attention.linear.bias                          512        0.03%\n",
            "fc.weight                                        262,144       12.86%\n",
            "fc.bias                                              512        0.03%\n",
            "classifier.weight                                  5,632        0.28%\n",
            "classifier.bias                                       11        0.00%\n",
            "\n",
            "📝 Detailed Model Architecture:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'total_params': 2037787,\n",
              " 'trainable_params': 2037787,\n",
              " 'model_size_mb': 7.773540496826172}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def analyze_model_complexity(model, input_size=(1, 10, 300, 12), device='cuda'):\n",
        "    \"\"\"\n",
        "    Analyze model complexity: parameters, FLOPs, memory\n",
        "\n",
        "    Args:\n",
        "        model: Your HANWithAttention model\n",
        "        input_size: (batch, segments, timesteps, channels)\n",
        "        device: 'cuda' or 'cpu'\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"MODEL COMPLEXITY ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # 1. Parameter count\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    non_trainable_params = total_params - trainable_params\n",
        "\n",
        "    print(f\"\\n📊 Parameter Count:\")\n",
        "    print(f\"   Total Parameters:       {total_params:,}\")\n",
        "    print(f\"   Trainable Parameters:   {trainable_params:,}\")\n",
        "    print(f\"   Non-trainable Parameters: {non_trainable_params:,}\")\n",
        "    print(f\"   Model Size (MB):        {total_params * 4 / (1024**2):.2f}\")  # 4 bytes per float32\n",
        "\n",
        "    # 2. FLOPs calculation\n",
        "    dummy_input = torch.randn(input_size).to(device)\n",
        "\n",
        "    try:\n",
        "        macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
        "        macs, params = clever_format([macs, params], \"%.3f\")\n",
        "        print(f\"\\n🔢 FLOPs (Floating Point Operations):\")\n",
        "        print(f\"   MACs (Multiply-Accumulate): {macs}\")\n",
        "        print(f\"   Parameters (thop):          {params}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n⚠️  FLOPs calculation failed: {e}\")\n",
        "\n",
        "    # 3. Layer-wise parameter breakdown\n",
        "    print(f\"\\n📋 Layer-wise Parameter Breakdown:\")\n",
        "    print(f\"{'Layer Name':<40} {'Parameters':>15} {'% of Total':>12}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            param_count = param.numel()\n",
        "            percentage = 100 * param_count / trainable_params\n",
        "            print(f\"{name:<40} {param_count:>15,} {percentage:>11.2f}%\")\n",
        "\n",
        "    # 4. Detailed model summary\n",
        "    print(f\"\\n📝 Detailed Model Architecture:\")\n",
        "    summary(model,\n",
        "            input_size=input_size,\n",
        "            col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
        "            depth=4,\n",
        "            device=device,\n",
        "            verbose=0)\n",
        "\n",
        "    return {\n",
        "        'total_params': total_params,\n",
        "        'trainable_params': trainable_params,\n",
        "        'model_size_mb': total_params * 4 / (1024**2)\n",
        "    }\n",
        "\n",
        "analyze_model_complexity(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHsLQY8jZiU9",
        "outputId": "17f5914e-d886-425d-81ae-5097ae4920d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model size: 7.774MB\n"
          ]
        }
      ],
      "source": [
        "# From: https://discuss.pytorch.org/t/finding-model-size/130275\n",
        "\n",
        "param_size = 0\n",
        "for param in model.parameters():\n",
        "    param_size += param.nelement() * param.element_size()\n",
        "buffer_size = 0\n",
        "for buffer in model.buffers():\n",
        "    buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "print('model size: {:.3f}MB'.format(size_all_mb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_uVZS6MdoxT",
        "outputId": "670faef9-6ece-4222-b550-435b9d57c5b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "INFERENCE BENCHMARK\n",
            "================================================================================\n",
            "Device: cuda\n",
            "Input shape: (1, 10, 300, 12)\n",
            "Throughput batch size: 16\n",
            "\n",
            "Batch-1 Latency (ms):\n",
            "     mean_ms: 1.716\n",
            "      std_ms: 0.099\n",
            "   median_ms: 1.693\n",
            "      min_ms: 1.629\n",
            "      max_ms: 2.359\n",
            "\n",
            "Batch-N Throughput:\n",
            "     batch_time_ms: 3.276\n",
            "     per_sample_ms: 0.205\n",
            "   samples_per_sec: 4883.44\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# =============================================================================\n",
        "# Benchmark Environment Setup\n",
        "# =============================================================================\n",
        "\n",
        "def setup_benchmark_env():\n",
        "    \"\"\"\n",
        "    Freeze backend behavior for reproducible benchmarking.\n",
        "    \"\"\"\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = False\n",
        "    torch.backends.cudnn.allow_tf32 = False\n",
        "\n",
        "def time_forward(model, inputs, device='cuda'):\n",
        "    \"\"\"\n",
        "    Time a single forward pass with proper synchronization.\n",
        "    Returns elapsed time in seconds.\n",
        "    \"\"\"\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "        start = torch.cuda.Event(enable_timing=True)\n",
        "        end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "        start.record()\n",
        "        _ = model(inputs)\n",
        "        end.record()\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        return start.elapsed_time(end) / 1000.0  # seconds\n",
        "    else:\n",
        "        t0 = time.time()\n",
        "        _ = model(inputs)\n",
        "        return time.time() - t0\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Batch-1 Latency Benchmark\n",
        "# =============================================================================\n",
        "\n",
        "def benchmark_latency(\n",
        "    model,\n",
        "    input_shape,\n",
        "    device='cuda',\n",
        "    runs=100,\n",
        "    warmup=20\n",
        "):\n",
        "    \"\"\"\n",
        "    Measure true per-sample inference latency (batch size = 1).\n",
        "    \"\"\"\n",
        "    model = model.to(device).eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Warmup\n",
        "        for _ in range(warmup):\n",
        "            x = torch.randn(input_shape, device=device)\n",
        "            _ = model(x)\n",
        "            if device == 'cuda':\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "        times = []\n",
        "        for _ in range(runs):\n",
        "            x = torch.randn(input_shape, device=device)\n",
        "            elapsed = time_forward(model, x, device)\n",
        "            times.append(elapsed)\n",
        "\n",
        "    times = np.array(times)\n",
        "\n",
        "    return {\n",
        "        \"mean_ms\": times.mean() * 1000,\n",
        "        \"std_ms\": times.std() * 1000,\n",
        "        \"median_ms\": np.median(times) * 1000,\n",
        "        \"min_ms\": times.min() * 1000,\n",
        "        \"max_ms\": times.max() * 1000,\n",
        "    }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Batch-N Throughput Benchmark\n",
        "# =============================================================================\n",
        "\n",
        "def benchmark_throughput(\n",
        "    model,\n",
        "    input_shape,\n",
        "    batch_size,\n",
        "    device='cuda',\n",
        "    runs=100,\n",
        "    warmup=20\n",
        "):\n",
        "    \"\"\"\n",
        "    Measure throughput under batched inference.\n",
        "    \"\"\"\n",
        "    model = model.to(device).eval()\n",
        "    shape = (batch_size,) + input_shape[1:]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Warmup\n",
        "        for _ in range(warmup):\n",
        "            x = torch.randn(shape, device=device)\n",
        "            _ = model(x)\n",
        "            if device == 'cuda':\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "        times = []\n",
        "        for _ in range(runs):\n",
        "            x = torch.randn(shape, device=device)\n",
        "            elapsed = time_forward(model, x, device)\n",
        "            times.append(elapsed)\n",
        "\n",
        "    times = np.array(times)\n",
        "\n",
        "    return {\n",
        "        \"batch_time_ms\": times.mean() * 1000,\n",
        "        \"per_sample_ms\": (times.mean() / batch_size) * 1000,\n",
        "        \"samples_per_sec\": batch_size / times.mean()\n",
        "    }\n",
        "\n",
        "def run_inference_benchmark(\n",
        "    model,\n",
        "    input_shape=(1, 10, 300, 12),\n",
        "    batch_size=16,\n",
        "    device='cuda'\n",
        "):\n",
        "    setup_benchmark_env()\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"INFERENCE BENCHMARK\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Input shape: {input_shape}\")\n",
        "    print(f\"Throughput batch size: {batch_size}\")\n",
        "\n",
        "    latency = benchmark_latency(\n",
        "        model=model,\n",
        "        input_shape=input_shape,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    throughput = benchmark_throughput(\n",
        "        model=model,\n",
        "        input_shape=input_shape,\n",
        "        batch_size=batch_size,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print(\"\\nBatch-1 Latency (ms):\")\n",
        "    for k, v in latency.items():\n",
        "        print(f\"  {k:>10}: {v:.3f}\")\n",
        "\n",
        "    print(\"\\nBatch-N Throughput:\")\n",
        "    for k, v in throughput.items():\n",
        "        if \"ms\" in k:\n",
        "            print(f\"  {k:>16}: {v:.3f}\")\n",
        "        else:\n",
        "            print(f\"  {k:>16}: {v:.2f}\")\n",
        "\n",
        "    return {\n",
        "        \"latency\": latency,\n",
        "        \"throughput\": throughput\n",
        "    }\n",
        "\n",
        "results = run_inference_benchmark(\n",
        "    model,\n",
        "    input_shape=(1, 10, 300, 12),\n",
        "    batch_size=16,\n",
        "    device='cuda'\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
