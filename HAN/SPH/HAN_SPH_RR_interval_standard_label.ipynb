{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbKFm3-45fxQ",
        "outputId": "f32d34ed-2f95-442b-9540-6fae50770262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q torchinfo mlflow optuna thop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua-UVjXsOWsu",
        "outputId": "feeac186-5719-413a-bd77-b5d30e733219"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Optional\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pywt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "from scipy.signal import butter, filtfilt, find_peaks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "import optuna\n",
        "from optuna.exceptions import TrialPruned\n",
        "from dotenv import load_dotenv\n",
        "import time\n",
        "from thop import profile, clever_format\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il9nOz1tLNU9",
        "outputId": "d0c5891b-b256-4231-c5ed-65600dbd64a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/1222522124100997', creation_time=1768344478752, experiment_id='1222522124100997', last_update_time=1768424820958, lifecycle_stage='active', name='/Users/oladipoeyiara@gmail.com/han_sph_full_rr_interval_after_tuning', tags={'mlflow.experiment.sourceName': '/Users/oladipoeyiara@gmail.com/han_sph_full_rr_interval_after_tuning',\n",
              " 'mlflow.experimentKind': 'custom_model_development',\n",
              " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
              " 'mlflow.ownerEmail': 'oladipoeyiara@gmail.com',\n",
              " 'mlflow.ownerId': '1108839756692281'}>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/oladipoeyiara@gmail.com/han_sph_full_rr_interval_after_tuning\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adAQ0YZbMAkt"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AunfTkWOIiHX",
        "outputId": "ccd096c8-2636-46fd-d9bd-3ef5b14545b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Successfully extracted /content/drive/MyDrive/records.zip to /content\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Define the path to the zip file in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/records.zip'\n",
        "\n",
        "# Define the extraction path\n",
        "extract_path = '/content'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Check if the zip file exists\n",
        "if os.path.exists(zip_file_path):\n",
        "    # Extract the zip file\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"Successfully extracted {zip_file_path} to {extract_path}\")\n",
        "else:\n",
        "    print(f\"Error: {zip_file_path} not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdLWrjEoInkc"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Config\n",
        "# -------------------------\n",
        "PATH = \"records\"\n",
        "SAMPLING_RATE = 500\n",
        "BATCH_SIZE = 32\n",
        "DROP_LAST = True\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJSNbPRaJIS4"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# utilities: filtering and peak detection\n",
        "# -------------------------\n",
        "def denoise(data):\n",
        "    # wavelet transform\n",
        "    coeffs = pywt.wavedec(data=data, wavelet='db5', level=9)\n",
        "    cA9, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1 = coeffs\n",
        "\n",
        "    # Threshold denoising\n",
        "    threshold = (np.median(np.abs(cD1)) / 0.6745) * (np.sqrt(2 * np.log(len(cD1))))\n",
        "    cD1.fill(0)\n",
        "    cD2.fill(0)\n",
        "    for i in range(1, len(coeffs) - 2):\n",
        "        coeffs[i] = pywt.threshold(coeffs[i], threshold)\n",
        "\n",
        "    # Inverse wavelet transform to obtain the denoised signal\n",
        "    rdata = pywt.waverec(coeffs=coeffs, wavelet='db5')\n",
        "    return rdata\n",
        "\n",
        "\n",
        "def pan_tompkins_detector(ecg_signal, fs):\n",
        "    lowcut, highcut = 5.0, 15.0\n",
        "    nyquist = 0.5 * fs\n",
        "    low, high = lowcut / nyquist, highcut / nyquist\n",
        "    b, a = butter(1, [low, high], btype='band')\n",
        "    filtered_ecg = filtfilt(b, a, ecg_signal)\n",
        "    diff_ecg = np.diff(filtered_ecg)\n",
        "    squared_ecg = diff_ecg ** 2\n",
        "    window_size = int(0.150 * fs)\n",
        "    mwa_ecg = np.convolve(squared_ecg, np.ones(window_size) / window_size, mode='same')\n",
        "    peaks, _ = find_peaks(mwa_ecg, distance=int(0.6 * fs))\n",
        "    return peaks\n",
        "\n",
        "\n",
        "def multi_lead_fusion(detected_peaks, fs, fusion_window=0.1, min_leads=None):\n",
        "    n_leads = len(detected_peaks)\n",
        "    if min_leads is None:\n",
        "        min_leads = int(np.ceil(n_leads / 2))\n",
        "\n",
        "    # Collect all peaks with their lead information\n",
        "    all_peaks = [(p, lead) for lead, peaks in enumerate(detected_peaks) for p in peaks]\n",
        "    all_peaks.sort(key=lambda x: x[0])\n",
        "\n",
        "    fused_peaks = []\n",
        "    i = 0\n",
        "\n",
        "    while i < len(all_peaks):\n",
        "        # Start a new cluster\n",
        "        cluster = [all_peaks[i]]\n",
        "        i += 1\n",
        "\n",
        "        # Add nearby peaks to the cluster\n",
        "        while i < len(all_peaks) and all_peaks[i][0] - cluster[-1][0] <= fusion_window * fs:\n",
        "            cluster.append(all_peaks[i])\n",
        "            i += 1\n",
        "\n",
        "        # Check if cluster has peaks from enough leads\n",
        "        unique_leads = {lead for _, lead in cluster}\n",
        "        if len(unique_leads) >= min_leads:\n",
        "            # Use median position as the fused peak\n",
        "            fused_peak = int(np.median([p for (p, _) in cluster]))\n",
        "            fused_peaks.append(fused_peak)\n",
        "\n",
        "    return np.array(sorted(fused_peaks))\n",
        "\n",
        "\n",
        "def detect_r_peaks(ecg_signals, fs):\n",
        "    detected_peaks = []\n",
        "    for lead in ecg_signals:\n",
        "        peaks = pan_tompkins_detector(lead, fs)\n",
        "        detected_peaks.append(peaks)\n",
        "\n",
        "    fused_r_peaks = multi_lead_fusion(detected_peaks, fs, fusion_window=0.1, min_leads=6)\n",
        "    return fused_r_peaks\n",
        "\n",
        "\n",
        "def extract_segments_around_peaks(signal, r_peaks, pre_samples, post_samples):\n",
        "    segments = []\n",
        "\n",
        "    for peak in r_peaks:\n",
        "        start = max(0, peak - pre_samples)\n",
        "        end = min(len(signal), peak + post_samples)\n",
        "\n",
        "        # Only include segments with the correct length\n",
        "        if end - start == pre_samples + post_samples:\n",
        "            segment = signal[start:end]\n",
        "            segments.append(segment)\n",
        "\n",
        "    return segments\n",
        "\n",
        "def extract_rr_beats_multi_lead(ecg_signals, fs, denoise_fn=None,\n",
        "                                min_rr_ms=300, max_rr_ms=1500, min_beats=2):\n",
        "    \"\"\"\n",
        "    Returns a list of beats, each beat is an array with shape (T_i, C) where C = n_leads.\n",
        "    \"\"\"\n",
        "    ecg = np.array(ecg_signals)\n",
        "    ecg = np.nan_to_num(ecg, nan=0.0, posinf=0.0, neginf=0.0)                 # (n_leads, n_samples)\n",
        "    eps = 1e-8\n",
        "    means = np.mean(ecg, axis=1, keepdims=True)\n",
        "    stds = np.std(ecg, axis=1, keepdims=True)\n",
        "\n",
        "    # Prevent division by zero or exploding values for flat-line signals\n",
        "    # If std is close to 0, set it to 1 (result will be 0/1 = 0, which is correct for flat line)\n",
        "    stds = np.where(stds < 1e-7, 1.0, stds)\n",
        "\n",
        "    ecg = (ecg - means) / stds\n",
        "\n",
        "    n_leads, n_samples = ecg.shape\n",
        "\n",
        "    if denoise_fn is not None:\n",
        "        ecg = np.array([denoise_fn(lead) for lead in ecg])\n",
        "\n",
        "    # Detect fused R-peaks once across leads\n",
        "    r_peaks = detect_r_peaks(ecg, fs)            # uses your multi-lead fusion\n",
        "    if len(r_peaks) < min_beats:\n",
        "        return None  # not enough beats\n",
        "\n",
        "    # RR in samples/ms\n",
        "    rr_samples = np.diff(r_peaks)\n",
        "    rr_ms = (rr_samples / fs) * 1000.0\n",
        "    valid = (rr_ms >= min_rr_ms) & (rr_ms <= max_rr_ms)\n",
        "    if valid.sum() == 0:\n",
        "        return None\n",
        "\n",
        "    beats = []\n",
        "    for i in range(len(r_peaks) - 1):\n",
        "        if not valid[i]:\n",
        "            continue\n",
        "        start = r_peaks[i]\n",
        "        end   = r_peaks[i+1]\n",
        "        seg = ecg[:, start:end].T                # (T_i, C)\n",
        "\n",
        "        if np.isnan(seg).any():\n",
        "            continue\n",
        "        if seg.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "        if seg.shape[0] > 0:\n",
        "            beats.append(seg.astype(np.float32))\n",
        "\n",
        "    if len(beats) == 0:\n",
        "        return None\n",
        "    return beats  # list of variable-length (T_i, C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTpLOqc4JgEI",
        "outputId": "98798a7a-14a6-4611-c572-52d2917249b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_classes: 11 labels: ['A', 'C', 'D', 'E', 'F', 'H', 'I', 'J', 'K', 'L', 'M']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n",
            "[Parallel(n_jobs=11)]: Done   3 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=11)]: Done  10 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=11)]: Done  19 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=11)]: Done  28 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=11)]: Done  39 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=11)]: Done  50 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=11)]: Done  63 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=11)]: Done  76 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=11)]: Done  91 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=11)]: Done 106 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=11)]: Done 123 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=11)]: Batch computation too fast (0.19748764738174937s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=11)]: Done 140 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=11)]: Batch computation too fast (0.17038679122924805s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=11)]: Done 164 tasks      | elapsed:    3.4s\n",
            "[Parallel(n_jobs=11)]: Done 206 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=11)]: Done 290 tasks      | elapsed:    4.0s\n",
            "[Parallel(n_jobs=11)]: Done 374 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=11)]: Done 466 tasks      | elapsed:    4.8s\n",
            "[Parallel(n_jobs=11)]: Done 558 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=11)]: Done 658 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=11)]: Done 758 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=11)]: Done 866 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=11)]: Done 974 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=11)]: Done 1090 tasks      | elapsed:    7.4s\n",
            "[Parallel(n_jobs=11)]: Done 1206 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=11)]: Done 1330 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=11)]: Done 1454 tasks      | elapsed:    8.9s\n",
            "[Parallel(n_jobs=11)]: Done 1586 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=11)]: Done 1718 tasks      | elapsed:   10.0s\n",
            "[Parallel(n_jobs=11)]: Done 1858 tasks      | elapsed:   10.6s\n",
            "[Parallel(n_jobs=11)]: Done 1998 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=11)]: Done 2146 tasks      | elapsed:   11.7s\n",
            "[Parallel(n_jobs=11)]: Done 2294 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=11)]: Done 2450 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=11)]: Done 2606 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=11)]: Done 2770 tasks      | elapsed:   14.5s\n",
            "[Parallel(n_jobs=11)]: Done 2934 tasks      | elapsed:   15.3s\n",
            "[Parallel(n_jobs=11)]: Done 3106 tasks      | elapsed:   16.0s\n",
            "[Parallel(n_jobs=11)]: Done 3278 tasks      | elapsed:   16.8s\n",
            "[Parallel(n_jobs=11)]: Done 3458 tasks      | elapsed:   17.6s\n",
            "[Parallel(n_jobs=11)]: Done 3638 tasks      | elapsed:   18.3s\n",
            "[Parallel(n_jobs=11)]: Done 3826 tasks      | elapsed:   19.2s\n",
            "[Parallel(n_jobs=11)]: Done 4014 tasks      | elapsed:   20.0s\n",
            "[Parallel(n_jobs=11)]: Done 4210 tasks      | elapsed:   20.8s\n",
            "[Parallel(n_jobs=11)]: Done 4406 tasks      | elapsed:   21.6s\n",
            "[Parallel(n_jobs=11)]: Done 4610 tasks      | elapsed:   22.4s\n",
            "[Parallel(n_jobs=11)]: Done 4814 tasks      | elapsed:   23.3s\n",
            "[Parallel(n_jobs=11)]: Done 5026 tasks      | elapsed:   24.1s\n",
            "[Parallel(n_jobs=11)]: Done 5238 tasks      | elapsed:   25.0s\n",
            "[Parallel(n_jobs=11)]: Done 5458 tasks      | elapsed:   25.9s\n",
            "[Parallel(n_jobs=11)]: Done 5678 tasks      | elapsed:   26.8s\n",
            "[Parallel(n_jobs=11)]: Done 5906 tasks      | elapsed:   27.8s\n",
            "[Parallel(n_jobs=11)]: Done 6134 tasks      | elapsed:   28.7s\n",
            "[Parallel(n_jobs=11)]: Done 6370 tasks      | elapsed:   29.7s\n",
            "[Parallel(n_jobs=11)]: Done 6606 tasks      | elapsed:   30.7s\n",
            "[Parallel(n_jobs=11)]: Done 6850 tasks      | elapsed:   31.8s\n",
            "[Parallel(n_jobs=11)]: Done 7094 tasks      | elapsed:   32.9s\n",
            "[Parallel(n_jobs=11)]: Done 7346 tasks      | elapsed:   34.0s\n",
            "[Parallel(n_jobs=11)]: Done 7598 tasks      | elapsed:   35.2s\n",
            "[Parallel(n_jobs=11)]: Done 7858 tasks      | elapsed:   36.5s\n",
            "[Parallel(n_jobs=11)]: Done 8118 tasks      | elapsed:   37.7s\n",
            "[Parallel(n_jobs=11)]: Done 8386 tasks      | elapsed:   39.1s\n",
            "[Parallel(n_jobs=11)]: Done 8654 tasks      | elapsed:   40.4s\n",
            "[Parallel(n_jobs=11)]: Done 8930 tasks      | elapsed:   41.7s\n",
            "[Parallel(n_jobs=11)]: Done 9206 tasks      | elapsed:   43.0s\n",
            "[Parallel(n_jobs=11)]: Done 9490 tasks      | elapsed:   44.3s\n",
            "[Parallel(n_jobs=11)]: Done 9774 tasks      | elapsed:   45.6s\n",
            "[Parallel(n_jobs=11)]: Done 10066 tasks      | elapsed:   47.1s\n",
            "[Parallel(n_jobs=11)]: Done 10358 tasks      | elapsed:   48.5s\n",
            "[Parallel(n_jobs=11)]: Done 10658 tasks      | elapsed:   50.0s\n",
            "[Parallel(n_jobs=11)]: Done 10958 tasks      | elapsed:   51.4s\n",
            "[Parallel(n_jobs=11)]: Done 11266 tasks      | elapsed:   52.8s\n",
            "[Parallel(n_jobs=11)]: Done 11574 tasks      | elapsed:   54.1s\n",
            "[Parallel(n_jobs=11)]: Done 11890 tasks      | elapsed:   55.4s\n",
            "[Parallel(n_jobs=11)]: Done 12206 tasks      | elapsed:   56.7s\n",
            "[Parallel(n_jobs=11)]: Done 12530 tasks      | elapsed:   58.0s\n",
            "[Parallel(n_jobs=11)]: Done 12854 tasks      | elapsed:   59.4s\n",
            "[Parallel(n_jobs=11)]: Done 13186 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=11)]: Done 13518 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=11)]: Done 13858 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=11)]: Done 14198 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=11)]: Done 14546 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=11)]: Done 14894 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=11)]: Done 15250 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=11)]: Done 15606 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=11)]: Done 15970 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=11)]: Done 16334 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=11)]: Done 16706 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=11)]: Done 17078 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=11)]: Done 17458 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=11)]: Done 17838 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=11)]: Done 18226 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=11)]: Done 18614 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=11)]: Done 19010 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=11)]: Done 19406 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=11)]: Done 19810 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=11)]: Done 20214 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=11)]: Done 20626 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=11)]: Done 21038 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=11)]: Done 21458 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=11)]: Done 21878 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=11)]: Done 22025 out of 22046 | elapsed:  1.6min remaining:    0.1s\n",
            "[Parallel(n_jobs=11)]: Done 22046 out of 22046 | elapsed:  1.6min finished\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing as mp\n",
        "\n",
        "# -------------------------\n",
        "metadata = pd.read_csv(\"metadata.csv\")\n",
        "codes = pd.read_csv(\"code.csv\")\n",
        "\n",
        "code_mappings = dict(zip(codes['Code'].astype(str), codes['Category']))\n",
        "\n",
        "metadata = metadata[~metadata['AHA_Code'].str.contains(\";\")]\n",
        "metadata['AHA_Code'] = metadata['AHA_Code'].str.split(\"+\").str[0]\n",
        "metadata['AHA_Code_Mapped'] = metadata['AHA_Code'].map(code_mappings)\n",
        "\n",
        "unique_labels = sorted(metadata['AHA_Code_Mapped'].dropna().unique())\n",
        "label2idx = {lbl: i for i, lbl in enumerate(unique_labels)}\n",
        "num_classes = len(unique_labels)\n",
        "\n",
        "print(\"num_classes:\", num_classes, \"labels:\", unique_labels)\n",
        "\n",
        "def process_row(row):\n",
        "    ecg_data_path = os.path.join(PATH, row.ECG_ID + \".h5\")\n",
        "    if not os.path.exists(ecg_data_path):\n",
        "        return None\n",
        "    try:\n",
        "        with h5py.File(ecg_data_path, 'r') as f:\n",
        "            ecg = np.array(f['ecg'])  # shape (n_leads, n_samples)\n",
        "    except Exception as e:\n",
        "        print(\"error reading\", ecg_data_path, e)\n",
        "        return None\n",
        "\n",
        "    beats = extract_rr_beats_multi_lead(ecg, fs=SAMPLING_RATE, denoise_fn=denoise)\n",
        "    if beats is None:\n",
        "        return None\n",
        "\n",
        "    label = row.AHA_Code_Mapped\n",
        "    if pd.isna(label):\n",
        "        return None\n",
        "    if label not in label2idx:\n",
        "        return None\n",
        "\n",
        "    return ((beats, label2idx[label]))\n",
        "\n",
        "# Use all physical cores by default\n",
        "n_jobs = max(1, mp.cpu_count() - 1)\n",
        "\n",
        "results = Parallel(\n",
        "    n_jobs=n_jobs,\n",
        "    backend=\"loky\",\n",
        "    verbose=10\n",
        ")(\n",
        "    delayed(process_row)(row)\n",
        "    for row in metadata.itertuples(index=False)\n",
        ")\n",
        "\n",
        "data_list = [r for r in results if r is not None]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs7wTSUUL2wR"
      },
      "outputs": [],
      "source": [
        "# ---------- Length-bucketing Batch Sampler ----------\n",
        "class LengthBucketBatchSampler(Sampler):\n",
        "    def __init__(self,\n",
        "                 lengths: List[int],\n",
        "                 batch_size: int,\n",
        "                 bin_size: Optional[int] = None,\n",
        "                 shuffle: bool = True,\n",
        "                 drop_last: bool = False):\n",
        "        self.lengths = list(lengths)\n",
        "        self.batch_size = int(batch_size)\n",
        "        self.bin_size = bin_size\n",
        "        self.shuffle = shuffle\n",
        "        self.drop_last = drop_last\n",
        "\n",
        "        # Build mapping length_key -> list of indices\n",
        "        self._buckets = defaultdict(list)\n",
        "        for idx, L in enumerate(self.lengths):\n",
        "            key = self._length_key(L)\n",
        "            self._buckets[key].append(idx)\n",
        "\n",
        "        # Convert to normal dict for iteration; keep keys list stable\n",
        "        self.bucket_keys = list(self._buckets.keys())\n",
        "\n",
        "    def _length_key(self, length: int) -> int:\n",
        "        if self.bin_size is None or self.bin_size <= 0:\n",
        "            return int(length)   # exact-length bucket\n",
        "        else:\n",
        "            return (length // self.bin_size) * self.bin_size\n",
        "\n",
        "    def __iter__(self):\n",
        "      # For each epoch, build batches from buckets.\n",
        "      batches = []\n",
        "      for key in self.bucket_keys:\n",
        "          idxs = list(self._buckets[key])\n",
        "          if len(idxs) < self.batch_size:\n",
        "              # skip this bucket entirely\n",
        "              continue\n",
        "          if self.shuffle:\n",
        "              random.shuffle(idxs)\n",
        "          # chunk into batches\n",
        "          for i in range(0, len(idxs), self.batch_size):\n",
        "              batch = idxs[i:i + self.batch_size]\n",
        "              if len(batch) < self.batch_size and self.drop_last:\n",
        "                  continue\n",
        "              batches.append(batch)\n",
        "\n",
        "      if self.shuffle:\n",
        "          random.shuffle(batches)\n",
        "\n",
        "      for batch in batches:\n",
        "          yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        total = 0\n",
        "        for key in self.bucket_keys:\n",
        "            n = len(self._buckets[key])\n",
        "            if self.drop_last:\n",
        "                total += n // self.batch_size\n",
        "            else:\n",
        "                total += math.ceil(n / self.batch_size)\n",
        "        return total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dam8A7JIK2DU"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Dataset + Sampler + DataLoader\n",
        "# # -------------------------\n",
        "\n",
        "class ECGSegmentDatasetVarLen(Dataset):\n",
        "    def __init__(self, data_list):\n",
        "        self.data = data_list\n",
        "        # number of beats per record for length-bucketing by S\n",
        "        self.num_beats = [len(x[0]) for x in data_list]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        beats_list, label = self.data[idx]\n",
        "        # convert each beat to torch tensor\n",
        "        beats_tensors = [torch.from_numpy(b) if isinstance(b, np.ndarray) else torch.tensor(b)\n",
        "                         for b in beats_list]  # [(T_i, C), ...]\n",
        "        return {\"beats\": beats_tensors, \"label\": int(label), \"num_beats\": len(beats_tensors)}\n",
        "\n",
        "\n",
        "def collate_by_num_beats(batch):\n",
        "    s_vals = [item[\"num_beats\"] for item in batch]\n",
        "    if not all(s == s_vals[0] for s in s_vals):\n",
        "        raise ValueError(\"collate_by_num_beats received mixed num_beats in a batch\")\n",
        "    signals = torch.stack([item[\"signal\"] for item in batch], dim=0)  # (B, S, T, C)\n",
        "    labels = torch.tensor([item[\"label\"] for item in batch], dtype=torch.long)\n",
        "    return {\"signal\": signals, \"label\": labels, \"num_beats\": torch.tensor(s_vals, dtype=torch.long)}\n",
        "\n",
        "\n",
        "def pad_collate_varlen(batch):\n",
        "    B = len(batch)\n",
        "    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n",
        "    S_vals = [b[\"num_beats\"] for b in batch]\n",
        "    if not all(S_vals[0] == s for s in S_vals):\n",
        "        raise ValueError(\"Bucketed sampler should ensure same #beats (S) per batch.\")\n",
        "\n",
        "    S = S_vals[0]\n",
        "    C = batch[0][\"beats\"][0].shape[1]\n",
        "    # T_max across all beats of all items\n",
        "    T_max = max(beat.shape[0] for item in batch for beat in item[\"beats\"])\n",
        "\n",
        "    signal = torch.zeros((B, S, T_max, C), dtype=torch.float32)\n",
        "    mask   = torch.zeros((B, S, T_max),   dtype=torch.float32)\n",
        "\n",
        "    for bi, item in enumerate(batch):\n",
        "        for si, beat in enumerate(item[\"beats\"]):\n",
        "            T = beat.shape[0]\n",
        "            signal[bi, si, :T, :] = beat\n",
        "            mask[bi, si, :T] = 1.0\n",
        "\n",
        "    return {\"signal\": signal, \"mask\": mask, \"label\": labels,\n",
        "            \"num_beats\": torch.tensor(S_vals, dtype=torch.long)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6tvcFTaK4d6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "# # instantiate dataset and sampler\n",
        "ds = ECGSegmentDatasetVarLen(data_list)\n",
        "\n",
        "# -------------------------\n",
        "# Split indices\n",
        "# -------------------------\n",
        "all_indices = list(range(len(ds)))\n",
        "all_labels = [data_list[i][1] for i in all_indices]  # label_idx for each sample\n",
        "\n",
        "# First split: train+val vs test (stratified)\n",
        "trainval_indices, test_indices = train_test_split(\n",
        "    all_indices,\n",
        "    test_size=0.1,\n",
        "    random_state=10,\n",
        "    stratify=all_labels \n",
        ")\n",
        "\n",
        "# Extract labels for the trainval subset\n",
        "trainval_labels = [all_labels[i] for i in trainval_indices]\n",
        "\n",
        "# Second split: train vs val (stratified)\n",
        "train_indices, val_indices = train_test_split(\n",
        "    trainval_indices,\n",
        "    test_size=0.1,\n",
        "    random_state=10,\n",
        "    stratify=trainval_labels \n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Create Subsets\n",
        "# -------------------------\n",
        "train_ds = Subset(ds, train_indices)\n",
        "val_ds   = Subset(ds, val_indices)\n",
        "test_ds  = Subset(ds, test_indices)\n",
        "\n",
        "# -------------------------\n",
        "# Make loader helper\n",
        "# -------------------------\n",
        "def make_loader(subset_ds, batch_size=16, drop_last=True, shuffle=True):\n",
        "    subset_indices = subset_ds.indices\n",
        "    lengths = [ds.num_beats[i] for i in subset_indices]\n",
        "    sampler = LengthBucketBatchSampler(lengths, batch_size, bin_size=None,\n",
        "                                       shuffle=shuffle, drop_last=drop_last)\n",
        "    loader = DataLoader(subset_ds, batch_sampler=sampler,\n",
        "                        collate_fn=pad_collate_varlen,\n",
        "                        num_workers=0, pin_memory=True)\n",
        "    return loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4uGlP9vh0IL",
        "outputId": "146ac3cf-833f-4e91-e61c-25c6738f404f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train distribution: Counter({0: 11218, 9: 2190, 1: 2081, 6: 1093, 4: 408, 7: 282, 3: 215, 2: 211, 10: 45, 5: 29, 8: 21})\n",
            "Val distribution: Counter({0: 1246, 9: 244, 1: 231, 6: 122, 4: 46, 7: 31, 3: 24, 2: 23, 10: 5, 5: 3, 8: 2})\n",
            "Test distribution: Counter({0: 1385, 9: 271, 1: 257, 6: 135, 4: 50, 7: 35, 2: 26, 3: 26, 10: 6, 8: 3, 5: 3})\n"
          ]
        }
      ],
      "source": [
        "# Verifying stratifying\n",
        "train_loader = make_loader(train_ds, batch_size=BATCH_SIZE)\n",
        "val_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader  = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "def get_label_distribution(indices):\n",
        "    labels = [data_list[i][1] for i in indices]\n",
        "    return Counter(labels)\n",
        "\n",
        "print(\"Train distribution:\", get_label_distribution(train_indices))\n",
        "print(\"Val distribution:\", get_label_distribution(val_indices))\n",
        "print(\"Test distribution:\", get_label_distribution(test_indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTH5m7jHMjD9"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Attention / helper layers\n",
        "# -------------------------\n",
        "class ChannelAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Expects x shape = (batch, channels, seq_len)\n",
        "    \"\"\"\n",
        "    def __init__(self, channels, ratio=8):\n",
        "        super().__init__()\n",
        "        mid = max(1, channels // ratio)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(channels, mid, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(mid, channels, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, L)\n",
        "        avg_pool = torch.mean(x, dim=2)           # (B, C)\n",
        "        max_pool, _ = torch.max(x, dim=2)         # (B, C)\n",
        "        avg_out = self.mlp(avg_pool)              # (B, C)\n",
        "        max_out = self.mlp(max_pool)              # (B, C)\n",
        "        att = torch.sigmoid(avg_out + max_out)    # (B, C)\n",
        "        att = att.unsqueeze(2)                    # (B, C, 1)\n",
        "        return x * att                             # broadcast multiply -> (B, C, L)\n",
        "\n",
        "class SegmentAttention(nn.Module):\n",
        "    def __init__(self, input_dim, units):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_dim, units, bias=True)\n",
        "        self.u = nn.Parameter(torch.randn(units))\n",
        "\n",
        "    def forward(self, inputs, mask=None):\n",
        "        \"\"\"\n",
        "        inputs: (B, T, D)\n",
        "        mask:   (B, T) with 1=valid, 0=pad (or None)\n",
        "        \"\"\"\n",
        "        v = torch.tanh(self.linear(inputs))             # (B, T, units)\n",
        "        vu = torch.matmul(v, self.u)                    # (B, T)\n",
        "        if mask is not None:\n",
        "            # set -inf (large negative) where mask==0 so softmax->0\n",
        "            vu = vu.masked_fill(mask == 0, -1e9)\n",
        "        alphas = F.softmax(vu, dim=1)                   # (B, T)\n",
        "        alphas = torch.nan_to_num(alphas, nan=0.0)\n",
        "        output = torch.sum(inputs * alphas.unsqueeze(-1), dim=1)  # (B, D)\n",
        "        return output, alphas\n",
        "\n",
        "class TimeDistributedSegmentAttention(nn.Module):\n",
        "    def __init__(self, input_dim, units):\n",
        "        super().__init__()\n",
        "        self.segment_attention = SegmentAttention(input_dim, units)\n",
        "\n",
        "    def forward(self, inputs, mask=None):\n",
        "        \"\"\"\n",
        "        inputs: (B, S, T, D)\n",
        "        mask:   (B, S, T) or None\n",
        "        \"\"\"\n",
        "        B, S, T, D = inputs.shape\n",
        "        flat = inputs.view(B * S, T, D)                         # (B*S, T, D)\n",
        "        if mask is not None:\n",
        "            mask_flat = mask.view(B * S, T)                     # (B*S, T)\n",
        "        else:\n",
        "            mask_flat = None\n",
        "        outputs, alphas = self.segment_attention(flat, mask_flat)  # (B*S, D), (B*S, T)\n",
        "        outputs = outputs.view(B, S, D)                         # (B, S, D)\n",
        "        alphas  = alphas.view(B, S, T)                          # (B, S, T)\n",
        "        return outputs, alphas\n",
        "\n",
        "class HANWithAttention(nn.Module):\n",
        "    def __init__(self, num_classes=11):\n",
        "        super().__init__()\n",
        "        self.conv1d = nn.Conv1d(in_channels=12, out_channels=128, kernel_size=25, padding=12)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.channel_attention = ChannelAttention(128, ratio=8)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "        self.lstm_segment = nn.LSTM(input_size=128, hidden_size=256, batch_first=True)\n",
        "        self.time_distributed_attention = TimeDistributedSegmentAttention(input_dim=256, units=256)\n",
        "        self.lstm_sequence = nn.LSTM(input_size=256, hidden_size=512, batch_first=True)\n",
        "        self.final_attention = SegmentAttention(input_dim=512, units=512)\n",
        "        self.fc = nn.Linear(512, 2048)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.classifier = nn.Linear(2048, num_classes)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        logits, _, _ = self.forward_with_attention(x, mask)\n",
        "        return logits\n",
        "\n",
        "    def forward_with_attention(self, x, mask=None):\n",
        "        \"\"\"\n",
        "        x:    (B, S, T, C)\n",
        "        mask: (B, S, T) with 1=valid, 0=pad (or None)\n",
        "        \"\"\"\n",
        "        B, S, T, C = x.shape\n",
        "        x = x.view(B * S, T, C).permute(0, 2, 1)    # (B*S, C, T)\n",
        "\n",
        "        conv = self.conv1d(x)                       # (B*S, 128, T)\n",
        "        conv = self.bn1(conv)\n",
        "        conv = F.relu(conv)\n",
        "        att  = self.channel_attention(conv)         # (B*S, 128, T)\n",
        "        pooled = self.pool(att)                     # (B*S, 128, T2)\n",
        "        pooled = pooled.permute(0, 2, 1)            # (B*S, T2, 128)\n",
        "\n",
        "        # Downsample mask to T2 with the same pooling parameters\n",
        "        if mask is not None:\n",
        "            m = mask.view(B * S, 1, T)              # (B*S, 1, T)\n",
        "            m2 = F.max_pool1d(m, kernel_size=3, stride=2, padding=1)  # (B*S, 1, T2)\n",
        "            m2 = (m2 > 0.0).float().squeeze(1)      # (B*S, T2)\n",
        "        else:\n",
        "            m2 = None\n",
        "\n",
        "        seg_lstm_out, _ = self.lstm_segment(pooled) # (B*S, T2, 256)\n",
        "        seg_lstm_out = seg_lstm_out.view(B, S, seg_lstm_out.shape[1], seg_lstm_out.shape[2])  # (B, S, T2, 256)\n",
        "        if m2 is not None:\n",
        "            m2 = m2.view(B, S, -1)                  # (B, S, T2)\n",
        "\n",
        "        segment_outputs, segment_alphas = self.time_distributed_attention(seg_lstm_out, mask=m2)  # (B, S, 256), (B, S, T2)\n",
        "        seq_lstm_out, _ = self.lstm_sequence(segment_outputs)                                     # (B, S, 512)\n",
        "        final_output, final_alphas = self.final_attention(seq_lstm_out)                           # (B, 512), (B, S)\n",
        "\n",
        "        x = F.relu(self.fc(final_output))\n",
        "        x = self.dropout(x)\n",
        "        logits = self.classifier(x)                 # (B, num_classes)\n",
        "        return logits, final_alphas, segment_alphas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEp5ILUE8CqG",
        "outputId": "52341668-668e-4ffc-94eb-377428d97658"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================================================================================================\n",
              "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Trainable\n",
              "=================================================================================================================================================\n",
              "HANWithAttention                              [2, 10, 300, 12]          [2, 11]                   --                        True\n",
              "├─Conv1d: 1-1                                 [20, 12, 300]             [20, 128, 300]            38,528                    True\n",
              "├─BatchNorm1d: 1-2                            [20, 128, 300]            [20, 128, 300]            256                       True\n",
              "├─ChannelAttention: 1-3                       [20, 128, 300]            [20, 128, 300]            --                        True\n",
              "│    └─Sequential: 2-1                        [20, 128]                 [20, 128]                 --                        True\n",
              "│    │    └─Linear: 3-1                       [20, 128]                 [20, 16]                  2,064                     True\n",
              "│    │    └─ReLU: 3-2                         [20, 16]                  [20, 16]                  --                        --\n",
              "│    │    └─Linear: 3-3                       [20, 16]                  [20, 128]                 2,176                     True\n",
              "│    └─Sequential: 2-2                        [20, 128]                 [20, 128]                 (recursive)               True\n",
              "│    │    └─Linear: 3-4                       [20, 128]                 [20, 16]                  (recursive)               True\n",
              "│    │    └─ReLU: 3-5                         [20, 16]                  [20, 16]                  --                        --\n",
              "│    │    └─Linear: 3-6                       [20, 16]                  [20, 128]                 (recursive)               True\n",
              "├─MaxPool1d: 1-4                              [20, 128, 300]            [20, 128, 150]            --                        --\n",
              "├─LSTM: 1-5                                   [20, 150, 128]            [20, 150, 256]            395,264                   True\n",
              "├─TimeDistributedSegmentAttention: 1-6        [2, 10, 150, 256]         [2, 10, 256]              --                        True\n",
              "│    └─SegmentAttention: 2-3                  [20, 150, 256]            [20, 256]                 256                       True\n",
              "│    │    └─Linear: 3-7                       [20, 150, 256]            [20, 150, 256]            65,792                    True\n",
              "├─LSTM: 1-7                                   [2, 10, 256]              [2, 10, 512]              1,576,960                 True\n",
              "├─SegmentAttention: 1-8                       [2, 10, 512]              [2, 512]                  512                       True\n",
              "│    └─Linear: 2-4                            [2, 10, 512]              [2, 10, 512]              262,656                   True\n",
              "├─Linear: 1-9                                 [2, 512]                  [2, 2048]                 1,050,624                 True\n",
              "├─Dropout: 1-10                               [2, 2048]                 [2, 2048]                 --                        --\n",
              "├─Linear: 1-11                                [2, 2048]                 [2, 11]                   22,539                    True\n",
              "=================================================================================================================================================\n",
              "Total params: 3,417,627\n",
              "Trainable params: 3,417,627\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 1.45\n",
              "=================================================================================================================================================\n",
              "Input size (MB): 0.29\n",
              "Forward/backward pass size (MB): 24.82\n",
              "Params size (MB): 13.67\n",
              "Estimated Total Size (MB): 38.77\n",
              "================================================================================================================================================="
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = HANWithAttention(num_classes=11).to(device)\n",
        "\n",
        "summary(model,\n",
        "        input_size=(2, 10, 300, 12),    # this wouldn't be the actual size for r-r interval splitting\n",
        "        col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n",
        "        depth=4,\n",
        "        device=device.type)            # \"cpu\" or \"cuda\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZstNbOkxMugd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_metrics(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_labels, all_preds, all_probs = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            inputs = batch[\"signal\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "            labels = labels.cpu().numpy()\n",
        "\n",
        "            all_labels.extend(labels)\n",
        "            all_preds.extend(preds)\n",
        "            all_probs.extend(probs)\n",
        "\n",
        "    avg_loss = running_loss / len(all_labels)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "\n",
        "    try:\n",
        "      y_true = np.eye(num_classes)[all_labels]\n",
        "      y_score = np.array(all_probs)\n",
        "\n",
        "      auc_list = []\n",
        "      for i in range(num_classes):\n",
        "          if np.any(y_true[:, i]):  # class i exists\n",
        "              auc_list.append(roc_auc_score(y_true[:, i], y_score[:, i]))\n",
        "      if auc_list:\n",
        "          auc = np.mean(auc_list)\n",
        "      else:\n",
        "          auc = float(\"nan\")\n",
        "    except ValueError:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return avg_loss, acc, precision, recall, auc, f1\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer, criterion, device,\n",
        "          epochs, scheduler=None):\n",
        "    model.to(device)\n",
        "    history = {\n",
        "        \"train_loss\": [], \"train_acc\": [], \"train_f1\": [], \"train_precision\": [], \"train_recall\": [], \"train_auc\": [],\n",
        "        \"val_loss\": [],   \"val_acc\": [],   \"val_f1\": [],   \"val_precision\": [],   \"val_recall\": [], \"val_auc\": []\n",
        "    }\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        all_preds = []\n",
        "        all_probs = []\n",
        "        all_labels = []\n",
        "        steps = 0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False)\n",
        "        for batch in loop:\n",
        "            inputs = batch[\"signal\"].to(device)     # (B,S,T_max,C)\n",
        "            mask   = batch[\"mask\"].to(device)       # (B,S,T_max)\n",
        "            labels = batch[\"label\"].to(device)  \n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            outputs = model(inputs, mask=mask)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_size = labels.size(0)\n",
        "            running_loss += loss.item() * batch_size\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            probs = torch.softmax(outputs, dim=1).detach().cpu().numpy()\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += batch_size\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy().tolist())\n",
        "            all_probs.extend(probs.tolist())\n",
        "            all_labels.extend(labels.cpu().numpy().tolist())\n",
        "\n",
        "            steps += 1\n",
        "            loop.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{(correct/total):.4f}\")\n",
        "\n",
        "        if scheduler is not None:\n",
        "            try:\n",
        "                scheduler.step()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        if total == 0:\n",
        "            epoch_loss = float(\"nan\")\n",
        "            epoch_acc = float(\"nan\")\n",
        "            epoch_precision = epoch_recall = epoch_f1 = float(\"nan\")\n",
        "        else:\n",
        "            epoch_loss = running_loss / total\n",
        "            epoch_acc = correct / total\n",
        "            epoch_precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "            epoch_recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "            epoch_f1 = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "            try:\n",
        "              y_true = np.eye(num_classes)[all_labels]\n",
        "              y_score = np.array(all_probs)\n",
        "\n",
        "              auc_list = []\n",
        "              for i in range(num_classes):\n",
        "                  if np.any(y_true[:, i]):\n",
        "                      auc_list.append(roc_auc_score(y_true[:, i], y_score[:, i]))\n",
        "              if auc_list:\n",
        "                  auc = np.mean(auc_list)\n",
        "              else:\n",
        "                  auc = float(\"nan\")\n",
        "            except ValueError:\n",
        "                auc = float(\"nan\")\n",
        "\n",
        "        # append train history\n",
        "        history[\"train_loss\"].append(epoch_loss)\n",
        "        history[\"train_auc\"].append(auc)\n",
        "        history[\"train_acc\"].append(epoch_acc)\n",
        "        history[\"train_precision\"].append(epoch_precision)\n",
        "        history[\"train_recall\"].append(epoch_recall)\n",
        "        history[\"train_f1\"].append(epoch_f1)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{epochs}  train_loss: {epoch_loss:.4f}  train_acc: {epoch_acc:.4f}  train_f1: {epoch_f1:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        if val_loader is not None:\n",
        "            vloss, vacc, vprecision, vrecall, vauc, vf1 = evaluate_metrics(model, val_loader, criterion, device)\n",
        "            history[\"val_loss\"].append(vloss)\n",
        "            history[\"val_acc\"].append(vacc)\n",
        "            history[\"val_auc\"].append(vauc)\n",
        "            history[\"val_f1\"].append(vf1)\n",
        "            history[\"val_precision\"].append(vprecision)\n",
        "            history[\"val_recall\"].append(vrecall)\n",
        "\n",
        "\n",
        "            # log per-epoch metrics to mlflow if available\n",
        "            if 'mlflow' in globals():\n",
        "                try:\n",
        "                    mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
        "                    mlflow.log_metric(\"train_f1\", epoch_f1, step=epoch)\n",
        "                    mlflow.log_metric(\"train_precision\", epoch_precision, step=epoch)\n",
        "                    mlflow.log_metric(\"train_recall\", epoch_recall, step=epoch)\n",
        "                    mlflow.log_metric(\"train_acc\", epoch_acc, step=epoch)\n",
        "                    mlflow.log_metric(\"train_auc\", auc, step=epoch)\n",
        "\n",
        "                    mlflow.log_metric(\"val_loss\", vloss, step=epoch)\n",
        "                    mlflow.log_metric(\"val_f1\", vf1, step=epoch)\n",
        "                    mlflow.log_metric(\"val_precision\", vprecision, step=epoch)\n",
        "                    mlflow.log_metric(\"val_recall\", vrecall, step=epoch)\n",
        "                    mlflow.log_metric(\"val_acc\", vacc, step=epoch)\n",
        "                    mlflow.log_metric(\"val_auc\", vauc, step=epoch)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            tqdm.write(\n",
        "                f\"Epoch {epoch}  train_loss {epoch_loss:.4f} | val_loss {vloss:.4f} | \"\n",
        "                f\"val_f1 {vf1:.4f} | val_precision {vprecision:.4f} | val_recall {vrecall:.4f} | val_auc {vauc:.4f}\"\n",
        "            )\n",
        "        else:\n",
        "            # keep consistent history lengths\n",
        "            history[\"val_loss\"].append(None)\n",
        "            history[\"val_auc\"].append(None)\n",
        "            history[\"val_acc\"].append(None)\n",
        "            history[\"val_f1\"].append(None)\n",
        "            history[\"val_precision\"].append(None)\n",
        "            history[\"val_recall\"].append(None)\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKHGeA-VQrON"
      },
      "source": [
        "# -------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y69phNTc0vxd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "def run_experiments(model_fn,\n",
        "                    optimizer_fn, criterion, device, epochs, num_classes,\n",
        "                    seeds=10):\n",
        "\n",
        "  results = {\"acc\": [], \"precision\": [], \"recall\": [], \"auc\": [], \"loss\": []}\n",
        "  print(\"run exp\")\n",
        "  for seed in range(4, 10 ):\n",
        "      print(f\"\\n=== Seed {seed} ===\")\n",
        "      set_seed(seed)\n",
        "      ds = ECGSegmentDatasetVarLen(data_list)\n",
        "\n",
        "      all_indices = list(range(len(ds)))\n",
        "      all_labels = [data_list[i][1] for i in all_indices]  # label_idx for each sample\n",
        "\n",
        "      # First split: train+val vs test (stratified)\n",
        "      trainval_indices, test_indices = train_test_split(\n",
        "          all_indices,\n",
        "          test_size=0.1,\n",
        "          random_state=seed,\n",
        "          stratify=all_labels  # ← stratify by class labels\n",
        "      )\n",
        "\n",
        "      # Extract labels for the trainval subset\n",
        "      trainval_labels = [all_labels[i] for i in trainval_indices]\n",
        "\n",
        "      # Second split: train vs val (stratified)\n",
        "      train_indices, val_indices = train_test_split(\n",
        "          trainval_indices,\n",
        "          test_size=0.1,\n",
        "          random_state=seed,\n",
        "          stratify=trainval_labels  # ← stratify by class labels\n",
        "      )\n",
        "\n",
        "      # -------------------------\n",
        "      # Create Subsets\n",
        "      # -------------------------\n",
        "      train_ds = Subset(ds, train_indices)\n",
        "      val_ds   = Subset(ds, val_indices)\n",
        "      test_ds  = Subset(ds, test_indices)\n",
        "\n",
        "      train_loader = make_loader(train_ds, batch_size=BATCH_SIZE)\n",
        "      val_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "      test_loader  = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "      print(\"Train distribution:\", get_label_distribution(train_indices))\n",
        "      print(\"Val distribution:\", get_label_distribution(val_indices))\n",
        "      print(\"Test distribution:\", get_label_distribution(test_indices))\n",
        "\n",
        "      model = model_fn().to(device)\n",
        "      optimizer = optimizer_fn(model)\n",
        "      scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "      # Train\n",
        "      with mlflow.start_run(nested=True, run_name=f\"HAN-SPH-SEED-{seed}\"):\n",
        "        _ = train(model, train_loader, val_loader, optimizer, criterion, device, epochs, scheduler)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        loss, acc, precision, recall, auc, f1 = evaluate_metrics(model, test_loader, criterion, device)\n",
        "\n",
        "        print(f\"Test (seed {seed}) — loss: {loss:.4f}, acc: {acc:.4f}, \"\n",
        "            f\"precision: {precision:.4f}, recall: {recall:.4f}, auc: {auc:.4f}, f1: {f1:.4f}\")\n",
        "\n",
        "      results[\"loss\"].append(loss)\n",
        "      results[\"acc\"].append(acc)\n",
        "      results[\"precision\"].append(precision)\n",
        "      results[\"recall\"].append(recall)\n",
        "      results[\"auc\"].append(auc)\n",
        "\n",
        "  # Aggregate results\n",
        "  print(\"\\n=== Final Results (across seeds) ===\")\n",
        "  for k, v in results.items():\n",
        "      arr = np.array(v, dtype=np.float32)\n",
        "      print(f\"{k}: mean={arr.mean():.4f}, std={arr.std():.4f}\")\n",
        "\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76xZ_p8601Es"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  return HANWithAttention(num_classes=num_classes)\n",
        "\n",
        "def optimizer_fn(model):\n",
        "  return torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxs3CDseTbSz"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "run_experiments(model_fn, optimizer_fn, criterion, DEVICE, 30, 11, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU0OMFca7iI7",
        "outputId": "ca2a1892-6464-4793-aa81-76fb0cb92aa1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================================================================================================\n",
              "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Trainable\n",
              "=================================================================================================================================================\n",
              "HANWithAttention                              [2, 10, 300, 12]          [2, 11]                   --                        True\n",
              "├─Conv1d: 1-1                                 [20, 12, 300]             [20, 128, 300]            38,528                    True\n",
              "├─ChannelAttention: 1-2                       [20, 128, 300]            [20, 128, 300]            --                        True\n",
              "│    └─Sequential: 2-1                        [20, 128]                 [20, 128]                 --                        True\n",
              "│    │    └─Linear: 3-1                       [20, 128]                 [20, 16]                  2,064                     True\n",
              "│    │    └─ReLU: 3-2                         [20, 16]                  [20, 16]                  --                        --\n",
              "│    │    └─Linear: 3-3                       [20, 16]                  [20, 128]                 2,176                     True\n",
              "│    └─Sequential: 2-2                        [20, 128]                 [20, 128]                 (recursive)               True\n",
              "│    │    └─Linear: 3-4                       [20, 128]                 [20, 16]                  (recursive)               True\n",
              "│    │    └─ReLU: 3-5                         [20, 16]                  [20, 16]                  --                        --\n",
              "│    │    └─Linear: 3-6                       [20, 16]                  [20, 128]                 (recursive)               True\n",
              "├─MaxPool1d: 1-3                              [20, 128, 300]            [20, 128, 150]            --                        --\n",
              "├─LSTM: 1-4                                   [20, 150, 128]            [20, 150, 128]            132,096                   True\n",
              "├─TimeDistributedSegmentAttention: 1-5        [2, 10, 150, 128]         [2, 10, 128]              --                        True\n",
              "│    └─SegmentAttention: 2-3                  [20, 150, 128]            [20, 128]                 128                       True\n",
              "│    │    └─Linear: 3-7                       [20, 150, 128]            [20, 150, 128]            16,512                    True\n",
              "├─LSTM: 1-6                                   [2, 10, 128]              [2, 10, 512]              1,314,816                 True\n",
              "├─SegmentAttention: 1-7                       [2, 10, 512]              [2, 512]                  512                       True\n",
              "│    └─Linear: 2-4                            [2, 10, 512]              [2, 10, 512]              262,656                   True\n",
              "├─Linear: 1-8                                 [2, 512]                  [2, 512]                  262,656                   True\n",
              "├─Dropout: 1-9                                [2, 512]                  [2, 512]                  --                        --\n",
              "├─Linear: 1-10                                [2, 512]                  [2, 11]                   5,643                     True\n",
              "=================================================================================================================================================\n",
              "Total params: 2,037,787\n",
              "Trainable params: 2,037,787\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 655.31\n",
              "=================================================================================================================================================\n",
              "Input size (MB): 0.29\n",
              "Forward/backward pass size (MB): 12.51\n",
              "Params size (MB): 8.15\n",
              "Estimated Total Size (MB): 20.94\n",
              "================================================================================================================================================="
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model,\n",
        "        input_size=(2, 10, 300, 12),    # (batch, segments, timesteps, channels)\n",
        "        col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n",
        "        depth=4,\n",
        "        device=device.type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXVjg2BIKV9U"
      },
      "source": [
        "# Resource use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QOyRiZdxVBo"
      },
      "outputs": [],
      "source": [
        "!pip install calflops -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxpGdzARxbkS"
      },
      "outputs": [],
      "source": [
        "import calflops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZdSl-e2xxjq",
        "outputId": "181c25b6-1419-4cef-fa7f-d6c915c6765f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------- Calculate Flops Results -------------------------------------\n",
            "Notations:\n",
            "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
            "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
            "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
            "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
            "\n",
            "Total Training Params:                                                  3.42 M  \n",
            "fwd MACs:                                                               318.204 MMACs\n",
            "fwd FLOPs:                                                              1.8522 GFLOPS\n",
            "fwd+bwd MACs:                                                           954.612 MMACs\n",
            "fwd+bwd FLOPs:                                                          5.5565 GFLOPS\n",
            "\n",
            "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
            "Each module caculated is listed after its name in the following order: \n",
            "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
            "\n",
            "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
            " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
            "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
            "\n",
            "HANWithAttention(\n",
            "  3.42 M = 100% Params, 318.2 MMACs = 100% MACs, 1.85 GFLOPS = 100% FLOPs\n",
            "  (conv1d): Conv1d(38.53 K = 1.1274% Params, 115.2 MMACs = 36.2032% MACs, 230.78 MFLOPS = 12.4602% FLOPs, 12, 128, kernel_size=(25,), stride=(1,), padding=(12,))\n",
            "  (channel_attention): ChannelAttention(\n",
            "    4.24 K = 0.1241% Params, 81.92 KMACs = 0.0257% MACs, 164.16 KFLOPS = 0.0089% FLOPs\n",
            "    (mlp): Sequential(\n",
            "      4.24 K = 0.1241% Params, 81.92 KMACs = 0.0257% MACs, 164.16 KFLOPS = 0.0089% FLOPs\n",
            "      (0): Linear(2.06 K = 0.0604% Params, 40.96 KMACs = 0.0129% MACs, 81.92 KFLOPS = 0.0044% FLOPs, in_features=128, out_features=16, bias=True)\n",
            "      (1): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 320 FLOPS = 0% FLOPs)\n",
            "      (2): Linear(2.18 K = 0.0637% Params, 40.96 KMACs = 0.0129% MACs, 81.92 KFLOPS = 0.0044% FLOPs, in_features=16, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (pool): MaxPool1d(0 = 0% Params, 0 MACs = 0% MACs, 384 KFLOPS = 0.0207% FLOPs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (lstm_segment): LSTM(395.26 K = 11.5663% Params, 0 MACs = 0% MACs, 1.18 GFLOPS = 63.8972% FLOPs, 128, 256, batch_first=True)\n",
            "  (time_distributed_attention): TimeDistributedSegmentAttention(\n",
            "    66.05 K = 1.9327% Params, 196.61 MMACs = 61.7868% MACs, 393.22 MFLOPS = 21.23% FLOPs\n",
            "    (segment_attention): SegmentAttention(\n",
            "      66.05 K = 1.9327% Params, 196.61 MMACs = 61.7868% MACs, 393.22 MFLOPS = 21.23% FLOPs\n",
            "      (linear): Linear(65.79 K = 1.9252% Params, 98.3 MMACs = 30.8934% MACs, 196.61 MFLOPS = 10.615% FLOPs, in_features=256, out_features=256, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (lstm_sequence): LSTM(1.58 M = 46.1454% Params, 0 MACs = 0% MACs, 31.51 MFLOPS = 1.7012% FLOPs, 256, 512, batch_first=True)\n",
            "  (final_attention): SegmentAttention(\n",
            "    263.17 K = 7.7009% Params, 5.24 MMACs = 1.6476% MACs, 10.49 MFLOPS = 0.5661% FLOPs\n",
            "    (linear): Linear(262.66 K = 7.6859% Params, 2.62 MMACs = 0.8238% MACs, 5.24 MFLOPS = 0.2831% FLOPs, in_features=512, out_features=512, bias=True)\n",
            "  )\n",
            "  (fc): Linear(1.05 M = 30.7436% Params, 1.05 MMACs = 0.3295% MACs, 2.1 MFLOPS = 0.1132% FLOPs, in_features=512, out_features=2048, bias=True)\n",
            "  (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.4, inplace=False)\n",
            "  (classifier): Linear(22.54 K = 0.6595% Params, 22.53 KMACs = 0.0071% MACs, 45.06 KFLOPS = 0.0024% FLOPs, in_features=2048, out_features=11, bias=True)\n",
            ")\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Model FLOPs:1.8522 GFLOPS   MACs:318.204 MMACs   Params:3.4174 M \n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = HANWithAttention(num_classes=11)\n",
        "\n",
        "flops, macs, params = calflops.calculate_flops(model=model,\n",
        "                                      input_shape=(1, 10, 300, 12),\n",
        "                                      output_as_string=True,\n",
        "                                      output_precision=4)\n",
        "print(\"Model FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR5CvCk7KijN",
        "outputId": "0d0506fe-d0b8-4a63-9618-da1850c37c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "MODEL COMPLEXITY ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "📊 Parameter Count:\n",
            "   Total Parameters:       3,417,371\n",
            "   Trainable Parameters:   3,417,371\n",
            "   Non-trainable Parameters: 0\n",
            "   Model Size (MB):        13.04\n",
            "\n",
            "🔢 FLOPs (Floating Point Operations):\n",
            "   MACs (Multiply-Accumulate): 829.057M\n",
            "   Parameters (thop):          3.417M\n",
            "\n",
            "📋 Layer-wise Parameter Breakdown:\n",
            "Layer Name                                    Parameters   % of Total\n",
            "----------------------------------------------------------------------\n",
            "conv1d.weight                                     38,400        1.12%\n",
            "conv1d.bias                                          128        0.00%\n",
            "channel_attention.mlp.0.weight                     2,048        0.06%\n",
            "channel_attention.mlp.0.bias                          16        0.00%\n",
            "channel_attention.mlp.2.weight                     2,048        0.06%\n",
            "channel_attention.mlp.2.bias                         128        0.00%\n",
            "lstm_segment.weight_ih_l0                        131,072        3.84%\n",
            "lstm_segment.weight_hh_l0                        262,144        7.67%\n",
            "lstm_segment.bias_ih_l0                            1,024        0.03%\n",
            "lstm_segment.bias_hh_l0                            1,024        0.03%\n",
            "time_distributed_attention.segment_attention.u             256        0.01%\n",
            "time_distributed_attention.segment_attention.linear.weight          65,536        1.92%\n",
            "time_distributed_attention.segment_attention.linear.bias             256        0.01%\n",
            "lstm_sequence.weight_ih_l0                       524,288       15.34%\n",
            "lstm_sequence.weight_hh_l0                     1,048,576       30.68%\n",
            "lstm_sequence.bias_ih_l0                           2,048        0.06%\n",
            "lstm_sequence.bias_hh_l0                           2,048        0.06%\n",
            "final_attention.u                                    512        0.01%\n",
            "final_attention.linear.weight                    262,144        7.67%\n",
            "final_attention.linear.bias                          512        0.01%\n",
            "fc.weight                                      1,048,576       30.68%\n",
            "fc.bias                                            2,048        0.06%\n",
            "classifier.weight                                 22,528        0.66%\n",
            "classifier.bias                                       11        0.00%\n",
            "\n",
            "📝 Detailed Model Architecture:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'total_params': 3417371,\n",
              " 'trainable_params': 3417371,\n",
              " 'model_size_mb': 13.036235809326172}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def analyze_model_complexity(model, input_size=(1, 10, 300, 12), device='cuda'):\n",
        "    \"\"\"\n",
        "    Analyze model complexity: parameters, FLOPs, memory\n",
        "\n",
        "    Args:\n",
        "        model: Your HANWithAttention model\n",
        "        input_size: (batch, segments, timesteps, channels)\n",
        "        device: 'cuda' or 'cpu'\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"MODEL COMPLEXITY ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # 1. Parameter count\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    non_trainable_params = total_params - trainable_params\n",
        "\n",
        "    print(f\"\\n📊 Parameter Count:\")\n",
        "    print(f\"   Total Parameters:       {total_params:,}\")\n",
        "    print(f\"   Trainable Parameters:   {trainable_params:,}\")\n",
        "    print(f\"   Non-trainable Parameters: {non_trainable_params:,}\")\n",
        "    print(f\"   Model Size (MB):        {total_params * 4 / (1024**2):.2f}\")  # 4 bytes per float32\n",
        "\n",
        "    # 2. FLOPs calculation\n",
        "    dummy_input = torch.randn(input_size).to(device)\n",
        "\n",
        "    try:\n",
        "        macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
        "        macs, params = clever_format([macs, params], \"%.3f\")\n",
        "        print(f\"\\n🔢 FLOPs (Floating Point Operations):\")\n",
        "        print(f\"   MACs (Multiply-Accumulate): {macs}\")\n",
        "        print(f\"   Parameters (thop):          {params}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n⚠️  FLOPs calculation failed: {e}\")\n",
        "\n",
        "    # 3. Layer-wise parameter breakdown\n",
        "    print(f\"\\n📋 Layer-wise Parameter Breakdown:\")\n",
        "    print(f\"{'Layer Name':<40} {'Parameters':>15} {'% of Total':>12}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            param_count = param.numel()\n",
        "            percentage = 100 * param_count / trainable_params\n",
        "            print(f\"{name:<40} {param_count:>15,} {percentage:>11.2f}%\")\n",
        "\n",
        "    # 4. Detailed model summary\n",
        "    print(f\"\\n📝 Detailed Model Architecture:\")\n",
        "    summary(model,\n",
        "            input_size=input_size,\n",
        "            col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
        "            depth=4,\n",
        "            device=device,\n",
        "            verbose=0)\n",
        "\n",
        "    return {\n",
        "        'total_params': total_params,\n",
        "        'trainable_params': trainable_params,\n",
        "        'model_size_mb': total_params * 4 / (1024**2)\n",
        "    }\n",
        "\n",
        "analyze_model_complexity(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHsLQY8jZiU9",
        "outputId": "4b321613-6541-4632-b8b2-ecc51b6a7507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model size: 13.036MB\n"
          ]
        }
      ],
      "source": [
        "# From: https://discuss.pytorch.org/t/finding-model-size/130275\n",
        "\n",
        "param_size = 0\n",
        "for param in model.parameters():\n",
        "    param_size += param.nelement() * param.element_size()\n",
        "buffer_size = 0\n",
        "for buffer in model.buffers():\n",
        "    buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "print('model size: {:.3f}MB'.format(size_all_mb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_uVZS6MdoxT",
        "outputId": "8f4d17db-1d95-41c8-c892-7b512a1e736c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "INFERENCE BENCHMARK\n",
            "================================================================================\n",
            "Device: cuda\n",
            "Input shape: (1, 10, 300, 12)\n",
            "Throughput batch size: 16\n",
            "\n",
            "Batch-1 Latency (ms):\n",
            "     mean_ms: 3.188\n",
            "      std_ms: 0.174\n",
            "   median_ms: 3.162\n",
            "      min_ms: 3.072\n",
            "      max_ms: 4.449\n",
            "\n",
            "Batch-N Throughput:\n",
            "     batch_time_ms: 6.826\n",
            "     per_sample_ms: 0.427\n",
            "   samples_per_sec: 2343.96\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# =============================================================================\n",
        "# Benchmark Environment Setup\n",
        "# =============================================================================\n",
        "\n",
        "def setup_benchmark_env():\n",
        "    \"\"\"\n",
        "    Freeze backend behavior for reproducible benchmarking.\n",
        "    \"\"\"\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = False\n",
        "    torch.backends.cudnn.allow_tf32 = False\n",
        "\n",
        "def time_forward(model, inputs, device='cuda'):\n",
        "    \"\"\"\n",
        "    Time a single forward pass with proper synchronization.\n",
        "    Returns elapsed time in seconds.\n",
        "    \"\"\"\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "        start = torch.cuda.Event(enable_timing=True)\n",
        "        end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "        start.record()\n",
        "        _ = model(inputs)\n",
        "        end.record()\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        return start.elapsed_time(end) / 1000.0  # seconds\n",
        "    else:\n",
        "        t0 = time.time()\n",
        "        _ = model(inputs)\n",
        "        return time.time() - t0\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Batch-1 Latency Benchmark\n",
        "# =============================================================================\n",
        "\n",
        "def benchmark_latency(\n",
        "    model,\n",
        "    input_shape,\n",
        "    device='cuda',\n",
        "    runs=100,\n",
        "    warmup=20\n",
        "):\n",
        "    \"\"\"\n",
        "    Measure true per-sample inference latency (batch size = 1).\n",
        "    \"\"\"\n",
        "    model = model.to(device).eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Warmup\n",
        "        for _ in range(warmup):\n",
        "            x = torch.randn(input_shape, device=device)\n",
        "            _ = model(x)\n",
        "            if device == 'cuda':\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "        times = []\n",
        "        for _ in range(runs):\n",
        "            x = torch.randn(input_shape, device=device)\n",
        "            elapsed = time_forward(model, x, device)\n",
        "            times.append(elapsed)\n",
        "\n",
        "    times = np.array(times)\n",
        "\n",
        "    return {\n",
        "        \"mean_ms\": times.mean() * 1000,\n",
        "        \"std_ms\": times.std() * 1000,\n",
        "        \"median_ms\": np.median(times) * 1000,\n",
        "        \"min_ms\": times.min() * 1000,\n",
        "        \"max_ms\": times.max() * 1000,\n",
        "    }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Batch-N Throughput Benchmark\n",
        "# =============================================================================\n",
        "\n",
        "def benchmark_throughput(\n",
        "    model,\n",
        "    input_shape,\n",
        "    batch_size,\n",
        "    device='cuda',\n",
        "    runs=100,\n",
        "    warmup=20\n",
        "):\n",
        "    \"\"\"\n",
        "    Measure throughput under batched inference.\n",
        "    \"\"\"\n",
        "    model = model.to(device).eval()\n",
        "    shape = (batch_size,) + input_shape[1:]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Warmup\n",
        "        for _ in range(warmup):\n",
        "            x = torch.randn(shape, device=device)\n",
        "            _ = model(x)\n",
        "            if device == 'cuda':\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "        times = []\n",
        "        for _ in range(runs):\n",
        "            x = torch.randn(shape, device=device)\n",
        "            elapsed = time_forward(model, x, device)\n",
        "            times.append(elapsed)\n",
        "\n",
        "    times = np.array(times)\n",
        "\n",
        "    return {\n",
        "        \"batch_time_ms\": times.mean() * 1000,\n",
        "        \"per_sample_ms\": (times.mean() / batch_size) * 1000,\n",
        "        \"samples_per_sec\": batch_size / times.mean()\n",
        "    }\n",
        "\n",
        "def run_inference_benchmark(\n",
        "    model,\n",
        "    input_shape=(1, 10, 300, 12),\n",
        "    batch_size=16,\n",
        "    device='cuda'\n",
        "):\n",
        "    setup_benchmark_env()\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"INFERENCE BENCHMARK\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Input shape: {input_shape}\")\n",
        "    print(f\"Throughput batch size: {batch_size}\")\n",
        "\n",
        "    latency = benchmark_latency(\n",
        "        model=model,\n",
        "        input_shape=input_shape,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    throughput = benchmark_throughput(\n",
        "        model=model,\n",
        "        input_shape=input_shape,\n",
        "        batch_size=batch_size,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print(\"\\nBatch-1 Latency (ms):\")\n",
        "    for k, v in latency.items():\n",
        "        print(f\"  {k:>10}: {v:.3f}\")\n",
        "\n",
        "    print(\"\\nBatch-N Throughput:\")\n",
        "    for k, v in throughput.items():\n",
        "        if \"ms\" in k:\n",
        "            print(f\"  {k:>16}: {v:.3f}\")\n",
        "        else:\n",
        "            print(f\"  {k:>16}: {v:.2f}\")\n",
        "\n",
        "    return {\n",
        "        \"latency\": latency,\n",
        "        \"throughput\": throughput\n",
        "    }\n",
        "\n",
        "results = run_inference_benchmark(\n",
        "    model,\n",
        "    input_shape=(1, 10, 300, 12),\n",
        "    batch_size=16,\n",
        "    device='cuda'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W94rj934sru5",
        "outputId": "11285efc-cfa8-4e20-ab72-cd058cbb924f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "INFERENCE BENCHMARK\n",
            "================================================================================\n",
            "Device: cpu\n",
            "Input shape: (1, 10, 300, 12)\n",
            "Throughput batch size: 16\n",
            "\n",
            "Batch-1 Latency (ms):\n",
            "     mean_ms: 10.316\n",
            "      std_ms: 0.344\n",
            "   median_ms: 10.247\n",
            "      min_ms: 9.640\n",
            "      max_ms: 11.711\n",
            "\n",
            "Batch-N Throughput:\n",
            "     batch_time_ms: 128.110\n",
            "     per_sample_ms: 8.007\n",
            "   samples_per_sec: 124.89\n"
          ]
        }
      ],
      "source": [
        "\n",
        "results = run_inference_benchmark(\n",
        "    model,\n",
        "    input_shape=(1, 10, 300, 12),\n",
        "    batch_size=16,\n",
        "    device='cpu'\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
