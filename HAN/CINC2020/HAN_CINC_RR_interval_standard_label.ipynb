{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuHdxRc2rzG3",
        "outputId": "c5831ef7-0770-41dc-92fe-5833f1b85215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m148.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q wfdb torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDo4jPPWsFE8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Optional\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pywt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "from scipy.signal import butter, filtfilt, find_peaks\n",
        "from sklearn.model_selection import train_test_split\n",
        "import wfdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_rnJ5orsYo3",
        "outputId": "cb9f14ea-06e2-4aa6-bc67-c68f4f38382c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_ZOegzfsZeY"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/CINC2020.zip'\n",
        "extract_dir = '/content/'\n",
        "\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb5xuEnrtW_a"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Config\n",
        "# -------------------------\n",
        "SAMPLING_RATE = 500\n",
        "DROP_LAST = True\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeCdCeVKsi07"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# utilities: filtering and peak detection\n",
        "# -------------------------\n",
        "def denoise(data):\n",
        "    # wavelet transform\n",
        "    coeffs = pywt.wavedec(data=data, wavelet='db5', level=9)\n",
        "    cA9, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1 = coeffs\n",
        "\n",
        "    # Threshold denoising\n",
        "    threshold = (np.median(np.abs(cD1)) / 0.6745) * (np.sqrt(2 * np.log(len(cD1))))\n",
        "    cD1.fill(0)\n",
        "    cD2.fill(0)\n",
        "    for i in range(1, len(coeffs) - 2):\n",
        "        coeffs[i] = pywt.threshold(coeffs[i], threshold)\n",
        "\n",
        "    # Inverse wavelet transform to obtain the denoised signal\n",
        "    rdata = pywt.waverec(coeffs=coeffs, wavelet='db5')\n",
        "    return rdata\n",
        "\n",
        "\n",
        "def pan_tompkins_detector(ecg_signal, fs):\n",
        "    lowcut, highcut = 5.0, 15.0\n",
        "    nyquist = 0.5 * fs\n",
        "    low, high = lowcut / nyquist, highcut / nyquist\n",
        "    b, a = butter(1, [low, high], btype='band')\n",
        "    filtered_ecg = filtfilt(b, a, ecg_signal)\n",
        "    diff_ecg = np.diff(filtered_ecg)\n",
        "    squared_ecg = diff_ecg ** 2\n",
        "    window_size = int(0.150 * fs)\n",
        "    mwa_ecg = np.convolve(squared_ecg, np.ones(window_size) / window_size, mode='same')\n",
        "    peaks, _ = find_peaks(mwa_ecg, distance=int(0.6 * fs))\n",
        "    return peaks\n",
        "\n",
        "\n",
        "def multi_lead_fusion(detected_peaks, fs, fusion_window=0.1, min_leads=None):\n",
        "    n_leads = len(detected_peaks)\n",
        "    if min_leads is None:\n",
        "        min_leads = int(np.ceil(n_leads / 2))\n",
        "\n",
        "    # Collect all peaks with their lead information\n",
        "    all_peaks = [(p, lead) for lead, peaks in enumerate(detected_peaks) for p in peaks]\n",
        "    all_peaks.sort(key=lambda x: x[0])\n",
        "\n",
        "    fused_peaks = []\n",
        "    i = 0\n",
        "\n",
        "    while i < len(all_peaks):\n",
        "        # Start a new cluster\n",
        "        cluster = [all_peaks[i]]\n",
        "        i += 1\n",
        "\n",
        "        # Add nearby peaks to the cluster\n",
        "        while i < len(all_peaks) and all_peaks[i][0] - cluster[-1][0] <= fusion_window * fs:\n",
        "            cluster.append(all_peaks[i])\n",
        "            i += 1\n",
        "\n",
        "        # Check if cluster has peaks from enough leads\n",
        "        unique_leads = {lead for _, lead in cluster}\n",
        "        if len(unique_leads) >= min_leads:\n",
        "            # Use median position as the fused peak\n",
        "            fused_peak = int(np.median([p for (p, _) in cluster]))\n",
        "            fused_peaks.append(fused_peak)\n",
        "\n",
        "    return np.array(sorted(fused_peaks))\n",
        "\n",
        "\n",
        "def detect_r_peaks(ecg_signals, fs):\n",
        "    detected_peaks = []\n",
        "    for lead in ecg_signals:\n",
        "        peaks = pan_tompkins_detector(lead, fs)\n",
        "        detected_peaks.append(peaks)\n",
        "\n",
        "    fused_r_peaks = multi_lead_fusion(detected_peaks, fs, fusion_window=0.1, min_leads=6)\n",
        "    return fused_r_peaks\n",
        "\n",
        "\n",
        "def extract_segments_around_peaks(signal, r_peaks, pre_samples, post_samples):\n",
        "    segments = []\n",
        "\n",
        "    for peak in r_peaks:\n",
        "        start = max(0, peak - pre_samples)\n",
        "        end = min(len(signal), peak + post_samples)\n",
        "\n",
        "        # Only include segments with the correct length\n",
        "        if end - start == pre_samples + post_samples:\n",
        "            segment = signal[start:end]\n",
        "            segments.append(segment)\n",
        "\n",
        "    return segments\n",
        "\n",
        "\n",
        "def extract_rr_beats_multi_lead(ecg_signals, fs, denoise_fn=None,\n",
        "                                min_rr_ms=300, max_rr_ms=1500, min_beats=2):\n",
        "    \"\"\"\n",
        "    Returns a list of beats, each beat is an array with shape (T_i, C) where C = n_leads.\n",
        "    \"\"\"\n",
        "    ecg = np.array(ecg_signals)                  # (n_leads, n_samples)\n",
        "    n_leads, n_samples = ecg.shape\n",
        "\n",
        "    if denoise_fn is not None:\n",
        "        ecg = np.array([denoise_fn(lead) for lead in ecg])\n",
        "\n",
        "    # Detect fused R-peaks once across leads\n",
        "    r_peaks = detect_r_peaks(ecg, fs)            # uses your multi-lead fusion\n",
        "    if len(r_peaks) < min_beats:\n",
        "        return None  # not enough beats\n",
        "\n",
        "    # RR in samples/ms\n",
        "    rr_samples = np.diff(r_peaks)\n",
        "    rr_ms = (rr_samples / fs) * 1000.0\n",
        "    valid = (rr_ms >= min_rr_ms) & (rr_ms <= max_rr_ms)\n",
        "    if valid.sum() == 0:\n",
        "        return None\n",
        "\n",
        "    beats = []\n",
        "    for i in range(len(r_peaks) - 1):\n",
        "        if not valid[i]:\n",
        "            continue\n",
        "        start = r_peaks[i]\n",
        "        end   = r_peaks[i+1]\n",
        "        seg = ecg[:, start:end].T                # (T_i, C)\n",
        "        if seg.shape[0] > 0:\n",
        "            beats.append(seg.astype(np.float32))\n",
        "\n",
        "    if len(beats) == 0:\n",
        "        return None\n",
        "    return beats  # list of variable-length (T_i, C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhR-N6s5qdHA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wfdb\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "print(\"Loading and preprocessing ECG data (CINC)…\")\n",
        "\n",
        "RECORDS = \"/content/classification-of-12-lead-ecgs-the-physionetcomputing-in-cardiology-challenge-2020-1.0.2/RECORDS\"\n",
        "\n",
        "# LEAD_TO_KEEP = 1            # keep if you ever want single-lead; we're using all leads\n",
        "\n",
        "# keep only these Dx codes (strings)\n",
        "available_labels = [\n",
        "    '10370003', '164889003', '164909002', '164934002',\n",
        "    '270492004', '284470004', '426177001', '426783006',\n",
        "    '427084000', '427393009', '59118001'\n",
        "]\n",
        "\n",
        "tmp = []  # will store (beats_list, label_str)\n",
        "\n",
        "# --- enumerate dataset folders from CINC/RECORDS ---\n",
        "with open(RECORDS) as f:\n",
        "    FOLDERS = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "for folder in FOLDERS:\n",
        "    # your original exclusions\n",
        "    if folder in [\"training/ptb/g1/\", \"training/st_petersburg_incart/g1/\"]:\n",
        "        continue\n",
        "\n",
        "    records_path = os.path.join(\"/content/classification-of-12-lead-ecgs-the-physionetcomputing-in-cardiology-challenge-2020-1.0.2\", folder, \"RECORDS\")\n",
        "    if not os.path.exists(records_path):\n",
        "        continue\n",
        "\n",
        "    with open(records_path) as r:\n",
        "        files = [ln.strip() for ln in r if ln.strip()]\n",
        "\n",
        "    for file_name in files:\n",
        "        final_data_path = os.path.join(\"/content/classification-of-12-lead-ecgs-the-physionetcomputing-in-cardiology-challenge-2020-1.0.2\", folder, file_name)\n",
        "\n",
        "        # --- header: find a single Dx (skip multi-label) ---\n",
        "        try:\n",
        "            hdr = wfdb.rdheader(final_data_path)\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        label = None\n",
        "        for comment in (hdr.comments or []):\n",
        "            if comment.startswith(\"Dx:\") and \",\" not in comment:\n",
        "                # typical: \"Dx: 164889003\"\n",
        "                label = comment.replace(\"Dx:\", \"\").strip()\n",
        "                break\n",
        "\n",
        "        if (label is None) or (label not in available_labels):\n",
        "            continue\n",
        "\n",
        "        # --- read signal ---\n",
        "        try:\n",
        "            record = wfdb.rdrecord(final_data_path)       # p_signal: (n_samples, n_leads)\n",
        "            signal = record.p_signal\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        if signal is None:\n",
        "            continue\n",
        "\n",
        "        # replace NaNs, transpose -> (n_leads, n_samples), float32\n",
        "        signal = np.nan_to_num(signal, nan=0.0).T.astype(np.float32)\n",
        "\n",
        "        # multi-lead denoising (one wavelet pass per lead)\n",
        "        denoised = np.array([denoise(lead) for lead in signal], dtype=np.float32)\n",
        "        denoised = np.nan_to_num(denoised, nan=0.0)\n",
        "\n",
        "        if np.isnan(denoised).any():\n",
        "            print(\"WARNING: denoised signal contains NaNs for\", final_data_path)\n",
        "\n",
        "        # --- extract variable-length R–R beats across all leads ---\n",
        "        beats = extract_rr_beats_multi_lead(\n",
        "            denoised,               # (n_leads, n_samples)\n",
        "            fs=SAMPLING_RATE,\n",
        "            denoise_fn=None         # already denoised above\n",
        "        )\n",
        "\n",
        "        # beats is a Python list of arrays; each array has shape (T_i, C)\n",
        "        if beats is None or len(beats) == 0:\n",
        "            continue\n",
        "\n",
        "        tmp.append((beats, label))\n",
        "\n",
        "# --- build label -> index mapping from labels actually present ---\n",
        "unique_labels = sorted({lbl for (_, lbl) in tmp})\n",
        "label2idx = {lbl: i for i, lbl in enumerate(unique_labels)}\n",
        "num_classes = len(unique_labels)\n",
        "print(\"num_classes:\", num_classes, \"labels:\", unique_labels)\n",
        "\n",
        "# --- final data_list: (beats_list, label_idx) ---\n",
        "data_list = []\n",
        "for beats, lbl in tmp:\n",
        "    if lbl not in label2idx:\n",
        "        continue\n",
        "    data_list.append((beats, label2idx[lbl]))\n",
        "\n",
        "print(\"Prepared records:\", len(data_list))\n",
        "print(\"Beat counts distribution:\", Counter([len(x[0]) for x in data_list]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJDavkmbuK9X"
      },
      "outputs": [],
      "source": [
        "# ---------- Length-bucketing Batch Sampler ----------\n",
        "class LengthBucketBatchSampler(Sampler):\n",
        "    \"\"\"\n",
        "    Yields lists of indices (batches) where all samples in a batch share the same length-bucket.\n",
        "\n",
        "    Args:\n",
        "        lengths: list/array-like of int lengths (len(dataset) entries).\n",
        "        batch_size: target batch size.\n",
        "        bin_size: None for exact-length buckets. If int > 0, length_key = (length // bin_size) * bin_size.\n",
        "        shuffle: shuffle within buckets and shuffle batch order each epoch.\n",
        "        drop_last: whether to drop the last small batch in a bucket.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 lengths: List[int],\n",
        "                 batch_size: int,\n",
        "                 bin_size: Optional[int] = None,\n",
        "                 shuffle: bool = True,\n",
        "                 drop_last: bool = False):\n",
        "        self.lengths = list(lengths)\n",
        "        self.batch_size = int(batch_size)\n",
        "        self.bin_size = bin_size\n",
        "        self.shuffle = shuffle\n",
        "        self.drop_last = drop_last\n",
        "\n",
        "        # Build mapping length_key -> list of indices\n",
        "        self._buckets = defaultdict(list)\n",
        "        for idx, L in enumerate(self.lengths):\n",
        "            key = self._length_key(L)\n",
        "            self._buckets[key].append(idx)\n",
        "\n",
        "        # Convert to normal dict for iteration; keep keys list stable\n",
        "        self.bucket_keys = list(self._buckets.keys())\n",
        "\n",
        "    def _length_key(self, length: int) -> int:\n",
        "        if self.bin_size is None or self.bin_size <= 0:\n",
        "            return int(length)   # exact-length bucket\n",
        "        else:\n",
        "            return (length // self.bin_size) * self.bin_size\n",
        "\n",
        "    def __iter__(self):\n",
        "      # For each epoch, build batches from buckets.\n",
        "      batches = []\n",
        "      for key in self.bucket_keys:\n",
        "          idxs = list(self._buckets[key])\n",
        "          if len(idxs) < self.batch_size:\n",
        "              # skip this bucket entirely\n",
        "              continue\n",
        "          if self.shuffle:\n",
        "              random.shuffle(idxs)\n",
        "          # chunk into batches\n",
        "          for i in range(0, len(idxs), self.batch_size):\n",
        "              batch = idxs[i:i + self.batch_size]\n",
        "              if len(batch) < self.batch_size and self.drop_last:\n",
        "                  continue\n",
        "              batches.append(batch)\n",
        "\n",
        "      if self.shuffle:\n",
        "          random.shuffle(batches)\n",
        "\n",
        "      for batch in batches:\n",
        "          yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        total = 0\n",
        "        for key in self.bucket_keys:\n",
        "            n = len(self._buckets[key])\n",
        "            if self.drop_last:\n",
        "                total += n // self.batch_size\n",
        "            else:\n",
        "                total += math.ceil(n / self.batch_size)\n",
        "        return total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dam8A7JIK2DU"
      },
      "outputs": [],
      "source": [
        "class ECGSegmentDatasetVarLen(Dataset):\n",
        "    \"\"\"\n",
        "    data_list: list of tuples (beats_list, label_idx)\n",
        "      - beats_list is a Python list of arrays with shapes (T_i, C), i=1..S\n",
        "    \"\"\"\n",
        "    def __init__(self, data_list):\n",
        "        self.data = data_list\n",
        "        # number of beats per record for length-bucketing by S\n",
        "        self.num_beats = [len(x[0]) for x in data_list]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        beats_list, label = self.data[idx]\n",
        "        # convert each beat to torch tensor\n",
        "        beats_tensors = [torch.from_numpy(b) if isinstance(b, np.ndarray) else torch.tensor(b)\n",
        "                         for b in beats_list]  # [(T_i, C), ...]\n",
        "        return {\"beats\": beats_tensors, \"label\": int(label), \"num_beats\": len(beats_tensors)}\n",
        "\n",
        "\n",
        "def collate_by_num_beats(batch):\n",
        "    s_vals = [item[\"num_beats\"] for item in batch]\n",
        "    if not all(s == s_vals[0] for s in s_vals):\n",
        "        raise ValueError(\"collate_by_num_beats received mixed num_beats in a batch\")\n",
        "    signals = torch.stack([item[\"signal\"] for item in batch], dim=0)  # (B, S, T, C)\n",
        "    labels = torch.tensor([item[\"label\"] for item in batch], dtype=torch.long)\n",
        "    return {\"signal\": signals, \"label\": labels, \"num_beats\": torch.tensor(s_vals, dtype=torch.long)}\n",
        "\n",
        "\n",
        "def pad_collate_varlen(batch):\n",
        "    B = len(batch)\n",
        "    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n",
        "    S_vals = [b[\"num_beats\"] for b in batch]\n",
        "    if not all(S_vals[0] == s for s in S_vals):\n",
        "        raise ValueError(\"Bucketed sampler should ensure same #beats (S) per batch.\")\n",
        "\n",
        "    S = S_vals[0]\n",
        "    # C might be 12; infer from first item, first beat\n",
        "    C = batch[0][\"beats\"][0].shape[1]\n",
        "    # T_max across all beats of all items\n",
        "    T_max = max(beat.shape[0] for item in batch for beat in item[\"beats\"])\n",
        "\n",
        "    signal = torch.zeros((B, S, T_max, C), dtype=torch.float32)\n",
        "    mask   = torch.zeros((B, S, T_max),   dtype=torch.float32)\n",
        "\n",
        "    for bi, item in enumerate(batch):\n",
        "        for si, beat in enumerate(item[\"beats\"]):\n",
        "            T = beat.shape[0]\n",
        "            signal[bi, si, :T, :] = beat\n",
        "            mask[bi, si, :T] = 1.0\n",
        "\n",
        "    return {\"signal\": signal, \"mask\": mask, \"label\": labels,\n",
        "            \"num_beats\": torch.tensor(S_vals, dtype=torch.long)}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6tvcFTaK4d6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "# # instantiate dataset and sampler\n",
        "ds = ECGSegmentDatasetVarLen(data_list)\n",
        "\n",
        "# -------------------------\n",
        "# Split indices\n",
        "# -------------------------\n",
        "all_indices = list(range(len(ds)))\n",
        "all_labels = [data_list[i][1] for i in all_indices]\n",
        "\n",
        "# First split: train+val vs test (stratified)\n",
        "trainval_indices, test_indices = train_test_split(\n",
        "    all_indices,\n",
        "    test_size=0.1,\n",
        "    random_state=10,\n",
        "    stratify=all_labels  # ← stratify by class labels\n",
        ")\n",
        "\n",
        "# Extract labels for the trainval subset\n",
        "trainval_labels = [all_labels[i] for i in trainval_indices]\n",
        "\n",
        "# Second split: train vs val (stratified)\n",
        "train_indices, val_indices = train_test_split(\n",
        "    trainval_indices,\n",
        "    test_size=0.1,\n",
        "    random_state=10,\n",
        "    stratify=trainval_labels  # ← stratify by class labels\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Create Subsets\n",
        "# -------------------------\n",
        "train_ds = Subset(ds, train_indices)\n",
        "val_ds   = Subset(ds, val_indices)\n",
        "test_ds  = Subset(ds, test_indices)\n",
        "\n",
        "def make_loader(subset_ds, batch_size=16, drop_last=True, shuffle=True):\n",
        "    subset_indices = subset_ds.indices\n",
        "    lengths = [ds.num_beats[i] for i in subset_indices]\n",
        "    sampler = LengthBucketBatchSampler(lengths, batch_size, bin_size=None,\n",
        "                                       shuffle=shuffle, drop_last=drop_last)\n",
        "    loader = DataLoader(subset_ds, batch_sampler=sampler,\n",
        "                        collate_fn=pad_collate_varlen,\n",
        "                        num_workers=0, pin_memory=True)\n",
        "    return loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7sXFsk4N-3A",
        "outputId": "c6493772-2141-40fb-fc59-b6e5492000cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train distribution: Counter({7: 7364, 10: 1299, 1: 879, 4: 610, 5: 436, 6: 370, 0: 220, 8: 185, 2: 175, 3: 129, 9: 103})\n",
            "Val distribution: Counter({7: 818, 10: 144, 1: 98, 4: 68, 5: 48, 6: 41, 0: 25, 8: 21, 2: 20, 3: 14, 9: 11})\n",
            "Test distribution: Counter({7: 910, 10: 160, 1: 109, 4: 75, 5: 54, 6: 45, 0: 27, 8: 23, 2: 22, 3: 16, 9: 13})\n"
          ]
        }
      ],
      "source": [
        "# Verifying stratifying\n",
        "train_loader = make_loader(train_ds, batch_size=16)\n",
        "val_loader   = make_loader(val_ds, batch_size=16, shuffle=False)\n",
        "test_loader  = make_loader(test_ds, batch_size=16, shuffle=False)\n",
        "\n",
        "def get_label_distribution(indices):\n",
        "    labels = [data_list[i][1] for i in indices]\n",
        "    return Counter(labels)\n",
        "\n",
        "print(\"Train distribution:\", get_label_distribution(train_indices))\n",
        "print(\"Val distribution:\", get_label_distribution(val_indices))\n",
        "print(\"Test distribution:\", get_label_distribution(test_indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTH5m7jHMjD9",
        "outputId": "d4689075-517c-422d-9cdb-284f69792104"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================================================================================================\n",
              "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Trainable\n",
              "=================================================================================================================================================\n",
              "HANWithAttention                              [2, 10, 300, 12]          [2, 11]                   --                        True\n",
              "├─Conv1d: 1-1                                 [20, 12, 300]             [20, 256, 300]            77,056                    True\n",
              "├─BatchNorm1d: 1-2                            [20, 256, 300]            [20, 256, 300]            512                       True\n",
              "├─ChannelAttention: 1-3                       [20, 256, 300]            [20, 256, 300]            --                        True\n",
              "│    └─Sequential: 2-1                        [20, 256]                 [20, 256]                 --                        True\n",
              "│    │    └─Linear: 3-1                       [20, 256]                 [20, 32]                  8,224                     True\n",
              "│    │    └─ReLU: 3-2                         [20, 32]                  [20, 32]                  --                        --\n",
              "│    │    └─Linear: 3-3                       [20, 32]                  [20, 256]                 8,448                     True\n",
              "│    └─Sequential: 2-2                        [20, 256]                 [20, 256]                 (recursive)               True\n",
              "│    │    └─Linear: 3-4                       [20, 256]                 [20, 32]                  (recursive)               True\n",
              "│    │    └─ReLU: 3-5                         [20, 32]                  [20, 32]                  --                        --\n",
              "│    │    └─Linear: 3-6                       [20, 32]                  [20, 256]                 (recursive)               True\n",
              "├─MaxPool1d: 1-4                              [20, 256, 300]            [20, 256, 150]            --                        --\n",
              "├─LSTM: 1-5                                   [20, 150, 256]            [20, 150, 512]            1,576,960                 True\n",
              "├─TimeDistributedSegmentAttention: 1-6        [2, 10, 150, 512]         [2, 10, 512]              --                        True\n",
              "│    └─SegmentAttention: 2-3                  [20, 150, 512]            [20, 512]                 512                       True\n",
              "│    │    └─Linear: 3-7                       [20, 150, 512]            [20, 150, 512]            262,656                   True\n",
              "├─LSTM: 1-7                                   [2, 10, 512]              [2, 10, 256]              788,480                   True\n",
              "├─SegmentAttention: 1-8                       [2, 10, 256]              [2, 256]                  256                       True\n",
              "│    └─Linear: 2-4                            [2, 10, 256]              [2, 10, 256]              65,792                    True\n",
              "├─Linear: 1-9                                 [2, 256]                  [2, 512]                  131,584                   True\n",
              "├─Dropout: 1-10                               [2, 512]                  [2, 512]                  --                        --\n",
              "├─Linear: 1-11                                [2, 512]                  [2, 11]                   5,643                     True\n",
              "=================================================================================================================================================\n",
              "Total params: 2,926,123\n",
              "Trainable params: 2,926,123\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 5.22\n",
              "=================================================================================================================================================\n",
              "Input size (MB): 0.29\n",
              "Forward/backward pass size (MB): 49.33\n",
              "Params size (MB): 11.70\n",
              "Estimated Total Size (MB): 61.32\n",
              "================================================================================================================================================="
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Attention / helper layers\n",
        "# -------------------------\n",
        "class ChannelAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Expects x shape = (batch, channels, seq_len)\n",
        "    \"\"\"\n",
        "    def __init__(self, channels, ratio=8):\n",
        "        super().__init__()\n",
        "        mid = max(1, channels // ratio)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(channels, mid, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(mid, channels, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, L)\n",
        "        avg_pool = torch.mean(x, dim=2)           # (B, C)\n",
        "        max_pool, _ = torch.max(x, dim=2)         # (B, C)\n",
        "        avg_out = self.mlp(avg_pool)              # (B, C)\n",
        "        max_out = self.mlp(max_pool)              # (B, C)\n",
        "        att = torch.sigmoid(avg_out + max_out)    # (B, C)\n",
        "        att = att.unsqueeze(2)                    # (B, C, 1)\n",
        "        return x * att                             # broadcast multiply -> (B, C, L)\n",
        "\n",
        "class SegmentAttention(nn.Module):\n",
        "    def __init__(self, input_dim, units):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_dim, units, bias=True)\n",
        "        self.u = nn.Parameter(torch.randn(units))\n",
        "\n",
        "    def forward(self, inputs, mask=None):\n",
        "        \"\"\"\n",
        "        inputs: (B, T, D)\n",
        "        mask:   (B, T) with 1=valid, 0=pad (or None)\n",
        "        \"\"\"\n",
        "        v = torch.tanh(self.linear(inputs))             # (B, T, units)\n",
        "        vu = torch.matmul(v, self.u)                    # (B, T)\n",
        "        if mask is not None:\n",
        "            # set -inf (large negative) where mask==0 so softmax->0\n",
        "            vu = vu.masked_fill(mask == 0, float('-inf'))\n",
        "        alphas = F.softmax(vu, dim=1)                   # (B, T)\n",
        "        # NaN-safe: if an all-pad row slipped through, replace NaNs with 0\n",
        "        alphas = torch.nan_to_num(alphas, nan=0.0)\n",
        "        output = torch.sum(inputs * alphas.unsqueeze(-1), dim=1)  # (B, D)\n",
        "        return output, alphas\n",
        "\n",
        "class TimeDistributedSegmentAttention(nn.Module):\n",
        "    def __init__(self, input_dim, units):\n",
        "        super().__init__()\n",
        "        self.segment_attention = SegmentAttention(input_dim, units)\n",
        "\n",
        "    def forward(self, inputs, mask=None):\n",
        "        \"\"\"\n",
        "        inputs: (B, S, T, D)\n",
        "        mask:   (B, S, T) or None\n",
        "        \"\"\"\n",
        "        B, S, T, D = inputs.shape\n",
        "        flat = inputs.view(B * S, T, D)                         # (B*S, T, D)\n",
        "        if mask is not None:\n",
        "            mask_flat = mask.view(B * S, T)                     # (B*S, T)\n",
        "        else:\n",
        "            mask_flat = None\n",
        "        outputs, alphas = self.segment_attention(flat, mask_flat)  # (B*S, D), (B*S, T)\n",
        "        outputs = outputs.view(B, S, D)                         # (B, S, D)\n",
        "        alphas  = alphas.view(B, S, T)                          # (B, S, T)\n",
        "        return outputs, alphas\n",
        "\n",
        "class HANWithAttention(nn.Module):\n",
        "    def __init__(self, num_classes=11):\n",
        "        super().__init__()\n",
        "        self.conv1d = nn.Conv1d(in_channels=12, out_channels=256, kernel_size=25, padding=12)\n",
        "        self.channel_attention = ChannelAttention(256, ratio=8)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "        self.lstm_segment = nn.LSTM(input_size=256, hidden_size=512, batch_first=True)\n",
        "        self.time_distributed_attention = TimeDistributedSegmentAttention(input_dim=512, units=512)\n",
        "        self.lstm_sequence = nn.LSTM(input_size=512, hidden_size=256, batch_first=True)\n",
        "        self.final_attention = SegmentAttention(input_dim=256, units=256)\n",
        "        self.fc = nn.Linear(256, 512)\n",
        "        self.dropout = nn.Dropout(0.24)\n",
        "        self.classifier = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        logits, _, _ = self.forward_with_attention(x, mask)\n",
        "        return logits\n",
        "\n",
        "    def forward_with_attention(self, x, mask=None):\n",
        "        \"\"\"\n",
        "        x:    (B, S, T, C)\n",
        "        mask: (B, S, T) with 1=valid, 0=pad (or None)\n",
        "        \"\"\"\n",
        "        B, S, T, C = x.shape\n",
        "        x = x.view(B * S, T, C).permute(0, 2, 1)    # (B*S, C, T)\n",
        "\n",
        "        conv = self.conv1d(x)                       # (B*S, 128, T)\n",
        "        conv = self.bn1(conv)        # Normalize activations\n",
        "        conv = F.relu(conv)\n",
        "        att  = self.channel_attention(conv)         # (B*S, 128, T)\n",
        "        pooled = self.pool(att)                     # (B*S, 128, T2)\n",
        "        pooled = pooled.permute(0, 2, 1)            # (B*S, T2, 128)\n",
        "\n",
        "        # Downsample mask to T2 with the same pooling parameters\n",
        "        if mask is not None:\n",
        "            m = mask.view(B * S, 1, T)              # (B*S, 1, T)\n",
        "            m2 = F.max_pool1d(m, kernel_size=3, stride=2, padding=1)  # (B*S, 1, T2)\n",
        "            m2 = (m2 > 0.0).float().squeeze(1)      # (B*S, T2)\n",
        "        else:\n",
        "            m2 = None\n",
        "\n",
        "        seg_lstm_out, _ = self.lstm_segment(pooled) # (B*S, T2, 256)\n",
        "        seg_lstm_out = seg_lstm_out.view(B, S, seg_lstm_out.shape[1], seg_lstm_out.shape[2])  # (B, S, T2, 256)\n",
        "        if m2 is not None:\n",
        "            m2 = m2.view(B, S, -1)                  # (B, S, T2)\n",
        "\n",
        "        segment_outputs, segment_alphas = self.time_distributed_attention(seg_lstm_out, mask=m2)  # (B, S, 256), (B, S, T2)\n",
        "        seq_lstm_out, _ = self.lstm_sequence(segment_outputs)                                     # (B, S, 512)\n",
        "        final_output, final_alphas = self.final_attention(seq_lstm_out)                           # (B, 512), (B, S)\n",
        "\n",
        "        x = F.relu(self.fc(final_output))\n",
        "        x = self.dropout(x)\n",
        "        logits = self.classifier(x)                 # (B, num_classes)\n",
        "        return logits, final_alphas, segment_alphas\n",
        "\n",
        "\n",
        "model = HANWithAttention(num_classes=11).to(DEVICE)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = HANWithAttention().to(device)\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model,\n",
        "        input_size=(2, 10, 300, 12),    # (batch, segments, timesteps, channels)\n",
        "        col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n",
        "        depth=4,\n",
        "        device=device.type)        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IXEraoezEka"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_metrics(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_labels, all_preds, all_probs = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            inputs = batch[\"signal\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "            labels = labels.cpu().numpy()\n",
        "\n",
        "            all_labels.extend(labels)\n",
        "            all_preds.extend(preds)\n",
        "            all_probs.extend(probs)\n",
        "\n",
        "    avg_loss = running_loss / len(all_labels)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "\n",
        "    try:\n",
        "      y_true = np.eye(num_classes)[all_labels]\n",
        "      y_score = np.array(all_probs)\n",
        "\n",
        "      auc_list = []\n",
        "      for i in range(num_classes):\n",
        "          if np.any(y_true[:, i]):  # class i exists\n",
        "              auc_list.append(roc_auc_score(y_true[:, i], y_score[:, i]))\n",
        "      if auc_list:\n",
        "          auc = np.mean(auc_list)\n",
        "      else:\n",
        "          auc = float(\"nan\")\n",
        "    except ValueError:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return avg_loss, acc, precision, recall, auc, f1\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer, criterion, device,\n",
        "          epochs, scheduler=None):\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    history = {\n",
        "        \"train_loss\": [], \"train_acc\": [], \"train_f1\": [], \"train_precision\": [], \"train_recall\": [], \"train_auc\": [],\n",
        "        \"val_loss\": [],   \"val_acc\": [],   \"val_f1\": [],   \"val_precision\": [],   \"val_recall\": [], \"val_auc\": []\n",
        "    }\n",
        "\n",
        "    skip_seed = False\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False)\n",
        "        for batch in loop:\n",
        "            inputs = batch[\"signal\"].to(device)\n",
        "            mask = batch.get(\"mask\", None)\n",
        "            if mask is not None:\n",
        "                mask = mask.to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            outputs = model(inputs, mask=mask) if mask is not None else model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_size = labels.size(0)\n",
        "            running_loss += loss.item() * batch_size\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            probs = torch.softmax(outputs, dim=1).detach().cpu().numpy()\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += batch_size\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            loop.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{correct/total:.4f}\")\n",
        "\n",
        "        epoch_loss = running_loss / total\n",
        "        epoch_acc = correct / total\n",
        "        epoch_precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "        epoch_recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "        epoch_f1 = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "\n",
        "        try:\n",
        "            y_true = np.eye(num_classes)[all_labels]\n",
        "            y_score = np.array(all_probs)\n",
        "            auc_list = [\n",
        "                roc_auc_score(y_true[:, i], y_score[:, i])\n",
        "                for i in range(num_classes) if np.any(y_true[:, i])\n",
        "            ]\n",
        "            epoch_auc = np.mean(auc_list) if auc_list else float(\"nan\")\n",
        "        except ValueError:\n",
        "            epoch_auc = float(\"nan\")\n",
        "\n",
        "        history[\"train_loss\"].append(epoch_loss)\n",
        "        history[\"train_acc\"].append(epoch_acc)\n",
        "        history[\"train_precision\"].append(epoch_precision)\n",
        "        history[\"train_recall\"].append(epoch_recall)\n",
        "        history[\"train_f1\"].append(epoch_f1)\n",
        "        history[\"train_auc\"].append(epoch_auc)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch}/{epochs} | \"\n",
        "            f\"train_loss {epoch_loss:.4f} | train_f1 {epoch_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        if val_loader is not None:\n",
        "            vloss, vacc, vprecision, vrecall, vauc, vf1 = evaluate_metrics(\n",
        "                model, val_loader, criterion, device\n",
        "            )\n",
        "\n",
        "            history[\"val_loss\"].append(vloss)\n",
        "            history[\"val_acc\"].append(vacc)\n",
        "            history[\"val_precision\"].append(vprecision)\n",
        "            history[\"val_recall\"].append(vrecall)\n",
        "            history[\"val_f1\"].append(vf1)\n",
        "            history[\"val_auc\"].append(vauc)\n",
        "\n",
        "            print(\n",
        "                f\"Epoch {epoch} | \"\n",
        "                f\"val_loss {vloss:.4f} | val_f1 {vf1:.4f} | \"\n",
        "                f\"val_precision {vprecision:.4f} | val_recall {vrecall:.4f}\"\n",
        "            )\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step(vloss)\n",
        "\n",
        "        else:\n",
        "            history[\"val_loss\"].append(None)\n",
        "            history[\"val_acc\"].append(None)\n",
        "            history[\"val_precision\"].append(None)\n",
        "            history[\"val_recall\"].append(None)\n",
        "            history[\"val_f1\"].append(None)\n",
        "            history[\"val_auc\"].append(None)\n",
        "\n",
        "    return history, skip_seed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yS2XaV_2Pbe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from tqdm import tqdm\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def run_experiments(model_fn,\n",
        "                    optimizer_fn, criterion, device, epochs, num_classes,\n",
        "                    seeds=10):\n",
        "    results = {\"acc\": [], \"precision\": [], \"recall\": [], \"auc\": [], \"loss\": []}\n",
        "\n",
        "    for seed in range(40, 60):\n",
        "        print(f\"\\n=== Seed {seed} ===\")\n",
        "        set_seed(seed)\n",
        "        ds = ECGSegmentDatasetVarLen(data_list)\n",
        "\n",
        "        all_indices = list(range(len(ds)))\n",
        "        all_labels = [data_list[i][1] for i in all_indices]\n",
        "\n",
        "        # Train/val/test split\n",
        "        trainval_indices, test_indices = train_test_split(\n",
        "            all_indices, test_size=0.1, random_state=seed, stratify=all_labels\n",
        "        )\n",
        "        trainval_labels = [all_labels[i] for i in trainval_indices]\n",
        "        train_indices, val_indices = train_test_split(\n",
        "            trainval_indices, test_size=0.1, random_state=seed, stratify=trainval_labels\n",
        "        )\n",
        "\n",
        "        # Datasets and loaders\n",
        "        train_ds = Subset(ds, train_indices)\n",
        "        val_ds = Subset(ds, val_indices)\n",
        "        test_ds = Subset(ds, test_indices)\n",
        "        train_loader = make_loader(train_ds, batch_size=BATCH_SIZE)\n",
        "        val_loader = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "        test_loader = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        print(\"Train distribution:\", get_label_distribution(train_indices))\n",
        "        print(\"Val distribution:\", get_label_distribution(val_indices))\n",
        "        print(\"Test distribution:\", get_label_distribution(test_indices))\n",
        "\n",
        "        model = model_fn().to(device)\n",
        "        optimizer = optimizer_fn(model)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='min', factor=0.1, patience=2\n",
        "        )\n",
        "\n",
        "        # --- Train ---\n",
        "        history, _ = train(model, train_loader, val_loader, optimizer, criterion, device, epochs, scheduler)\n",
        "    \n",
        "\n",
        "        # --- Evaluate on test set ---\n",
        "        loss, acc, precision, recall, auc, f1 = evaluate_metrics(model, test_loader, criterion, device)\n",
        "        print(f\"Test (seed {seed}) — loss: {loss:.4f}, acc: {acc:.4f}, \"\n",
        "              f\"precision: {precision:.4f}, recall: {recall:.4f}, auc: {auc:.4f}, f1: {f1:.4f}\")\n",
        "\n",
        "        results[\"loss\"].append(loss)\n",
        "        results[\"acc\"].append(acc)\n",
        "        results[\"precision\"].append(precision)\n",
        "        results[\"recall\"].append(recall)\n",
        "        results[\"auc\"].append(auc)\n",
        "\n",
        "    # --- Aggregate results ---\n",
        "    print(\"\\n=== Final Results (across seeds) ===\")\n",
        "    for k, v in results.items():\n",
        "        arr = np.array(v, dtype=np.float32)\n",
        "        print(f\"{k}: mean={arr.mean():.4f}, std={arr.std():.4f}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgCeupwD6_59"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  return HANWithAttention(num_classes=num_classes)\n",
        "\n",
        "def optimizer_fn(model):\n",
        "  return torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgDZXVhbPePG"
      },
      "outputs": [],
      "source": [
        "results = run_experiments(\n",
        "    model_fn=model_fn,\n",
        "    optimizer_fn=optimizer_fn,\n",
        "    criterion=criterion,\n",
        "    device=DEVICE,\n",
        "    epochs=25,\n",
        "    num_classes=num_classes,\n",
        "    seeds=10\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
